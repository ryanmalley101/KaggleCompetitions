{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Digit Recognizer"
      ],
      "metadata": {
        "id": "gkiVev0MpDAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
        "\n",
        "In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We’ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare."
      ],
      "metadata": {
        "id": "-8xVyzOFpv_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get helper functions and import libraries\n",
        "\n",
        "I've stored some functions helpful for data analysis on GitHub. Credit to Daniel Bourke for many of them, check out his course on Zero to Mastery!"
      ],
      "metadata": {
        "id": "gnm2IJegMEnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper functions\n",
        "import os.path\n",
        "!wget https://raw.githubusercontent.com/ryanmalley101/Inara/main/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZW0LaIQMOWW",
        "outputId": "0af3046f-1f53-433c-ec4b-175932a49234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-06 06:21:52--  https://raw.githubusercontent.com/ryanmalley101/Inara/main/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4494 (4.4K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]   4.39K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-06 06:21:52 (56.3 MB/s) - ‘helper_functions.py.1’ saved [4494/4494]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import *\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "Uiy8D5BZNSji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore Datasets\n"
      ],
      "metadata": {
        "id": "o0GhZfnhp0RP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and Unzip Data"
      ],
      "metadata": {
        "id": "b_jxFCfOQk5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/datasets/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c digit-recognizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6Muh-NgqAsr",
        "outputId": "b3543be5-3f25-47e1-eeba-d79f34cb0eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Downloading digit-recognizer.zip to /content\n",
            " 85% 13.0M/15.3M [00:01<00:00, 14.6MB/s]\n",
            "100% 15.3M/15.3M [00:01<00:00, 9.46MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip\n",
        "unzip_data(\"/content/digit-recognizer.zip\")"
      ],
      "metadata": {
        "id": "1IYQeq-KOBW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Data into DataFrames"
      ],
      "metadata": {
        "id": "U-Umg_tSOiZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv = \"/content/train.csv\"\n",
        "test_csv = \"/content/test.csv\"\n",
        "\n",
        "# Read the csvs into a dataframe\n",
        "train_df = pd.read_csv(train_csv)\n",
        "test_df = pd.read_csv(test_csv)\n",
        "\n",
        "\n",
        "# Extract the labels from the training dataframe\n",
        "train_labels_df = train_df[\"label\"]\n",
        "train_labels_df.head()\n",
        "\n",
        "# Drop the labels column from the training dataframe\n",
        "train_df = train_df.drop(\"label\", axis=1)\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "3MQ_JouYO4aO",
        "outputId": "9e5f15a5-cf69-417f-fe25-d921e743c84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0           0       0       0       0       0       0       0       0       0   \n",
              "1           0       0       0       0       0       0       0       0       0   \n",
              "2           0       0       0       0       0       0       0       0       0   \n",
              "3           0       0       0       0       0       0       0       0       0   \n",
              "4           0       0       0       0       0       0       0       0       0   \n",
              "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "41995       0       0       0       0       0       0       0       0       0   \n",
              "41996       0       0       0       0       0       0       0       0       0   \n",
              "41997       0       0       0       0       0       0       0       0       0   \n",
              "41998       0       0       0       0       0       0       0       0       0   \n",
              "41999       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "       pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
              "0           0  ...         0         0         0         0         0   \n",
              "1           0  ...         0         0         0         0         0   \n",
              "2           0  ...         0         0         0         0         0   \n",
              "3           0  ...         0         0         0         0         0   \n",
              "4           0  ...         0         0         0         0         0   \n",
              "...       ...  ...       ...       ...       ...       ...       ...   \n",
              "41995       0  ...         0         0         0         0         0   \n",
              "41996       0  ...         0         0         0         0         0   \n",
              "41997       0  ...         0         0         0         0         0   \n",
              "41998       0  ...         0         0         0         0         0   \n",
              "41999       0  ...         0         0         0         0         0   \n",
              "\n",
              "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
              "0             0         0         0         0         0  \n",
              "1             0         0         0         0         0  \n",
              "2             0         0         0         0         0  \n",
              "3             0         0         0         0         0  \n",
              "4             0         0         0         0         0  \n",
              "...         ...       ...       ...       ...       ...  \n",
              "41995         0         0         0         0         0  \n",
              "41996         0         0         0         0         0  \n",
              "41997         0         0         0         0         0  \n",
              "41998         0         0         0         0         0  \n",
              "41999         0         0         0         0         0  \n",
              "\n",
              "[42000 rows x 784 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7a43b55-3992-405a-97b3-13eb74b2ac17\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41998</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42000 rows × 784 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7a43b55-3992-405a-97b3-13eb74b2ac17')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7a43b55-3992-405a-97b3-13eb74b2ac17 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7a43b55-3992-405a-97b3-13eb74b2ac17');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot number of each class in training set\n",
        "train_labels_df.value_counts().plot(kind=\"bar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "GWo4uESUew5v",
        "outputId": "05a88a1f-6c52-4141-93b4-59f5560f612e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa284158040>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing this is pretty much as possible seems almost impossible. Dataframes aren't going to be helpful here"
      ],
      "metadata": {
        "id": "V4br6RL3RROA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the dataframes to numpy arrays so they can be reshapes\n",
        "train_np = train_df.to_numpy()\n",
        "test_np = test_df.to_numpy()\n",
        "train_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLEH7KzqRvpl",
        "outputId": "7baff64e-a458-4b06-8169-7cdfd3c15b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through np array and reshape the 1D arrays to 2D image tensors\n",
        "train_2d = []\n",
        "for x in train_np:\n",
        "  train_2d.append(x.reshape(28, 28))\n",
        "train_2d[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woEzI5xDR4lr",
        "outputId": "8bb0895d-5333-4c4e-f559-5b7293f080c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 188, 255,  94,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 191, 250, 253,  93,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0, 123, 248, 253, 167,  10,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  80, 247, 253, 208,  13,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  29, 207, 253, 235,  77,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  54, 209, 253, 253,  88,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  93, 254, 253, 238, 170,  17,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         23, 210, 254, 253, 159,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  16,\n",
              "        209, 253, 254, 240,  81,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  27,\n",
              "        253, 253, 254,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  20, 206,\n",
              "        254, 254, 198,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 168, 253,\n",
              "        253, 196,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  20, 203, 253,\n",
              "        248,  76,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  22, 188, 253, 245,\n",
              "         93,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 103, 253, 253, 191,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  89, 240, 253, 195,  25,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  15, 220, 253, 253,  80,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  94, 253, 253, 253,  94,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  89, 251, 253, 250, 131,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 214, 218,  95,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_nine_images(train_2d, train_labels_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "vInhoegeSzM7",
        "outputId": "27a331a9-735f-4a02-b0f5-53ef069f6232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape train and test sets into 3 dimension images\n"
      ],
      "metadata": {
        "id": "e6mKiX10uldv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize\n",
        "train_df = train_df / 255.0\n",
        "test_df = test_df / 255.0"
      ],
      "metadata": {
        "id": "jdJBSt9rulIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape into image\n",
        "train_df_reshaped = train_df.values.reshape(-1,28,28,1)\n",
        "test_df_reshaped = test_df.values.reshape(-1,28,28,1)"
      ],
      "metadata": {
        "id": "WZm7qqfhvHPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create train and val splits directly from the pandas dataframes (to preserve one dimensional data)\n"
      ],
      "metadata": {
        "id": "nxYX1WJmhdHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(train_df_reshaped, train_labels_df.to_numpy(), test_size=0.2, random_state=42)\n",
        "# x_train = tf.expand_dims(x_train, axis=-1)\n",
        "# x_val = tf.expand_dims(x_val, axis=-1)\n",
        "len(x_train), len(y_train), len(x_val), len(y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTVg5XOHnHpS",
        "outputId": "004d9bf6-fe2a-44ce-d7e5-a16e7d9896fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33600, 33600, 8400, 8400)"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(y_train)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up2uSYgEpIr7",
        "outputId": "d4a06f5f-c5aa-48e7-a985-bb24ad3ff931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        6\n",
              "1        5\n",
              "2        3\n",
              "3        4\n",
              "4        7\n",
              "        ..\n",
              "33595    9\n",
              "33596    9\n",
              "33597    2\n",
              "33598    6\n",
              "33599    0\n",
              "Name: 0, Length: 33600, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encode Labels\n",
        "y_train_one_hot = pd.get_dummies(pd.DataFrame(y_train)[0]).to_numpy()\n",
        "y_val_one_hot = pd.get_dummies(pd.DataFrame(y_val)[0]).to_numpy()"
      ],
      "metadata": {
        "id": "XvjaEHy5nKQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn numpy arrays into tensorflow Datasets\n",
        "train_ds_unoptimized = tf.data.Dataset.from_tensor_slices((x_train, y_train_one_hot))\n",
        "val_ds_unoptimized = tf.data.Dataset.from_tensor_slices((x_val, y_val_one_hot))\n",
        "train_ds = train_ds_unoptimized.batch(32, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds_unoptimized.batch(32, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKh_-GNRpsm_",
        "outputId": "e65ee37f-0dcd-4bd8-d02c-f9c022b27558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset element_spec=(TensorSpec(shape=(32, 28, 28, 1), dtype=tf.float64, name=None), TensorSpec(shape=(32, 10), dtype=tf.uint8, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation"
      ],
      "metadata": {
        "id": "5TgjhTEm0ElM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# With data augmentation to prevent overfitting (accuracy 0.99286)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "trAB2FLG0HeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start modelling experiments\n",
        "\n",
        "1. Baseline (SVC Classifier as per https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
        "2. Simple Dense Model (Two hidden layers, 10 neurons each)"
      ],
      "metadata": {
        "id": "Xap5Q7C-T1lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Baseline SVC Classifier\n",
        "Multiclass in this case with a \"one-versus-one\" approach"
      ],
      "metadata": {
        "id": "fg4nKTIqhGhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "# Create SVC Classifier\n",
        "\n",
        "model_0 = GaussianNB()\n",
        "model_0.fit(tf.squeeze(tf.reshape(x_train, shape=(int(42000*.8), 1, 784))), y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukwwNHtihSBI",
        "outputId": "d86b02be-1f70-49eb-9872-1380b2fad5aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLP1brZozdX6",
        "outputId": "75c44191-388e-48af-ea3a-4e5c7b92a104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8400"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How accurate is the SVC Classifier\n",
        "model_0_results = model_0.score(tf.squeeze(tf.reshape(x_val, shape=(int(8400), 1, 784))), y_val)\n",
        "print(f\"Baseline Accuracy: {model_0_results*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a0Vu-ruh36E",
        "outputId": "1ff906f3-632e-4050-fffe-e0e05699c6be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy: 56.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Simple Dense Model\n",
        "\n",
        "We'll make a very basic Dense model with a normalization layer to get values from 0-255 to 0-1"
      ],
      "metadata": {
        "id": "DBuwr7wRjiR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(10, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_1.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDHgrCvhm3FN",
        "outputId": "0cb1a8ec-6623-4f22-9f36-f09527c62c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.7120 - accuracy: 0.7894 - val_loss: 0.3794 - val_accuracy: 0.8927\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.3281 - accuracy: 0.9046 - val_loss: 0.3234 - val_accuracy: 0.9090\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2882 - accuracy: 0.9162 - val_loss: 0.3035 - val_accuracy: 0.9138\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.2671 - accuracy: 0.9222 - val_loss: 0.2914 - val_accuracy: 0.9167\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2525 - accuracy: 0.9264 - val_loss: 0.2828 - val_accuracy: 0.9198\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2410 - accuracy: 0.9295 - val_loss: 0.2774 - val_accuracy: 0.9207\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2318 - accuracy: 0.9320 - val_loss: 0.2734 - val_accuracy: 0.9214\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2241 - accuracy: 0.9346 - val_loss: 0.2699 - val_accuracy: 0.9232\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2176 - accuracy: 0.9368 - val_loss: 0.2673 - val_accuracy: 0.9237\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.2120 - accuracy: 0.9381 - val_loss: 0.2654 - val_accuracy: 0.9251\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2071 - accuracy: 0.9400 - val_loss: 0.2638 - val_accuracy: 0.9250\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.2028 - accuracy: 0.9408 - val_loss: 0.2624 - val_accuracy: 0.9259\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1989 - accuracy: 0.9415 - val_loss: 0.2608 - val_accuracy: 0.9265\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1954 - accuracy: 0.9426 - val_loss: 0.2593 - val_accuracy: 0.9272\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1922 - accuracy: 0.9437 - val_loss: 0.2584 - val_accuracy: 0.9276\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1891 - accuracy: 0.9445 - val_loss: 0.2579 - val_accuracy: 0.9276\n",
            "Epoch 17/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1864 - accuracy: 0.9453 - val_loss: 0.2574 - val_accuracy: 0.9277\n",
            "Epoch 18/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1838 - accuracy: 0.9463 - val_loss: 0.2569 - val_accuracy: 0.9275\n",
            "Epoch 19/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1816 - accuracy: 0.9471 - val_loss: 0.2563 - val_accuracy: 0.9274\n",
            "Epoch 20/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1794 - accuracy: 0.9477 - val_loss: 0.2563 - val_accuracy: 0.9272\n",
            "Epoch 21/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1773 - accuracy: 0.9484 - val_loss: 0.2567 - val_accuracy: 0.9275\n",
            "Epoch 22/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1755 - accuracy: 0.9489 - val_loss: 0.2568 - val_accuracy: 0.9278\n",
            "Epoch 23/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1737 - accuracy: 0.9494 - val_loss: 0.2574 - val_accuracy: 0.9288\n",
            "Epoch 24/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1721 - accuracy: 0.9497 - val_loss: 0.2579 - val_accuracy: 0.9287\n",
            "Epoch 25/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1706 - accuracy: 0.9503 - val_loss: 0.2583 - val_accuracy: 0.9282\n",
            "Epoch 26/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1690 - accuracy: 0.9503 - val_loss: 0.2589 - val_accuracy: 0.9281\n",
            "Epoch 27/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1676 - accuracy: 0.9507 - val_loss: 0.2593 - val_accuracy: 0.9286\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa1c6541910>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results = model_1.evaluate(val_ds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX4APYdps1k3",
        "outputId": "ec7cde20-b095-4f91-9bf1-4e5796fe1a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 2ms/step - loss: 0.2563 - accuracy: 0.9272\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.25629669427871704, 0.9272423386573792]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3 : More Complex Dense Model\n",
        "We'll add two more Dense layers to model 2 and increase the number of neurons to 16 per"
      ],
      "metadata": {
        "id": "k555d0z3v2tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(16, activation=\"relu\"),\n",
        "  layers.Dense(16, activation=\"relu\"),\n",
        "  layers.Dense(16, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_2.fit(train_ds,\n",
        "            batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBTlA_ZCEjy2",
        "outputId": "f82e7958-7249-4f0f-bfa9-6bffd1917fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.6053 - accuracy: 0.8125 - val_loss: 0.3064 - val_accuracy: 0.9115\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.2680 - accuracy: 0.9215 - val_loss: 0.2513 - val_accuracy: 0.9270\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2149 - accuracy: 0.9359 - val_loss: 0.2254 - val_accuracy: 0.9344\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1834 - accuracy: 0.9452 - val_loss: 0.2072 - val_accuracy: 0.9402\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1624 - accuracy: 0.9529 - val_loss: 0.1944 - val_accuracy: 0.9435\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 5s 4ms/step - loss: 0.1472 - accuracy: 0.9560 - val_loss: 0.1893 - val_accuracy: 0.9448\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1353 - accuracy: 0.9604 - val_loss: 0.1877 - val_accuracy: 0.9458\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1264 - accuracy: 0.9632 - val_loss: 0.1863 - val_accuracy: 0.9455\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1188 - accuracy: 0.9652 - val_loss: 0.1855 - val_accuracy: 0.9470\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1120 - accuracy: 0.9667 - val_loss: 0.1875 - val_accuracy: 0.9467\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1054 - accuracy: 0.9691 - val_loss: 0.1918 - val_accuracy: 0.9473\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0999 - accuracy: 0.9708 - val_loss: 0.1970 - val_accuracy: 0.9473\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 5s 4ms/step - loss: 0.0950 - accuracy: 0.9720 - val_loss: 0.2003 - val_accuracy: 0.9461\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0906 - accuracy: 0.9735 - val_loss: 0.2061 - val_accuracy: 0.9467\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0866 - accuracy: 0.9752 - val_loss: 0.2093 - val_accuracy: 0.9460\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0833 - accuracy: 0.9761 - val_loss: 0.2198 - val_accuracy: 0.9449\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa1c630cfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results = model_2.evaluate(val_ds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dW4P1xuEtK6",
        "outputId": "0d50b2d1-fd2f-4dab-9191-334bb99e3577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 2ms/step - loss: 0.1855 - accuracy: 0.9470\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18553291261196136, 0.9470419883728027]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.take(1)"
      ],
      "metadata": {
        "id": "jdfZq4_jGVBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4 - CNN\n",
        "\n",
        "Create a model with convolutional layers"
      ],
      "metadata": {
        "id": "Sywk0AkYFj5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_3 = tf.keras.Sequential([\n",
        "  layers.Conv2D(filters=8, kernel_size=3, activation=\"relu\", name=\"conv_1\"),\n",
        "  layers.Conv2D(filters=8, kernel_size=3, activation=\"relu\", name=\"conv_2\"),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_3.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37AOyw5NFv-c",
        "outputId": "edaf5be9-4b1b-40f6-9552-7ddaa9e75728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 10s 3ms/step - loss: 0.2646 - accuracy: 0.9231 - val_loss: 0.1198 - val_accuracy: 0.9643\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0899 - accuracy: 0.9737 - val_loss: 0.1002 - val_accuracy: 0.9686\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0645 - accuracy: 0.9810 - val_loss: 0.0978 - val_accuracy: 0.9702\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0499 - accuracy: 0.9854 - val_loss: 0.0971 - val_accuracy: 0.9714\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0390 - accuracy: 0.9887 - val_loss: 0.0932 - val_accuracy: 0.9741\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0307 - accuracy: 0.9909 - val_loss: 0.0861 - val_accuracy: 0.9777\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 0.0913 - val_accuracy: 0.9786\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.0957 - val_accuracy: 0.9775\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.1030 - val_accuracy: 0.9779\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0953 - val_accuracy: 0.9797\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.1077 - val_accuracy: 0.9785\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.1210 - val_accuracy: 0.9781\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.1131 - val_accuracy: 0.9783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa1c6ec70a0>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results = model_3.evaluate(val_ds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XYzRKUBGDyn",
        "outputId": "8a1c8b2a-53de-491b-d0f0-0619bdc90883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 2ms/step - loss: 0.0861 - accuracy: 0.9777\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08613207936286926, 0.9776955842971802]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5 - More complex CNN with Dropout and Max Pooling\n"
      ],
      "metadata": {
        "id": "feRS6qV8QhkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_4 = tf.keras.Sequential([\n",
        "  layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool2D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool2D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(256, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_4.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_4.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNxeT-mPOzB2",
        "outputId": "c90ab71e-6053-4a52-8f3c-dfae7471bc26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 5s 4ms/step - loss: 0.4464 - accuracy: 0.8588 - val_loss: 0.1172 - val_accuracy: 0.9667\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1691 - accuracy: 0.9471 - val_loss: 0.0785 - val_accuracy: 0.9748\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1273 - accuracy: 0.9602 - val_loss: 0.0676 - val_accuracy: 0.9784\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1067 - accuracy: 0.9641 - val_loss: 0.0569 - val_accuracy: 0.9828\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0966 - accuracy: 0.9691 - val_loss: 0.0527 - val_accuracy: 0.9845\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0859 - accuracy: 0.9722 - val_loss: 0.0505 - val_accuracy: 0.9844\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0804 - accuracy: 0.9745 - val_loss: 0.0471 - val_accuracy: 0.9852\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0765 - accuracy: 0.9751 - val_loss: 0.0436 - val_accuracy: 0.9866\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0684 - accuracy: 0.9770 - val_loss: 0.0421 - val_accuracy: 0.9859\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0662 - accuracy: 0.9787 - val_loss: 0.0382 - val_accuracy: 0.9869\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0629 - accuracy: 0.9808 - val_loss: 0.0392 - val_accuracy: 0.9874\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0608 - accuracy: 0.9800 - val_loss: 0.0381 - val_accuracy: 0.9876\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0561 - accuracy: 0.9822 - val_loss: 0.0346 - val_accuracy: 0.9890\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0565 - accuracy: 0.9808 - val_loss: 0.0350 - val_accuracy: 0.9897\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0528 - accuracy: 0.9822 - val_loss: 0.0326 - val_accuracy: 0.9899\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0510 - accuracy: 0.9834 - val_loss: 0.0359 - val_accuracy: 0.9884\n",
            "Epoch 17/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0501 - accuracy: 0.9831 - val_loss: 0.0351 - val_accuracy: 0.9889\n",
            "Epoch 18/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0453 - accuracy: 0.9847 - val_loss: 0.0332 - val_accuracy: 0.9894\n",
            "Epoch 19/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0487 - accuracy: 0.9834 - val_loss: 0.0322 - val_accuracy: 0.9902\n",
            "Epoch 20/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0464 - accuracy: 0.9839 - val_loss: 0.0323 - val_accuracy: 0.9895\n",
            "Epoch 21/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0434 - accuracy: 0.9854 - val_loss: 0.0320 - val_accuracy: 0.9891\n",
            "Epoch 22/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0452 - accuracy: 0.9851 - val_loss: 0.0285 - val_accuracy: 0.9911\n",
            "Epoch 23/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0440 - accuracy: 0.9845 - val_loss: 0.0304 - val_accuracy: 0.9901\n",
            "Epoch 24/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0414 - accuracy: 0.9859 - val_loss: 0.0337 - val_accuracy: 0.9893\n",
            "Epoch 25/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0428 - accuracy: 0.9854 - val_loss: 0.0300 - val_accuracy: 0.9912\n",
            "Epoch 26/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0444 - accuracy: 0.9861 - val_loss: 0.0310 - val_accuracy: 0.9896\n",
            "Epoch 27/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0393 - accuracy: 0.9869 - val_loss: 0.0367 - val_accuracy: 0.9894\n",
            "Epoch 28/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0380 - accuracy: 0.9868 - val_loss: 0.0271 - val_accuracy: 0.9911\n",
            "Epoch 29/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0355 - accuracy: 0.9879 - val_loss: 0.0325 - val_accuracy: 0.9912\n",
            "Epoch 30/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0369 - accuracy: 0.9873 - val_loss: 0.0302 - val_accuracy: 0.9909\n",
            "Epoch 31/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0368 - accuracy: 0.9871 - val_loss: 0.0304 - val_accuracy: 0.9906\n",
            "Epoch 32/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0353 - accuracy: 0.9886 - val_loss: 0.0286 - val_accuracy: 0.9914\n",
            "Epoch 33/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0380 - accuracy: 0.9864 - val_loss: 0.0354 - val_accuracy: 0.9889\n",
            "Epoch 34/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0372 - accuracy: 0.9876 - val_loss: 0.0307 - val_accuracy: 0.9895\n",
            "Epoch 35/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 0.0298 - val_accuracy: 0.9911\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa1c6c092e0>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_results = model_4.evaluate(val_ds)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeHrxRWyPsu2",
        "outputId": "5b095535-3497-4469-deef-71b8b50d4fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 2ms/step - loss: 0.0271 - accuracy: 0.9911\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02705557830631733, 0.9910544157028198]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 6 : LSTM"
      ],
      "metadata": {
        "id": "8LRjY_pTQpES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6AifJFk289I",
        "outputId": "97377a60-457c-4429-d5bc-5d53aaf62536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (32, 26, 26, 10)          100       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (32, 13, 13, 10)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (32, 13, 13, 10)          0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (32, 11, 11, 10)          910       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (32, 5, 5, 10)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (32, 5, 5, 10)            0         \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (32, 250)                 0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (32, 256)                 64256     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (32, 10)                  2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67,836\n",
            "Trainable params: 67,836\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Let's build an LSTM model with the Functional API\n",
        "inputs = layers.Input(shape=(28, 28, 1))\n",
        "x = layers.Reshape(target_shape=(784, 1))(inputs)\n",
        "# layers.Flatten()(inputs)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(128, return_sequences=True, name=\"LSTM_1\")(x) # this layer will error if the inputs are not the right shape\n",
        "x = layers.LSTM(128, name=\"LSTM_2\")(x) # using the tanh loss function results in a massive error\n",
        "# print(x.shape)\n",
        "# Add another optional dense layer (you could add more of these to see if they improve model performance)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "output = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model_5 = tf.keras.Model(inputs=inputs, outputs=output, name=\"model_5_lstm\")\n",
        "\n",
        "# Compile the model\n",
        "model_5.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_5.fit(train_ds,\n",
        "            batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "KZ_4F3uTQta5",
        "outputId": "3dd20774-5bf5-4525-c016-e502150acfcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 784, 1)\n",
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 133s 73ms/step - loss: 2.3019 - accuracy: 0.1137 - val_loss: 2.3010 - val_accuracy: 0.1083\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 74s 71ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1083\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 73s 69ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1083\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 76s 73ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1083\n",
            "Epoch 5/100\n",
            "  57/1050 [>.............................] - ETA: 1:03 - loss: 2.3004 - accuracy: 0.1086"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-e462706e8a50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m model_5.fit(train_ds,\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# steps_per_epoch = int(len(train_ds)//32),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \"\"\"\n\u001b[1;32m   1158\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_results = model_5.evaluate(val_ds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPF7q5o_U0ve",
        "outputId": "c6ae516b-2de1-457d-e5bf-e26ba1cd58d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 8s 29ms/step - loss: 2.3011 - accuracy: 0.1083\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3011300563812256, 0.10830152779817581]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well that sucked, LSTMs don't seem to be helping much"
      ],
      "metadata": {
        "id": "pTWh1oYNRUg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 7 - Random Forests\n",
        "\n",
        "This will be my first time creating a random forest model, let's see how it goes. Pulling the structure from: https://www.tensorflow.org/decision_forests/tutorials/beginner_colab"
      ],
      "metadata": {
        "id": "CgMVkK4vUBhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_decision_forests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJI5rHceU67I",
        "outputId": "44df481b-cb05-4cec-f897-29b465224b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_decision_forests\n",
            "  Downloading tensorflow_decision_forests-1.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (1.3.0)\n",
            "Collecting wurlitzer\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (1.3.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (0.38.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (1.15.0)\n",
            "Collecting tensorflow~=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m543.3/588.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "train_ds_categorical = tf.data.Dataset.from_tensor_slices((tf.squeeze(x_train), y_train))\n",
        "val_ds_categorical = tf.data.Dataset.from_tensor_slices((tf.squeeze(x_val), y_val))\n",
        "train_ds_large_batch = train_ds_categorical.batch(1000).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds_large_batch = val_ds_categorical.batch(1000).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Specify the model.\n",
        "model_6 = tfdf.keras.RandomForestModel(verbose=2)\n",
        "\n",
        "# Train the model.\n",
        "model_6.fit(train_ds_large_batch,\n",
        "            validation_data = val_ds_large_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "CdB87DbYUTn8",
        "outputId": "d1129424-9906-4f61-e6b2-3234b321e2a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-77ab536fd54e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_ds_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_ds_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_ds_large_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ds_categorical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_decision_forests'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I don't know how to fix the evaluation errors in this function. I'll take the output accuracy above at its word, ~96%"
      ],
      "metadata": {
        "id": "YcJOSrJSUpC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results = [0.26379, 0.960982]"
      ],
      "metadata": {
        "id": "QUF1vry3VDX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluate model results\n",
        "results = {\"model_1_baseline\": model_0_results,\n",
        "           \"model_2_dense_lite\": model_1_results,\n",
        "           \"model_3_dense_large\": model_2_results,\n",
        "           \"model_4_cnn_lite\": model_3_results,\n",
        "           \"model_5_cnn_large\": model_4_results,\n",
        "           \"model_6_lstm\": model_5_results,\n",
        "           \"model_7_random_forest\": model_6_results}\n",
        "\n",
        "results_df = pd.DataFrame(results).transpose()\n",
        "acc_df = results_df[1]\n",
        "acc_df"
      ],
      "metadata": {
        "id": "nXK4eGP9f0cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_df.sort_values(ascending=False).plot(kind=\"bar\", title=\"Model Accuracy\")"
      ],
      "metadata": {
        "id": "_YVHIwZ1gX1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So model 5 is our most accurate model, the only one to beat the baseline. Lets try and fine tune it."
      ],
      "metadata": {
        "id": "hRetTPV6hyUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tuning\n"
      ],
      "metadata": {
        "id": "Kmt7YED6ii8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 8 - Reduce Dropout"
      ],
      "metadata": {
        "id": "3A6hfuv_jJBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce dropout percentages\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_7 = tf.keras.Sequential([\n",
        "  layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(256, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_7.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\n",
        "                        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6bSzSS2ir8D",
        "outputId": "6e6c1a22-9b66-4a18-b281-b33c0d26103c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 7s 6ms/step - loss: 0.3744 - accuracy: 0.8832 - val_loss: 0.1044 - val_accuracy: 0.9684 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1341 - accuracy: 0.9580 - val_loss: 0.0755 - val_accuracy: 0.9763 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0992 - accuracy: 0.9682 - val_loss: 0.0617 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0832 - accuracy: 0.9732 - val_loss: 0.0554 - val_accuracy: 0.9819 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0718 - accuracy: 0.9769 - val_loss: 0.0514 - val_accuracy: 0.9843 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0608 - accuracy: 0.9800 - val_loss: 0.0447 - val_accuracy: 0.9860 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0597 - accuracy: 0.9801 - val_loss: 0.0455 - val_accuracy: 0.9858 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0529 - accuracy: 0.9826 - val_loss: 0.0474 - val_accuracy: 0.9851 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0489 - accuracy: 0.9843 - val_loss: 0.0388 - val_accuracy: 0.9878 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0457 - accuracy: 0.9850 - val_loss: 0.0398 - val_accuracy: 0.9870 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0420 - accuracy: 0.9860 - val_loss: 0.0435 - val_accuracy: 0.9865 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0415 - accuracy: 0.9861 - val_loss: 0.0454 - val_accuracy: 0.9850 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0373 - accuracy: 0.9883 - val_loss: 0.0355 - val_accuracy: 0.9891 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0353 - accuracy: 0.9880 - val_loss: 0.0399 - val_accuracy: 0.9882 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0359 - accuracy: 0.9878 - val_loss: 0.0354 - val_accuracy: 0.9890 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0330 - accuracy: 0.9885 - val_loss: 0.0401 - val_accuracy: 0.9889 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0317 - accuracy: 0.9893 - val_loss: 0.0396 - val_accuracy: 0.9882 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.0382 - val_accuracy: 0.9878 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0273 - accuracy: 0.9907 - val_loss: 0.0379 - val_accuracy: 0.9887 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "1039/1050 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9899\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0295 - accuracy: 0.9899 - val_loss: 0.0371 - val_accuracy: 0.9890 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.0306 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.0302 - val_accuracy: 0.9913 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.0305 - val_accuracy: 0.9912 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.0304 - val_accuracy: 0.9908 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.0298 - val_accuracy: 0.9913 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0160 - accuracy: 0.9942 - val_loss: 0.0293 - val_accuracy: 0.9915 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0154 - accuracy: 0.9943 - val_loss: 0.0303 - val_accuracy: 0.9913 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.0310 - val_accuracy: 0.9915 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0309 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.0300 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "1043/1050 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9946\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 0.0309 - val_accuracy: 0.9915 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0305 - val_accuracy: 0.9914 - lr: 1.0000e-05\n",
            "Epoch 33/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.0303 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
            "Epoch 34/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0142 - accuracy: 0.9948 - val_loss: 0.0302 - val_accuracy: 0.9917 - lr: 1.0000e-05\n",
            "Epoch 35/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0304 - val_accuracy: 0.9915 - lr: 1.0000e-05\n",
            "Epoch 36/100\n",
            "1039/1050 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9954\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0303 - val_accuracy: 0.9917 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa1c6ed8100>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7_results = model_7.evaluate(val_ds)\n",
        "model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV_Ekz4Bi1Gg",
        "outputId": "d9b35804-0dca-4e9c-eba2-d9f00a60b50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 2ms/step - loss: 0.0293 - accuracy: 0.9915\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.029341470450162888, 0.991531491279602]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 9 - Increase Convolution Units"
      ],
      "metadata": {
        "id": "ogzjkB0gjH-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce dropout percentages\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_8 = tf.keras.Sequential([\n",
        "  layers.Conv2D(32, 3, activation=\"relu\", batch_input_shape=(32, 28, 28, 1)),\n",
        "  layers.MaxPool2D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Conv2D(16, 3, activation=\"relu\"),\n",
        "  layers.MaxPool2D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(256, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_8.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_8.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\n",
        "                        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "_7gFfvoijSji",
        "outputId": "63bd405e-c986-4e19-86c4-dfa96eaaf63d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1048/1050 [============================>.] - ETA: 0s - loss: 0.3041 - accuracy: 0.9052"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-9d5c778e90eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m model_8.fit(train_ds,\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;31m# batch_size=32,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# steps_per_epoch = int(len(train_ds)//32),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1445\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1446\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    984\u001b[0m               *args, **kwds))\n\u001b[1;32m    985\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       return self._concrete_stateful_fn._call_flat(\n\u001b[0m\u001b[1;32m    987\u001b[0m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_8_results = model_8.evaluate(val_ds)\n",
        "model_8_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTBheLHqjXlb",
        "outputId": "9e46872c-e2bf-49fa-d9e3-0d8108bfc2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9938\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02378423698246479, 0.9937977194786072]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 10 - Change Dense Layers Before Output\n",
        "\n"
      ],
      "metadata": {
        "id": "VpQ9nqiZjlY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce dropout percentages\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_9 = tf.keras.Sequential([\n",
        "  layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool2D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool2D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_9.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_9.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\n",
        "                        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1)])"
      ],
      "metadata": {
        "id": "Zvurj6gwmygF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e726558-2229-403a-9914-e83306382489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.5371 - accuracy: 0.8317 - val_loss: 0.1715 - val_accuracy: 0.9523 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.2241 - accuracy: 0.9296 - val_loss: 0.1271 - val_accuracy: 0.9625 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1742 - accuracy: 0.9456 - val_loss: 0.1005 - val_accuracy: 0.9679 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1435 - accuracy: 0.9546 - val_loss: 0.0811 - val_accuracy: 0.9735 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1231 - accuracy: 0.9611 - val_loss: 0.0786 - val_accuracy: 0.9739 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1100 - accuracy: 0.9646 - val_loss: 0.0641 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1047 - accuracy: 0.9664 - val_loss: 0.0630 - val_accuracy: 0.9803 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0991 - accuracy: 0.9689 - val_loss: 0.0614 - val_accuracy: 0.9806 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0879 - accuracy: 0.9723 - val_loss: 0.0519 - val_accuracy: 0.9828 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0872 - accuracy: 0.9720 - val_loss: 0.0507 - val_accuracy: 0.9843 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0822 - accuracy: 0.9733 - val_loss: 0.0462 - val_accuracy: 0.9859 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0789 - accuracy: 0.9746 - val_loss: 0.0501 - val_accuracy: 0.9831 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0761 - accuracy: 0.9748 - val_loss: 0.0451 - val_accuracy: 0.9859 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0735 - accuracy: 0.9762 - val_loss: 0.0418 - val_accuracy: 0.9871 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0674 - accuracy: 0.9790 - val_loss: 0.0459 - val_accuracy: 0.9846 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0694 - accuracy: 0.9778 - val_loss: 0.0404 - val_accuracy: 0.9864 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0668 - accuracy: 0.9783 - val_loss: 0.0398 - val_accuracy: 0.9874 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0633 - accuracy: 0.9796 - val_loss: 0.0415 - val_accuracy: 0.9866 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0620 - accuracy: 0.9791 - val_loss: 0.0367 - val_accuracy: 0.9878 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0611 - accuracy: 0.9797 - val_loss: 0.0351 - val_accuracy: 0.9885 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0598 - accuracy: 0.9802 - val_loss: 0.0371 - val_accuracy: 0.9883 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0607 - accuracy: 0.9793 - val_loss: 0.0335 - val_accuracy: 0.9902 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0608 - accuracy: 0.9806 - val_loss: 0.0380 - val_accuracy: 0.9875 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0593 - accuracy: 0.9803 - val_loss: 0.0368 - val_accuracy: 0.9874 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0531 - accuracy: 0.9827 - val_loss: 0.0369 - val_accuracy: 0.9885 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0577 - accuracy: 0.9807 - val_loss: 0.0387 - val_accuracy: 0.9878 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "1039/1050 [============================>.] - ETA: 0s - loss: 0.0547 - accuracy: 0.9820\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0547 - accuracy: 0.9820 - val_loss: 0.0347 - val_accuracy: 0.9893 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0477 - accuracy: 0.9845 - val_loss: 0.0315 - val_accuracy: 0.9903 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0445 - accuracy: 0.9847 - val_loss: 0.0314 - val_accuracy: 0.9897 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0450 - accuracy: 0.9851 - val_loss: 0.0306 - val_accuracy: 0.9902 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0453 - accuracy: 0.9849 - val_loss: 0.0308 - val_accuracy: 0.9903 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0468 - accuracy: 0.9851 - val_loss: 0.0304 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0413 - accuracy: 0.9861 - val_loss: 0.0300 - val_accuracy: 0.9903 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0428 - accuracy: 0.9849 - val_loss: 0.0302 - val_accuracy: 0.9903 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0426 - accuracy: 0.9851 - val_loss: 0.0300 - val_accuracy: 0.9907 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0427 - accuracy: 0.9855 - val_loss: 0.0297 - val_accuracy: 0.9911 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0435 - accuracy: 0.9855 - val_loss: 0.0297 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0439 - accuracy: 0.9851 - val_loss: 0.0295 - val_accuracy: 0.9905 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0407 - accuracy: 0.9866 - val_loss: 0.0300 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0429 - accuracy: 0.9858 - val_loss: 0.0301 - val_accuracy: 0.9908 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0418 - accuracy: 0.9858 - val_loss: 0.0301 - val_accuracy: 0.9907 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0413 - accuracy: 0.9869 - val_loss: 0.0296 - val_accuracy: 0.9905 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "1038/1050 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9862\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0401 - accuracy: 0.9863 - val_loss: 0.0296 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0396 - accuracy: 0.9859 - val_loss: 0.0295 - val_accuracy: 0.9909 - lr: 1.0000e-05\n",
            "Epoch 45/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0377 - accuracy: 0.9877 - val_loss: 0.0294 - val_accuracy: 0.9908 - lr: 1.0000e-05\n",
            "Epoch 46/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0402 - accuracy: 0.9861 - val_loss: 0.0294 - val_accuracy: 0.9909 - lr: 1.0000e-05\n",
            "Epoch 47/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0406 - accuracy: 0.9866 - val_loss: 0.0294 - val_accuracy: 0.9911 - lr: 1.0000e-05\n",
            "Epoch 48/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0401 - accuracy: 0.9866 - val_loss: 0.0294 - val_accuracy: 0.9909 - lr: 1.0000e-05\n",
            "Epoch 49/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0406 - accuracy: 0.9864 - val_loss: 0.0295 - val_accuracy: 0.9911 - lr: 1.0000e-05\n",
            "Epoch 50/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0295 - val_accuracy: 0.9911 - lr: 1.0000e-05\n",
            "Epoch 51/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0378 - accuracy: 0.9880 - val_loss: 0.0296 - val_accuracy: 0.9911 - lr: 1.0000e-05\n",
            "Epoch 52/100\n",
            "1036/1050 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9872\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0398 - accuracy: 0.9872 - val_loss: 0.0295 - val_accuracy: 0.9912 - lr: 1.0000e-05\n",
            "Epoch 53/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0389 - accuracy: 0.9876 - val_loss: 0.0295 - val_accuracy: 0.9912 - lr: 1.0000e-06\n",
            "Epoch 54/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0381 - accuracy: 0.9866 - val_loss: 0.0295 - val_accuracy: 0.9911 - lr: 1.0000e-06\n",
            "Epoch 55/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0369 - accuracy: 0.9878 - val_loss: 0.0295 - val_accuracy: 0.9911 - lr: 1.0000e-06\n",
            "Epoch 56/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0406 - accuracy: 0.9860 - val_loss: 0.0295 - val_accuracy: 0.9911 - lr: 1.0000e-06\n",
            "Epoch 57/100\n",
            "1036/1050 [============================>.] - ETA: 0s - loss: 0.0417 - accuracy: 0.9860\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0417 - accuracy: 0.9860 - val_loss: 0.0295 - val_accuracy: 0.9911 - lr: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa214739970>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_9_results = model_9.evaluate(val_ds)\n",
        "model_9_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG9UxuY4kCP3",
        "outputId": "c07fa2b2-19b7-4455-865c-c126c98bc282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9911\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.029368488118052483, 0.9910544157028198]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 11 - Add another Conv layer block\n"
      ],
      "metadata": {
        "id": "LGgzWo6HkFbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_10 = tf.keras.Sequential([\n",
        "  layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool2D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool2D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool2D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(256, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_10.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_10.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UZQ1EjwHkmoG",
        "outputId": "6decc25d-e7fb-4d13-926e-069325ed65ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 5s 4ms/step - loss: 1.3857 - accuracy: 0.5106 - val_loss: 0.6926 - val_accuracy: 0.8193 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.9371 - accuracy: 0.6778 - val_loss: 0.4928 - val_accuracy: 0.8783 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.8286 - accuracy: 0.7208 - val_loss: 0.4466 - val_accuracy: 0.8881 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.7601 - accuracy: 0.7449 - val_loss: 0.4237 - val_accuracy: 0.8918 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.7186 - accuracy: 0.7604 - val_loss: 0.4218 - val_accuracy: 0.8851 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.6865 - accuracy: 0.7739 - val_loss: 0.3730 - val_accuracy: 0.9040 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.6642 - accuracy: 0.7808 - val_loss: 0.3896 - val_accuracy: 0.8969 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.6504 - accuracy: 0.7859 - val_loss: 0.3486 - val_accuracy: 0.9053 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.6272 - accuracy: 0.7948 - val_loss: 0.3659 - val_accuracy: 0.9016 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.6130 - accuracy: 0.7979 - val_loss: 0.3443 - val_accuracy: 0.9089 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.6016 - accuracy: 0.8041 - val_loss: 0.3306 - val_accuracy: 0.9120 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.5899 - accuracy: 0.8076 - val_loss: 0.3465 - val_accuracy: 0.9088 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.5825 - accuracy: 0.8089 - val_loss: 0.3294 - val_accuracy: 0.9104 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.5697 - accuracy: 0.8154 - val_loss: 0.3460 - val_accuracy: 0.9101 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.5631 - accuracy: 0.8178 - val_loss: 0.3229 - val_accuracy: 0.9172 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.5549 - accuracy: 0.8192 - val_loss: 0.3225 - val_accuracy: 0.9163 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.5485 - accuracy: 0.8232 - val_loss: 0.3076 - val_accuracy: 0.9203 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.5417 - accuracy: 0.8232 - val_loss: 0.3383 - val_accuracy: 0.9135 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.5318 - accuracy: 0.8237 - val_loss: 0.3013 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.5188 - accuracy: 0.8303 - val_loss: 0.3143 - val_accuracy: 0.9173 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.5281 - accuracy: 0.8274 - val_loss: 0.3058 - val_accuracy: 0.9214 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.5064 - accuracy: 0.8340 - val_loss: 0.2994 - val_accuracy: 0.9189 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.5082 - accuracy: 0.8339 - val_loss: 0.3021 - val_accuracy: 0.9176 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.5068 - accuracy: 0.8335 - val_loss: 0.3128 - val_accuracy: 0.9142 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.5003 - accuracy: 0.8369 - val_loss: 0.2952 - val_accuracy: 0.9193 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4883 - accuracy: 0.8420 - val_loss: 0.3259 - val_accuracy: 0.9130 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4876 - accuracy: 0.8397 - val_loss: 0.2915 - val_accuracy: 0.9154 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4835 - accuracy: 0.8411 - val_loss: 0.2989 - val_accuracy: 0.9166 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4731 - accuracy: 0.8463 - val_loss: 0.3900 - val_accuracy: 0.8923 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4783 - accuracy: 0.8457 - val_loss: 0.3158 - val_accuracy: 0.9171 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4753 - accuracy: 0.8476 - val_loss: 0.3067 - val_accuracy: 0.9154 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "1040/1050 [============================>.] - ETA: 0s - loss: 0.4722 - accuracy: 0.8461\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4724 - accuracy: 0.8462 - val_loss: 0.3067 - val_accuracy: 0.9179 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4472 - accuracy: 0.8547 - val_loss: 0.2940 - val_accuracy: 0.9214 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4385 - accuracy: 0.8596 - val_loss: 0.2894 - val_accuracy: 0.9225 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4335 - accuracy: 0.8604 - val_loss: 0.2843 - val_accuracy: 0.9227 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4402 - accuracy: 0.8591 - val_loss: 0.2853 - val_accuracy: 0.9216 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4418 - accuracy: 0.8580 - val_loss: 0.2918 - val_accuracy: 0.9208 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4371 - accuracy: 0.8583 - val_loss: 0.2825 - val_accuracy: 0.9225 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4374 - accuracy: 0.8592 - val_loss: 0.2872 - val_accuracy: 0.9209 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            " 953/1050 [==========================>...] - ETA: 0s - loss: 0.4337 - accuracy: 0.8599"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-bcc6514b645f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m model_10.fit(train_ds,\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;31m# batch_size=32,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# steps_per_epoch = int(len(train_ds)//32),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m-> 2452\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2687\u001b[0m           f\"hashable.  Original error: {e}.\")\n\u001b[1;32m   2688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2689\u001b[0;31m     \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2690\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/function/polymorphism/function_cache.py\u001b[0m in \u001b[0;36mlookup\u001b[0;34m(self, key, use_function_subtyping)\u001b[0m\n\u001b[1;32m    117\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_primary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mdispatch_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdispatch_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_primary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdispatch_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/function/polymorphism/type_dispatch.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;34m\"\"\"Returns the deepest subtype target if it exists in the table.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# For known exact matches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_table\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/function/polymorphism/function_cache.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/function/trace_type/default_types.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/function/trace_type/default_types.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/function/trace_type/default_types.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__get_cmp_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;34m\"\"\"Returns a hashable eq-comparable key for `self`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;31m# TODO(b/133606651): Decide whether to cache this value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    515\u001b[0m       ])\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    515\u001b[0m       ])\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;34m\"\"\"Converts `value` to a hashable key.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     if isinstance(value, (int, float, bool, np.generic, dtypes.DType, TypeSpec,\n\u001b[0m\u001b[1;32m    504\u001b[0m                           tensor_shape.TensorShape)):\n\u001b[1;32m    505\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_10_results = model_10.evaluate(val_ds)\n",
        "model_10_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPzDD2KykfQu",
        "outputId": "fa5951d4-b7ea-4ad5-cd2a-eb0d1d40ca89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 2ms/step - loss: 0.2782 - accuracy: 0.9224\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.278230220079422, 0.9223520755767822]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 12 - Model 5 with LR callback\n"
      ],
      "metadata": {
        "id": "LT86M5Apk3h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_11 = tf.keras.Sequential([\n",
        "  layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool2D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool2D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(256, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_11.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_11.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9mAzIzamA3q",
        "outputId": "5a85bb4b-f307-4750-8df7-3943b575e7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4464 - accuracy: 0.8588 - val_loss: 0.1172 - val_accuracy: 0.9667 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1691 - accuracy: 0.9469 - val_loss: 0.0787 - val_accuracy: 0.9751 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1270 - accuracy: 0.9601 - val_loss: 0.0678 - val_accuracy: 0.9790 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1064 - accuracy: 0.9646 - val_loss: 0.0587 - val_accuracy: 0.9815 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0972 - accuracy: 0.9693 - val_loss: 0.0536 - val_accuracy: 0.9834 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0858 - accuracy: 0.9725 - val_loss: 0.0500 - val_accuracy: 0.9840 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0799 - accuracy: 0.9743 - val_loss: 0.0484 - val_accuracy: 0.9849 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0773 - accuracy: 0.9748 - val_loss: 0.0435 - val_accuracy: 0.9866 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0685 - accuracy: 0.9776 - val_loss: 0.0420 - val_accuracy: 0.9869 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0658 - accuracy: 0.9785 - val_loss: 0.0378 - val_accuracy: 0.9880 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0630 - accuracy: 0.9803 - val_loss: 0.0383 - val_accuracy: 0.9877 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0604 - accuracy: 0.9805 - val_loss: 0.0397 - val_accuracy: 0.9880 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0557 - accuracy: 0.9821 - val_loss: 0.0357 - val_accuracy: 0.9888 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0552 - accuracy: 0.9815 - val_loss: 0.0364 - val_accuracy: 0.9894 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0531 - accuracy: 0.9824 - val_loss: 0.0327 - val_accuracy: 0.9899 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0526 - accuracy: 0.9824 - val_loss: 0.0371 - val_accuracy: 0.9877 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0506 - accuracy: 0.9832 - val_loss: 0.0352 - val_accuracy: 0.9896 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0456 - accuracy: 0.9840 - val_loss: 0.0328 - val_accuracy: 0.9902 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0479 - accuracy: 0.9839 - val_loss: 0.0315 - val_accuracy: 0.9899 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0467 - accuracy: 0.9841 - val_loss: 0.0333 - val_accuracy: 0.9890 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0441 - accuracy: 0.9846 - val_loss: 0.0331 - val_accuracy: 0.9890 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0455 - accuracy: 0.9850 - val_loss: 0.0292 - val_accuracy: 0.9911 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0431 - accuracy: 0.9855 - val_loss: 0.0313 - val_accuracy: 0.9903 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0430 - accuracy: 0.9852 - val_loss: 0.0306 - val_accuracy: 0.9899 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0428 - accuracy: 0.9853 - val_loss: 0.0292 - val_accuracy: 0.9902 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0440 - accuracy: 0.9858 - val_loss: 0.0296 - val_accuracy: 0.9908 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "1045/1050 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9863\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0414 - accuracy: 0.9863 - val_loss: 0.0305 - val_accuracy: 0.9902 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 0.0263 - val_accuracy: 0.9918 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.0262 - val_accuracy: 0.9920 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 0.0253 - val_accuracy: 0.9927 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0278 - accuracy: 0.9902 - val_loss: 0.0257 - val_accuracy: 0.9926 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.0251 - val_accuracy: 0.9930 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0286 - accuracy: 0.9904 - val_loss: 0.0254 - val_accuracy: 0.9924 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 0.0251 - val_accuracy: 0.9927 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0252 - val_accuracy: 0.9930 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0259 - accuracy: 0.9909 - val_loss: 0.0248 - val_accuracy: 0.9930 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0265 - accuracy: 0.9910 - val_loss: 0.0246 - val_accuracy: 0.9928 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.0246 - val_accuracy: 0.9930 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.0250 - val_accuracy: 0.9930 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0254 - accuracy: 0.9908 - val_loss: 0.0254 - val_accuracy: 0.9924 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0253 - accuracy: 0.9910 - val_loss: 0.0253 - val_accuracy: 0.9925 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "1043/1050 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9911\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0250 - accuracy: 0.9911 - val_loss: 0.0253 - val_accuracy: 0.9922 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.0251 - val_accuracy: 0.9922 - lr: 1.0000e-05\n",
            "Epoch 44/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0233 - accuracy: 0.9918 - val_loss: 0.0249 - val_accuracy: 0.9924 - lr: 1.0000e-05\n",
            "Epoch 45/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.0249 - val_accuracy: 0.9926 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa216d29d60>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_11_results = model_11.evaluate(val_ds)\n",
        "model_11_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNmvpaTPmDnc",
        "outputId": "790cdd60-f0d3-4bd2-a25e-70c2323601be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9930\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.024576721712946892, 0.9929627776145935]"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot fine tuning results"
      ],
      "metadata": {
        "id": "zXG_J2qTmHVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuning_results = {\"model_8_lower_dropout\": model_7_results,\n",
        "                       \"model_9_increase_filters\": model_8_results,\n",
        "                       \"model_10_lower_dense_output\": model_9_results,\n",
        "                       \"model_11_extra_conv_block\": model_10_results,\n",
        "                       \"model_5_baseline\": model_11_results}\n",
        "fine_tuning_df = pd.DataFrame(fine_tuning_results).transpose()\n",
        "fine_tuning_acc = fine_tuning_df[1]\n",
        "fine_tuning_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKChJRopmiED",
        "outputId": "26b2d908-ed60-44a4-e222-fc0c910acb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_8_lower_dropout          0.991531\n",
              "model_9_increase_filters       0.993798\n",
              "model_10_lower_dense_output    0.991054\n",
              "model_11_extra_conv_block      0.922352\n",
              "model_5_baseline               0.992963\n",
              "Name: 1, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuning_acc.sort_values(ascending=False).plot(kind=\"bar\", title=\"Fine Tuning Comparison\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "TQkFO0nmpFWm",
        "outputId": "2602bca2-e918-49ee-91be-68f34bf94ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa215f2ff10>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the hyperparameters were fine for the most part, just adding another convolutional block increased accuracy just a bit. So we'll go with that model, model 11."
      ],
      "metadata": {
        "id": "jQFcvEMTpiCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct the final model with tuned hyperparameters"
      ],
      "metadata": {
        "id": "P8h1_nIPn1uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = tf.keras.models.clone_model(model_8)\n",
        "final_model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "AxchP2x8o265"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we'd expect around a 98.6% accuracy rate on the csv uploaded to Kaggle."
      ],
      "metadata": {
        "id": "9r453GcJp2gg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit the augmented dataset"
      ],
      "metadata": {
        "id": "2K2-B7C61Ujw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUX8bXb69Xze",
        "outputId": "8dcf02eb-70e2-4fe9-e13b-09bf39aebb74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((33600, 28, 28, 1), (8400, 28, 28, 1), (33600,), (8400,))"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train = pd.get_dummies(train_labels_df).to_numpy()\n",
        "# y_val.shape"
      ],
      "metadata": {
        "id": "Qob4PRLsAjEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train = pd.get_dummies(train_labels_df).to_numpy()\n",
        "train_data = datagen.flow(x_train,  y_train_one_hot, batch_size=32)\n",
        "final_model.fit(train_data,\n",
        "                epochs = 30, \n",
        "                validation_data = (x_val, y_val_one_hot),\n",
        "                verbose = 2, \n",
        "                steps_per_epoch=x_train.shape[0] // 32,\n",
        "                callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001),\n",
        "                          #  tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True)\n",
        "                          ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nZFipDe1SFW",
        "outputId": "53993c38-2e37-4054-c5ae-4f96948e994c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1050/1050 - 12s - loss: 0.5412 - accuracy: 0.8235 - val_loss: 0.1001 - val_accuracy: 0.9680 - lr: 0.0010 - 12s/epoch - 11ms/step\n",
            "Epoch 2/30\n",
            "1050/1050 - 11s - loss: 0.2108 - accuracy: 0.9338 - val_loss: 0.0678 - val_accuracy: 0.9761 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
            "Epoch 3/30\n",
            "1050/1050 - 11s - loss: 0.1544 - accuracy: 0.9509 - val_loss: 0.0560 - val_accuracy: 0.9804 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
            "Epoch 4/30\n",
            "1050/1050 - 11s - loss: 0.1385 - accuracy: 0.9574 - val_loss: 0.0523 - val_accuracy: 0.9827 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
            "Epoch 5/30\n",
            "1050/1050 - 11s - loss: 0.1183 - accuracy: 0.9642 - val_loss: 0.0394 - val_accuracy: 0.9872 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
            "Epoch 6/30\n",
            "1050/1050 - 11s - loss: 0.1107 - accuracy: 0.9645 - val_loss: 0.0338 - val_accuracy: 0.9876 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
            "Epoch 7/30\n",
            "1050/1050 - 11s - loss: 0.1072 - accuracy: 0.9665 - val_loss: 0.0337 - val_accuracy: 0.9884 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
            "Epoch 8/30\n",
            "1050/1050 - 11s - loss: 0.0986 - accuracy: 0.9684 - val_loss: 0.0311 - val_accuracy: 0.9876 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
            "Epoch 9/30\n",
            "1050/1050 - 11s - loss: 0.0940 - accuracy: 0.9698 - val_loss: 0.0310 - val_accuracy: 0.9872 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
            "Epoch 10/30\n",
            "1050/1050 - 11s - loss: 0.0918 - accuracy: 0.9712 - val_loss: 0.0280 - val_accuracy: 0.9886 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
            "Epoch 11/30\n",
            "1050/1050 - 11s - loss: 0.0836 - accuracy: 0.9737 - val_loss: 0.0364 - val_accuracy: 0.9872 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
            "Epoch 12/30\n",
            "1050/1050 - 11s - loss: 0.0836 - accuracy: 0.9726 - val_loss: 0.0336 - val_accuracy: 0.9880 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "1050/1050 - 14s - loss: 0.0785 - accuracy: 0.9752 - val_loss: 0.0275 - val_accuracy: 0.9886 - lr: 0.0010 - 14s/epoch - 13ms/step\n",
            "Epoch 14/30\n",
            "1050/1050 - 11s - loss: 0.0674 - accuracy: 0.9782 - val_loss: 0.0273 - val_accuracy: 0.9893 - lr: 5.0000e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 15/30\n",
            "1050/1050 - 11s - loss: 0.0670 - accuracy: 0.9790 - val_loss: 0.0283 - val_accuracy: 0.9903 - lr: 5.0000e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 16/30\n",
            "1050/1050 - 11s - loss: 0.0631 - accuracy: 0.9802 - val_loss: 0.0229 - val_accuracy: 0.9903 - lr: 5.0000e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 17/30\n",
            "1050/1050 - 11s - loss: 0.0629 - accuracy: 0.9803 - val_loss: 0.0217 - val_accuracy: 0.9907 - lr: 5.0000e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 18/30\n",
            "1050/1050 - 11s - loss: 0.0613 - accuracy: 0.9809 - val_loss: 0.0262 - val_accuracy: 0.9894 - lr: 5.0000e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 19/30\n",
            "1050/1050 - 11s - loss: 0.0589 - accuracy: 0.9808 - val_loss: 0.0235 - val_accuracy: 0.9905 - lr: 5.0000e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 20/30\n",
            "1050/1050 - 11s - loss: 0.0627 - accuracy: 0.9804 - val_loss: 0.0224 - val_accuracy: 0.9912 - lr: 5.0000e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 21/30\n",
            "1050/1050 - 11s - loss: 0.0580 - accuracy: 0.9810 - val_loss: 0.0245 - val_accuracy: 0.9897 - lr: 5.0000e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 22/30\n",
            "1050/1050 - 11s - loss: 0.0591 - accuracy: 0.9817 - val_loss: 0.0222 - val_accuracy: 0.9910 - lr: 5.0000e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "1050/1050 - 11s - loss: 0.0582 - accuracy: 0.9822 - val_loss: 0.0270 - val_accuracy: 0.9889 - lr: 5.0000e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 24/30\n",
            "1050/1050 - 11s - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.0192 - val_accuracy: 0.9920 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 25/30\n",
            "1050/1050 - 11s - loss: 0.0522 - accuracy: 0.9833 - val_loss: 0.0205 - val_accuracy: 0.9917 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 26/30\n",
            "1050/1050 - 11s - loss: 0.0515 - accuracy: 0.9838 - val_loss: 0.0211 - val_accuracy: 0.9906 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "1050/1050 - 11s - loss: 0.0494 - accuracy: 0.9847 - val_loss: 0.0199 - val_accuracy: 0.9918 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 28/30\n",
            "1050/1050 - 11s - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.0190 - val_accuracy: 0.9918 - lr: 1.2500e-04 - 11s/epoch - 11ms/step\n",
            "Epoch 29/30\n",
            "1050/1050 - 11s - loss: 0.0505 - accuracy: 0.9835 - val_loss: 0.0183 - val_accuracy: 0.9923 - lr: 1.2500e-04 - 11s/epoch - 10ms/step\n",
            "Epoch 30/30\n",
            "1050/1050 - 11s - loss: 0.0463 - accuracy: 0.9856 - val_loss: 0.0190 - val_accuracy: 0.9920 - lr: 1.2500e-04 - 11s/epoch - 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa2162036a0>"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Test Dataset"
      ],
      "metadata": {
        "id": "xOdhPhUHqFOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds = tf.round(final_model.predict(test_df_reshaped))\n",
        "test_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG8eR2K-qMdq",
        "outputId": "8b490fe0-f8cf-4117-b69b-d0a8e7b15d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "875/875 [==============================] - 2s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(28000, 10), dtype=float32, numpy=\n",
              "array([[0., 0., 1., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds_labels = tf.argmax(test_preds, axis=1)\n",
        "# test_preds_labels_df = pd.DataFrame(test_preds_labels)\n",
        "# test_preds_labels_df"
      ],
      "metadata": {
        "id": "zjpFGuxIqRcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "DGHpl3sasrzc",
        "outputId": "98174632-7848-4b05-dfaa-a4f5c5574742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "27995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "27996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "27997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "27998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "27999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "\n",
              "       pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
              "0         0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              "1         0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              "2         0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              "3         0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              "4         0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              "...       ...  ...       ...       ...       ...       ...       ...   \n",
              "27995     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              "27996     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              "27997     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              "27998     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              "27999     0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              "\n",
              "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
              "0           0.0       0.0       0.0       0.0       0.0  \n",
              "1           0.0       0.0       0.0       0.0       0.0  \n",
              "2           0.0       0.0       0.0       0.0       0.0  \n",
              "3           0.0       0.0       0.0       0.0       0.0  \n",
              "4           0.0       0.0       0.0       0.0       0.0  \n",
              "...         ...       ...       ...       ...       ...  \n",
              "27995       0.0       0.0       0.0       0.0       0.0  \n",
              "27996       0.0       0.0       0.0       0.0       0.0  \n",
              "27997       0.0       0.0       0.0       0.0       0.0  \n",
              "27998       0.0       0.0       0.0       0.0       0.0  \n",
              "27999       0.0       0.0       0.0       0.0       0.0  \n",
              "\n",
              "[28000 rows x 784 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83598c8f-a753-43eb-97df-79b10d14c300\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28000 rows × 784 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83598c8f-a753-43eb-97df-79b10d14c300')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83598c8f-a753-43eb-97df-79b10d14c300 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83598c8f-a753-43eb-97df-79b10d14c300');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(np.arange(1, 28001)), len(test_preds_labels))\n",
        "numpy_predicts = {\"ImageId\": np.arange(1, 28001), \"Label\":test_preds_labels}\n",
        "predict_df = pd.DataFrame(numpy_predicts)\n",
        "predict_df.to_csv(\"prediction_1.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKNQzQ4EreVP",
        "outputId": "755eb65a-bd00-4fbf-f759-13aec212c329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28000 28000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQN9Zv31soYo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}