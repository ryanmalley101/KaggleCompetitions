{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Digit Recognizer"
      ],
      "metadata": {
        "id": "gkiVev0MpDAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
        "\n",
        "In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We’ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare."
      ],
      "metadata": {
        "id": "-8xVyzOFpv_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get helper functions and import libraries\n",
        "\n",
        "I've stored some functions helpful for data analysis on GitHub. Credit to Daniel Bourke for many of them, check out his course on Zero to Mastery!"
      ],
      "metadata": {
        "id": "gnm2IJegMEnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper functions\n",
        "import os.path\n",
        "!wget https://raw.githubusercontent.com/ryanmalley101/Inara/main/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZW0LaIQMOWW",
        "outputId": "81f7e85f-0e59-487d-d468-1259d07d8fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-06 04:27:46--  https://raw.githubusercontent.com/ryanmalley101/Inara/main/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4494 (4.4K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]   4.39K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-06 04:27:46 (65.9 MB/s) - ‘helper_functions.py.1’ saved [4494/4494]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import *\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "Uiy8D5BZNSji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore Datasets\n"
      ],
      "metadata": {
        "id": "o0GhZfnhp0RP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and Unzip Data"
      ],
      "metadata": {
        "id": "b_jxFCfOQk5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/datasets/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c digit-recognizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6Muh-NgqAsr",
        "outputId": "2ce5fddc-7b2d-4e2a-fd9e-11b9a0aab2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "digit-recognizer.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip\n",
        "unzip_data(\"/content/digit-recognizer.zip\")"
      ],
      "metadata": {
        "id": "1IYQeq-KOBW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Data into DataFrames"
      ],
      "metadata": {
        "id": "U-Umg_tSOiZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv = \"/content/train.csv\"\n",
        "test_csv = \"/content/test.csv\"\n",
        "\n",
        "# Read the csvs into a dataframe\n",
        "train_df = pd.read_csv(train_csv)\n",
        "test_df = pd.read_csv(test_csv)\n",
        "\n",
        "\n",
        "# Extract the labels from the training dataframe\n",
        "train_labels_df = train_df[\"label\"]\n",
        "train_labels_df.head()\n",
        "\n",
        "# Drop the labels column from the training dataframe\n",
        "train_df = train_df.drop(\"label\", axis=1)\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "3MQ_JouYO4aO",
        "outputId": "13886774-9457-4598-ae7d-9498817fad15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0       0       0       0       0       0       0       0       0       0   \n",
              "1       0       0       0       0       0       0       0       0       0   \n",
              "2       0       0       0       0       0       0       0       0       0   \n",
              "3       0       0       0       0       0       0       0       0       0   \n",
              "4       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
              "0       0  ...         0         0         0         0         0         0   \n",
              "1       0  ...         0         0         0         0         0         0   \n",
              "2       0  ...         0         0         0         0         0         0   \n",
              "3       0  ...         0         0         0         0         0         0   \n",
              "4       0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel780  pixel781  pixel782  pixel783  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2         0         0         0         0  \n",
              "3         0         0         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 784 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5ded499-9c10-4512-b25f-f1e601bbbc64\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5ded499-9c10-4512-b25f-f1e601bbbc64')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5ded499-9c10-4512-b25f-f1e601bbbc64 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5ded499-9c10-4512-b25f-f1e601bbbc64');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot number of each class in training set\n",
        "train_labels_df.value_counts().plot(kind=\"bar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "GWo4uESUew5v",
        "outputId": "64bab9fc-4941-4747-f8e1-705742743261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0978d41be0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing this is pretty much as possible seems almost impossible. Dataframes aren't going to be helpful here"
      ],
      "metadata": {
        "id": "V4br6RL3RROA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the dataframes to numpy arrays so they can be reshapes\n",
        "train_np = train_df.to_numpy()\n",
        "test_np = test_df.to_numpy()\n",
        "train_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLEH7KzqRvpl",
        "outputId": "b8ac64d6-3606-4fe3-d911-a8904b8c66ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through np array and reshape the 1D arrays to 2D image tensors\n",
        "train_2d = []\n",
        "for x in train_np:\n",
        "  train_2d.append(x.reshape(28, 28))\n",
        "train_2d[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woEzI5xDR4lr",
        "outputId": "8facaeb1-4ec8-4173-f129-22ea9fd40aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 188, 255,  94,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 191, 250, 253,  93,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0, 123, 248, 253, 167,  10,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  80, 247, 253, 208,  13,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  29, 207, 253, 235,  77,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  54, 209, 253, 253,  88,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  93, 254, 253, 238, 170,  17,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         23, 210, 254, 253, 159,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  16,\n",
              "        209, 253, 254, 240,  81,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  27,\n",
              "        253, 253, 254,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  20, 206,\n",
              "        254, 254, 198,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 168, 253,\n",
              "        253, 196,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  20, 203, 253,\n",
              "        248,  76,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  22, 188, 253, 245,\n",
              "         93,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 103, 253, 253, 191,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  89, 240, 253, 195,  25,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  15, 220, 253, 253,  80,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  94, 253, 253, 253,  94,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  89, 251, 253, 250, 131,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 214, 218,  95,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_nine_images(train_2d, train_labels_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "vInhoegeSzM7",
        "outputId": "11c638f9-1b65-48a8-bfb5-ed2d662c42a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 9 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAI/CAYAAAB6cKNOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZRdVZk34PcQZiQggUBEBgWRqUEbEQVExgRkEhAEB6IiQiIgItoIIgh8iGKAZp4xSHejkG4lyKSNQDOYBpUhX8KghAAyCTQk3YQQ4v3+CN9qw3kP1E3dyq3a9TxruXT97nbfnVC76seps++pWq1WAACUZJFuLwAAoNMUHACgOAoOAFAcBQcAKI6CAwAUR8EBAIqj4AAAxVFwOqyqqq9WVXV/VVUz3vjPXVVV7dztdUG32BMwv6qqhlRVdWJVVdOqqnr1jf8+qaqqRbu9tpL4y+y8JyPiHyLikZhXIEdHxM+rqtqk1Wrd39WVQXfYEzC/f4iIr8a8vfBARGwUEeMjYnZEnNjFdRWl8knGfa+qqhcj4tutVuuCbq8F+gN7gsGsqqprI+KFVqs1+m+y8RExrNVq7dK9lZXFr6j60BuXIfeNiHdExJ3dXg90mz0BERFxe0RsU1XVuhERVVWtHxHbRsR1XV1VYfyKqg9UVfV3EXFXRCwZEf8dEXu0Wq0Hursq6B57Aubzg4hYNiKmVFU1N+b9LP4/rVbr3O4uqyyu4PSNhyLiAxGxWUScFxHjq6rasLtLgq6yJ+B/fToi9o+Iz0TE37/xv8dWVXVAV1dVGPfgLARVVf06Iqa3Wi1fvBD2BINbVVVPRMSPWq3WP/5N9p2I+EKr1Vq7eysriys4C8ciEbFEtxcB/Yg9wWC2dETMfVM2N/xM7ij34HRYVVWnRMQvI+KJmPc71s9ExNYR4XM/GJTsCaiZGBFHVVU1LSL+b0R8MCKOiIjLu7qqwig4nbdKRFzxxn+/HBH3R8ROrVbrxq6uCrrHnoD5HRrzPu/m3IgYHhFPR8RFEXFCNxdVGvfgAADF8fs+AKA4Cg4AUBwFBwAojoIDABRHwQEAivN2x8QdsaKbqm4vIGFP0E32BMyvcU+4ggMAFEfBAQCKo+AAAMVRcACA4ig4AEBxFBwAoDgKDgBQHAUHACiOggMAFEfBAQCKo+AAAMVRcACA4ig4AEBxFBwAoDgKDgBQHAUHACjOot1eQAlmzZqV5gceeGCaDxs2rJaNHTs2Hbvccsul+SqrrNLD1QHA4OMKDgBQHAUHACiOggMAFEfBAQCKo+AAAMWpWq3WW73+li8yz0MPPZTmm222WZq//PLLPZ57++23T/MbbrghzYcMGdLjuQeAqtsLSNgTdJM9AfNr3BOu4AAAxVFwAIDiKDgAQHEUHACgOAoOAFAcp6j60BlnnJHmDz/8cC276KKL0rGvv/56mn/5y19O86Z5BignRmB+9kRhLrvssjQ/4IADej33pptumuY333xzLVtmmWV6/X5d4hQVADB4KDgAQHEUHACgOAoOAFAcNxn3E08//XSa77TTTmme3agcETFx4sRatt122y34wrrLDZX9yPTp09P861//ei37+c9/no5t+n7z6U9/upZdeeWVbaxu0LAnBqjx48en+Re/+MU0r6q++0f9zW9+s5adcsopffZ+fcxNxgDA4KHgAADFUXAAgOIoOABAcRQcAKA4TlH1c5dcckmaNz2qYZtttqll2cdyDxBOjHTBxRdfnOYnn3xymjedrso0fb9ZeeWVa9nUqVPTscsvv3yP369A9kQXzJw5M82bTvpNmDChlt16663p2NmzZ6f50KFDa9mPfvSjdOy//Mu/pPktt9yS5sOHD69lTSd5BwCnqACAwUPBAQCKo+AAAMVRcACA4ig4AEBxFu32Aphn7ty5aX733Xe3Nc8zzzxTy1544YV07LBhw9qam4Hrtttuq2XHH398Ovauu+5K89dee63H77fCCiukedPX4nPPPVfL5syZ0+P3g07I9klExEEHHZTmTc8E7IRsfzadnl1iiSXSvOkU1WDhCg4AUBwFBwAojoIDABRHwQEAiuMm437immuuSfMLLrigrXlWWWWVWvbqq68u0JoYeG666aY0//SnP13LXn755XRsVeWffL744ouneXYz5G677ZaO3WCDDdL8ox/9aC3LPqoe+tJxxx2X5n15M3GTq6++upYdfvjhHZl7zJgxHZmnv3MFBwAojoIDABRHwQEAiqPgAADFUXAAgOI4RdUF2ammH/7whx2Ze/jw4bXsne98Z0fmpv948cUX0zw7LRURMWPGjB7PfeSRR6b5AQcckObrrLNOLdtqq616/H4RETvuuGMta/r4eeiEXXfdtZY1Pdqg6QRh0yMc9tprrx6vo9VqpXn2vbzJuHHj2pp7xRVX7PHcA5krOABAcRQcAKA4Cg4AUBwFBwAojoIDABTHKao2/fWvf61lTc/0+dnPfpbm2bN7nnnmmbbW0fTsqpEjR9Yyp1HKs8IKK6R50ymqCy+8sJatv/766djDDjsszVddddUeri7iXe96V5o3ner485//3OO5oRPuueeeWtb0HLamvXLmmWd2dE1vZ+bMmWk+e/bsNG/684wdO7Zja+rPXMEBAIqj4AAAxVFwAIDiKDgAQHEUHACgOFXTqYY3vOWLJfvtb3+b5qeddlotu+qqq/psHSeeeGKaH3XUUWm+6KJFHYzLjwB0V7/eEy+99FKa33fffbVs7bXXTse2c1oqIuK5556rZZtuumk6dpFF8n+n+sMf/lDLllxyyXTsoYcemuZ/+tOf0nz55ZevZRdccEE6dqWVVkrzfsSe6JARI0bUsmeffTYdO3To0DTfd9990/yQQw6pZRtuuGEbq8tddNFFaX7wwQe3Nc/cuXN7vZZ+pHFPuIIDABRHwQEAiqPgAADFUXAAgOK4ybjBlVdemeb77bdfn7zfxhtvnOZ33HFHmi+zzDJ9so5+xg2V/Uj2mJKIiM9+9rO1rOkxJU038Y4ZM6aWXXLJJenYdh/rkH2Pa7o59Iorrkjzppuju8Ce6JDLL7+8lp166qnp2ClTprQ1d3Zj+8knn5yO3WKLLdI8u9l/6623TsdOnjw5zUePHp3ml156aZoPUG4yBgAGDwUHACiOggMAFEfBAQCKo+AAAMVxiqpB013pRx99dC1reqzDf/3Xf6X566+/Xsua7qS//fbbm5Y4GDgx0o/ce++9ab7JJpv0eI6m7zdV1ft/1E2PmHjyySd7/H7PPPNMmvejRzjYE31o5syZaT5hwoQ0P+GEE9J8+vTpPX7Pd7zjHWm+xBJL1LIXXnghHbvBBhuk+a9//es0Hz58eA9XNyA4RQUADB4KDgBQHAUHACiOggMAFEfBAQCK4xRVHzrggAPSPHsOyN/93d+lY++88840b7rzvjBOjPQj6623Xpo//PDDPZ6jnVNUX/rSl9Kxu+22W5r/8Y9/TPNvfOMbPXq/CKeoFtCg3RNNxo8fX8uOOuqodGzT11w7Jws///nP93gdBXKKCgAYPBQcAKA4Cg4AUBwFBwAozqLdXkDJHnjggV6Pbbpx8gMf+MACrQn+v6effjrNm27ufeihh3r9nuuvv36ajxs3rpaNGjWqrbnPPvvsNM9ubP7gBz+Yjh0kN+/Tx0aPHl3L1lxzzXTsNttsk+bt3GT80ksvpfmcOXPSfLHFFuvx3AOZKzgAQHEUHACgOAoOAFAcBQcAKI6CAwAUxymqDnjttdfayjNNd9iPGDFiQZYEb+uSSy5J85tuuinN2znVsfvuu6f5WWedlearrrpqj+dussgi+b+vZet+3/vel45daqmler0OyEyYMKGt8WussUYtmz59ejr22muvTfMLLrggzQ855JC21jJQuYIDABRHwQEAiqPgAADFUXAAgOIoOABAcYo8RXX11VfXskmTJqVjTz311Lbmzp7tcfHFF6dj77vvvh7Pu9lmm6X5yiuv3OM5oMmsWbNq2cknn9zWHE2nlL75zW/WsqOPPjod25fPesr+jE0+9KEP9dk64Ac/+EEtu/DCC9OxK664YprfcccdtWzvvfdOx951111p/sQTTzQtcVBwBQcAKI6CAwAUR8EBAIqj4AAAxVFwAIDiDOhTVC+++GKaH3PMMbWs6dkz7Tr00ENrWdPzPppstdVWvZ4D2nHZZZfVsldffTUd2/TMqey0VET7p7F666WXXkrzc845J81XW221WjZ69OiOronB6bHHHkvz7Jlr2QnciIiPfOQjaZ49h7AvTyGWyBUcAKA4Cg4AUBwFBwAojoIDABRnQN9k/NRTT6X5ww8/3KMsImLHHXdM8ylTpqR5Jz76+nvf+14tW2655Xo9LzTZd999a9nUqVPTsWuttVaaH3LIIR1d04I66qij0nz69Olpvv7669eylVZaqaNromxNNwife+65aZ79bNp6663Tsddcc02P33P27Nnp2FarleaDnSs4AEBxFBwAoDgKDgBQHAUHACiOggMAFGdAn6Jq+tjq5ZdfvpY1fbz7jTfe2NZ7vuc976llTY+B2GeffdJ8iy22aOs9obdWWGGFWpZ9nHx/cu+996b5zTffnOZNJ0mOPvrojq2JwanpVO24cePSPHvcyU477ZSObTqhdeyxx9ay2267LR07bNiwNN91113TfLBwBQcAKI6CAwAUR8EBAIqj4AAAxVFwAIDiDOhTVGuuuWaaP/DAA7Xs9NNPT8eedtppab7nnnum+Re/+MVatssuuzSsEOiJW265pZY1nTp57bXX0vyTn/xkmu+3334LvC7olOeffz7NR44cmeZNJ6YyX/3qV9N8yy237PEcJXIFBwAojoIDABRHwQEAiqPgAADFqZo+3vwNb/ki9LH65513nz3RCw899FCaf+QjH6llM2bMaGvuyy67LM3333//tubp5+yJLpg1a1aa77DDDml+11139Xjupp/B2eMevvzlL6djzzjjjDRfaqmleryOAaxxT7iCAwAUR8EBAIqj4AAAxVFwAIDiKDgAQHEG9KMagIHll7/8ZZq3c2LqiCOOSPOmRzVAbzWdRjr77LPTfMcdd6xlf/nLX9KxyyyzTJp/97vfrWVf+9rX0rGLL754mg92ruAAAMVRcACA4ig4AEBxFBwAoDgKDgBQHM+ioj/z3J3C3H777Wl+wAEH1LJjjjkmHdt0Wmro0KELvrCBw56A+XkWFQAweCg4AEBxFBwAoDgKDgBQHAUHACiOU1T0Z06MwPzsCZifU1QAwOCh4AAAxVFwAIDiKDgAQHEUHACgOAoOAFAcBQcAKI6CAwAUR8EBAIqj4AAAxXm7RzUAAAw4ruAAAMVRcACA4ig4AEBxFBwAoDgKDgBQHAUHACiOggMAFEfBAQCKo+AAAMVRcACA4ig4AEBxFBwAoDgKDgBQHAUHACiOggMAFEfB6QNVVS1bVdUZVVVNr6pqVlVVd1ZVtWm31wXdYk/A/KqqGlFV1fiqqv5SVdWrVVVNqarq491eV0kUnL5xcUSMiojREfF3EXFTRPy6qqpVu7oq6B57At5QVdXyEXFHRFQRsXNErBcRh0bEc91cV2mqVqvV7TUUpaqqpSJiZkTs1Wq1fvE3+e8i4vpWq/Wdri0OusCegPlVVXVyRHy81Wpt0e21lMwVnM5bNCKGRMSrb8pnRcSWC3850HX2BMzvkxExqaqqn1ZV9VxVVfdWVXVIVVVVtxdWEgWnw1qt1syIuCsivlNV1apVVQ2pqupzEfHRiBjR3dXBwmdPQM17I2JsRDwa8351+48RcUpEfLWbiyqNX1H1gaqq1oqISyNiq4iYGxG/j4iHI2KTVqu1XjfXBt1gT8D/qqrqtYi4p9Vqbf432ckRsYf90Dmu4PSBVqv1p1ar9fGIeEdErNZqtT4cEYvFvLYOg449AfN5OiKmvCmbGhGrd2EtxVJw+lCr1fqfVqv1dFVV74x5lyF/8Xb/HyiZPQERMe8E1fvflK0TEdO7sJZi+RVVH6iqalTMK48PRsTaEXFqzLvB8mOtVmtON9cG3WBPwP964zOg7oyI4yPipxHxwZj3UQpHt1qtc7q4tKK4gtM3louIs2PeN/PLI+L2iBjlGzmDmD0Bb2i1WnfHvJNU+0TE5Ij4PxFxbESc2811lcYVHACgOK7gAADFUXAAgOIoOABAcRQcAKA4Cg4AUJxF3+Z1R6zopv744Dl7gm6yJ2B+jXvCFRwAoDgKDgBQHAUHACiOggMAFEfBAQCKo+AAAMVRcACA4ig4AEBxFBwAoDgKDgBQnLd7VAMA0IYpU6bUspEjR6Zjn3rqqTQ/4YQTatl3vvOd3i1skHEFBwAojoIDABRHwQEAiqPgAADFUXAAgOJUrVbrrV5/yxehj1XdXkDCnqCb7Il+5Gtf+1qa33bbbbVs8uTJvX6/M888M83HjBnT67kHsMY94QoOAFAcBQcAKI6CAwAUR8EBAIqj4AAAxXGKiv7MiRGYnz3RBX/+85/TfLXVVkvzIUOG1LLVV189HfupT32qx+956qmnpmNHjBiR5oOEU1QAwOCh4AAAxVFwAIDiKDgAQHEUHACgOIt2ewEA0B/cd999af65z32u13PfdNNNab7WWmv1em5yruAAAMVRcACA4ig4AEBxFBwAoDhuMoZB6tprr03z2267Lc2vuuqqNJ8+fXot23TTTdOxxx13XJp/4hOfSHPoK9mjEJpuJn7wwQfbmvvggw+uZYP8cQpd4QoOAFAcBQcAKI6CAwAUR8EBAIqj4AAAxalardZbvf6WL/ZXc+fOrWVTpkxJx/7kJz9J8/Hjx6f5X/7yl1rW9HdYVVWaf/Ob36xlJ510Ujp2scUWS/NBIv8L7K4BuSeee+65WrbtttumY6dOndpn61hiiSXSPPsY+y233LLP1jGA2RMd8sgjj9Sy97///W3NseOOO6b5ddddt0BrYoE07glXcACA4ig4AEBxFBwAoDgKDgBQHAUHAChOkaeoLrvsslr25S9/uc/er91TVJlddtklzbfffvs0P/TQQ3s89wDmxEiHfPSjH61lkyZNSscOHTo0zffbb78033PPPWvZeeedl479wx/+0OP3zPZxRMTf//3fp/kgYU90yDe+8Y1aduaZZ7Y1x7/+67+m+a677rpAa2KBOEUFAAweCg4AUBwFBwAojoIDABSnyJuM99lnn1o2YcKEtubYfPPN03ybbbapZU1/h7/5zW/S/K677mprLZkrr7wyzffee+9ez92PuKGyQ0aMGFHLnn322XTsxhtvnOZNNwi34+mnn07z7FEqP/7xj9Oxq622Wppff/31aT5q1KhadsoppzSssN+zJ9qUPV4nImKzzTarZU888URbc8+ZM2eB1kRHuckYABg8FBwAoDgKDgBQHAUHACiOggMAFGdAn6KaPHlymm+00Ua1rOmxCe9617vS/M4770zzphMcmVmzZqX5DjvsUMvaPVm1wQYbpPn999/f1jz9nBMjHdJfTlG1Y8cdd0zzX/3qV23NM3z48FrWdJprALAn2nT44Yen+TnnnNPjOZoevdD0qAYWKqeoAIDBQ8EBAIqj4AAAxVFwAIDiKDgAQHEW7fYCeuOkk07q9RzveMc70vyBBx5I84kTJ9aysWPHpmOXWmqpND/yyCNr2V577dW0xFTT81UY3JpO7v31r3+tZW9zgrJPzJ07N82zr+fZs2enY5vWvcwyy6T5Nddc08PVQe6ggw7q9hJYAK7gAADFUXAAgOIoOABAcRQcAKA4Cg4AUJwBfYrq1ltvTfPslEXTM6dOPPHENP/EJz6x4At7G/fcc08t68aJFsrz7//+72n+8ssv17Km57M9/vjjad50GmmNNdaoZeeff3469oUXXkjzCRMmpHmmad1Npxk33XTTHs/NwNV0svSxxx5L86YTfZn+/v15ypQpaT5y5Mg0f+qpp3o8d9OffcyYMbVs3333TcdutdVWPX6/TnIFBwAojoIDABRHwQEAiqPgAADFGdA3GQ8fPjzNn3322Vq20korpWM/9alPdXRNPZHdZNx04yS0Y5dddknzd77znbUs2ycRES+99FKa77HHHgu+sDc03bDo65/eyr6vRkT88pe/TPMhQ4b0eO5ufH2ed955tezBBx9Mx952221p3rTH2/mzN92MfdFFF9Wyn/70p+nYCy+8MM3bfURRu1zBAQCKo+AAAMVRcACA4ig4AEBxFBwAoDgD+hTVsccem+b77LNPLZs2bVo6NrsTPKL5I6eXXXbZWjZ79ux0bNOjJJo+rr4da665Zq/nYPDYe++9a9nZZ5+9UN8vIuKggw5K8+23377P1gI9teuuu6b5Jpts0uu5mx4Z0fSYkhNOOKGWzZw5Mx3bzqmoiIjll1++lq244orp2KaTj9mjMWbMmJGO/cpXvpLmTSehP/axj6V5u1zBAQCKo+AAAMVRcACA4ig4AEBxFBwAoDgD+hRV03OkNthgg1o2ZcqUdOzBBx+c5qeddlqaL7nkkrVszpw56dipU6emeSest956fTY35TnzzDNr2ZZbbpmO/d3vfpfma6yxRppn+7DpRMZzzz3XtMReGzNmTJ/NzeAwceLENG/aE6NGjerx3E1jH3300R7P0WSrrbZK84033jjNs72/5557tvWe2emvptNSTaerXnnllbbes12u4AAAxVFwAIDiKDgAQHEUHACgOAP6JuMm3//+92vZt7/97XRs083HDz/8cI/fr+mjrKuq6vEc7fKoBnore6TJW+Wd0HRTYdMeynz+859Pc3uC/uK8886rZc8880yv573uuuvSfP3110/z1Vdfvdfv2WSvvfaqZUcffXQ6tukm477mCg4AUBwFBwAojoIDABRHwQEAiqPgAADFKfIU1S677FLLPvzhD6djL7/88rbmvueee2rZhz70obbmeOSRR2rZRRdd1NYcO+20U1vjoT84//zz07ydE4d9eTqRgavpe+LYsWPT/Kyzzur13J04Qdt0+u+qq66qZZtsskmP5+2U66+/Ps133nnnHs/R9GdseqRLp7iCAwAUR8EBAIqj4AAAxVFwAIDiKDgAQHGKPEWVGT58eJofeeSRC3klETfddFMtu/jii9uaY4011ujUcmCheeyxx7q9BAaZ7JlJERE/+9nPatnzzz/f1txz585N8yFDhtSyphND48ePT/OFfWIqe35WRMSNN96Y5gPhz+gKDgBQHAUHACiOggMAFEfBAQCKo+AAAMUZNKeo+pNhw4bVsmWXXTYdO3PmzDRveoZWN06FwZtNnjw5za+++uo093wp+spWW22V5tkpqm233bbP1vHSSy+l+cSJE9N8lVVWqWVNz3/qxP555pln0rzpeVtrr712Lfvxj3+cjt1ss80WeF294QoOAFAcBQcAKI6CAwAUR8EBAIrjJuMuyD6e+j3veU869v777+/r5UDH3XDDDX0298EHH9xnczN4rLvuurXs0EMPTcf+4he/SPNp06b1+P1ef/31ND/99NN7nLfzaIh27brrrmk+atSoND/ooIN6/Z59zRUcAKA4Cg4AUBwFBwAojoIDABRHwQEAiuMUFbDQNH3sezuWXnrpDqyEwW6llVaqZaeddlo69rOf/Wyab7rpph1d04JqOlm4yy679HiO7HRvRMSKK664QGvqD1zBAQCKo+AAAMVRcACA4ig4AEBxFBwAoDhOUfUTTadLOnHqBBa2559/Ps2rqmor7+1Y6ISmE0Z//etfF/JKaIcrOABAcRQcAKA4Cg4AUBwFBwAojpuM+4lO3HwJ/cX48eN7PUfTjZ1rrrlmr+cGyucKDgBQHAUHACiOggMAFEfBAQCKo+AAAMUp8hTV7Nmza9mLL76Yjh0xYkRfL6dPOElC6YYNG5bmyy677EJeCTAQuYIDABRHwQEAiqPgAADFUXAAgOIoOABAcYo8RbXIIvXetuSSS3ZhJX1njTXW6PYSoNGYMWPS/Pjjj+/xHAcffHCHVgMMRq7gAADFUXAAgOIoOABAcRQcAKA4Cg4AUJyq1Wq91etv+SKdc+CBB6b5pZdemuZz587ty+X0F1W3F5CwJ+gmewLm17gnXMEBAIqj4AAAxVFwAIDiKDgAQHHcZEx/5oZKmJ89AfNzkzEAMHgoOABAcRQcAKA4Cg4AUBwFBwAoztudogIAGHBcwQEAiqPgAADFUXAAgOIoOABAcRQcAKA4Cg4AUBwFBwAojoIDABRHwQEAiqPgAADFUXAAgOIoOABAcRQcAKA4Cg4AUBwFBwAojoLTB6qqGlFV1fiqqv5SVdWrVVVNqarq491eF3RTVVVjq6qa9sae+F1VVR/r9pqgG6qqGlJV1Yl/sx+mVVV1UlVVi3Z7bSXxl9lhVVUtHxF3RMTtEbFzRPwlIt4bEc91c13QTVVVfToi/jEixsa8vTE2Iq6vqmr9Vqv1eFcXBwvfP0TEVyNidEQ8EBEbRcT4iJgdESd2cV1FqVqtVrfXUJSqqk6OiI+3Wq0tur0W6C+qqpoUEfe3Wq0D/yZ7JCKubrVa3+7eymDhq6rq2oh4odVqjf6bbHxEDGu1Wrt0b2Vl8SuqzvtkREyqquqnVVU9V1XVvVVVHVJVVdXthUE3VFW1eERsEhE3vemlmyJi84W/Iui62yNim6qq1o2IqKpq/YjYNiKu6+qqCqPgdN57Y97l90cjYlTMuyx/Ssy7HAmD0YoRMSQinn1T/mxErLLwlwNd94OI+ElETKmqak5E/N+IGN9qtc7t7rLK4h6czlskIu75m8vuf6iq6n0xr+Cc3b1lAdBPfDoi9o+Iz8S8cvOBiPjHqqqmtVqtS7q6soK4gtN5T0fElDdlUyNi9S6sBfqD5yNibkSs/KZ85Yh4ZuEvB7ru1Ij4UavVurLVaj3QarV+EhGnRYT70TpIwem8OyLi/W/K1omI6V1YC3Rdq9V6LSJ+FxE7vOmlHSLizoW/Iui6pWNe6f9bc8PP5I7yK6rOOz0i7qyq6piI+GlEfDAiDouIo7u6Kuiu0yLiJ1VV/WfM+5eAgyPiXRFxfldXBd0xMSKOqqpqWsz7FdUHI+KIiLi8q6sqjGPifaCqqp0j4uSYdyXn8Zh3781ZLX/ZDGJVVY2NiG9FxIiImBwRX2+1Wrd1d1Ww8FVVtcZU9MAAAA2USURBVGzM+7ybPSJieMy7teHKiDih1Wq92s21lUTBAQCK4/d9AEBxFBwAoDgKDgBQHAUHACiOggMAFOftPgfHESu6qT8+oNSeoJvsCZhf455wBQcAKI6CAwAUR8EBAIqj4AAAxVFwAIDiKDgAQHEUHACgOAoOAFAcBQcAKI6CAwAU5+0e1cBC8vDDD6f5IYcckuavvfZamt9yyy2dWhIADFiu4AAAxVFwAIDiKDgAQHEUHACgOAoOAFAcp6i64Kabbqpln//859Ox7373u9P8iiuu6OiaAKAkruAAAMVRcACA4ig4AEBxFBwAoDgKDgBQnKrVar3V62/5Im9t8uTJab7ddtvVsqZnS02cODHNt9xyywVf2MBRdXsBCXuCbrInBqi5c+em+bXXXpvm48aNq2V//OMf07Enn3xymn/hC1/o2eIGtsY94QoOAFAcBQcAKI6CAwAUR8EBAIqj4AAAxXGKqgMeffTRNN9iiy3SfNasWbWs6U76QXJaqokTIwNAdtqj6cTIGWeckeZPP/10Ldtvv/3SsR/60IfS/IgjjmhaYknsiQEgO+104IEHpmNvvfXWNM9+NldV/o9/yJAhaf6Tn/wkzT/84Q/Xsve+973p2AHAKSoAYPBQcACA4ig4AEBxFBwAoDhuMu6A448/Ps2/973vpfnBBx9cy84777xOLqkUbqjsgpkzZ6b5WmutlebPP/98Xy6nx/bdd980Hz9+fC1bbLHF+no5fcWe6EceeeSRNB85cmQte/LJJ9OxTQdJpk6dWsuee+65NlbXbOmll65lJ554Yjr261//ekfesw+5yRgAGDwUHACgOAoOAFAcBQcAKI6CAwAUxymqNv32t7+tZR/72MfSsdttt12a/+xnP6tlQ4cO7d3CyuTESB96/PHH03zUqFFp/tBDD/XlcvrMd7/73VrWdPJxALAnuuD3v/99mjd9j3/llVdq2Te+8Y107N57753m2aN+Xn311XTsV77ylTRfZ5110vzqq6+uZb/73e/SsTfccEOab7PNNmneBU5RAQCDh4IDABRHwQEAiqPgAADFUXAAgOIs2u0F9FczZsxI82OOOaaWvf766+nYpjvbnZiiP/jTn/6U5gP1tFSTTj2/h/L953/+Z5rvvPPOaf7yyy+n+e67717LTj755HTslVdemebZ8wknTZqUjh03blyaL7XUUmm+66671rKNN944Hdv0c+zee++tZcsss0w6tltcwQEAiqPgAADFUXAAgOIoOABAcdxk3OCKK65I85tvvrmWbb/99unYPfbYo6NrggWVfcT7D3/4wz57vwsvvDDNV1hhhTS/+OKLa9kdd9yRjp05c2Zba7nxxhtr2bPPPpuOXXnllduam4HrqaeeqmX77bdfOvaFF15I89122y3Ns58fTYdRlltuuTTfaaedatno0aPTse163/veV8vWXnvtdOzkyZPTPHt8RdNji7rFFRwAoDgKDgBQHAUHACiOggMAFEfBAQCKM+hPUU2fPj3Njz322DRfb731atnpp5+ejq2qasEXBh103HHH1bLsdFGnZCdAIiJWXXXVNN9zzz1r2Wc+85l0bNNH2zeZNm1aLfuf//mftuZg4Jo9e3aaf+tb36pl2ddKRPNpqX/6p39K83YeWdC0V/rSnDlzepQNdK7gAADFUXAAgOIoOABAcRQcAKA4Cg4AUJxBf4rq0ksvTfMXX3wxzb/yla/Usg033LCja4JOmzRpUp/Nvfnmm9eyoUOH9nrevffeO80fe+yxNP/tb3/b47mbTpCNGTOmx3MwMDR97f/zP/9zLVtrrbXSsZ04LdUNr7zySpqfddZZteyhhx5KxzadfNxoo40WfGELiSs4AEBxFBwAoDgKDgBQHAUHACiOggMAFGfQnKKaMmVKmp9wwglpvu6666Z59kwfGMwOP/zwWrbsssv2et499tgjzW+99dY0b+cU1W9+85s0d4pqcFt66aXTvBunpWbNmlXLnn766XRs05449dRT0/zBBx+sZYsvvng69oILLkjz5ZZbLs37E1dwAIDiKDgAQHEUHACgOAoOAFCcQXOT8S233NLW+L322ivNl1xyyQ6spm727Nlp3vSR8ldffXWar7jiirVs//33T8d+4AMf6OHqoNluu+3W7SW07YEHHkjzxx9/PM1XX331vlwO/cTLL7/cVt7OjbaPPvpomp922mlpfs4559Syqqp6/H7tuuaaa9J85MiRffaefc0VHACgOAoOAFAcBQcAKI6CAwAUR8EBAIpT5Cmq7OOsv/3tb6dj11lnnTQ/5phjer2OV199Nc0vvPDCWnbeeeelY7OP1G5X08d4N31c/dChQ3v9npTnkEMOSfNFF12430Y+8YlPpPmZZ57Z4zmeeeaZNJ8xY8YCrYn+a4UVVkjztddeu5Y98sgj6djll1++o2taUK1Wq8/mnj59ep/N3S2u4AAAxVFwAIDiKDgAQHEUHACgOAoOAFCcIk9RvfDCC7Ws6XTExhtvnOZLLbVUj99v0qRJaf7FL34xzadOnVrLFlkk75o77LBDmjetO1vLf/zHf6Rjs7+nCKeoyA0fPjzNm752+8p1113X6zmani30yiuv9Hpu+pcNN9wwzbPvi00nBe+///40bzp11QnZz4+mE2Hjxo1L88MOOyzNsxOHTzzxRBurGxhcwQEAiqPgAADFUXAAgOIoOABAcYq8yfiGG27o8diRI0emedPNhhdddFEtO/LII9Oxr7/+eprvtNNOteyUU05Jx2600UZp3uSoo46qZXfffXc6dvHFF29rbijFZpttluZrrbXWQl4J3bLyyivXsquuuiod2/S4m2222abH7/fud787zc8///w0zx5J8uMf/zgde/rpp6f5tGnTera4QrmCAwAUR8EBAIqj4AAAxVFwAIDiKDgAQHGKPEXVjqaP8T7nnHPS/Fvf+lYtW3755dOxP/rRj9L8gAMO6OHqIubMmZPmX/va19L8sssuq2XHHXdcOnbVVVft8TpgYXv++efTvOlESztWW221NB82bFiv52bguvPOO9N89913b2ue7OvrxhtvTMeuu+66PZ53t912S/OmRzh86Utf6vXcA5krOABAcRQcAKA4Cg4AUBwFBwAojoIDABRn0J+iuvzyy9P82muvTfPsxNTEiRPTsVtuuWWP13Hfffel+Xe/+900v+aaa9L8wAMPrGVHHHFEj9dBmbbddttadtttt7U1R9P47HTIqFGj2po7c9hhh6V5015pR/b3weDy5JNP1rLPfOYz6dgZM2ak+d57753m2SncFVdcsY3V5ZpOSzX51a9+1eOxSy65ZLvL6fdcwQEAiqPgAADFUXAAgOIoOABAcRQcAKA4VavVeqvX3/LF/mrq1Km1bP311+/I3Pvvv38tGzduXDr2+uuvT/Mzzjijlk2ZMiUdu9JKK6X54YcfnuaHHnpoLVtsscXSsQNA1e0FJAbknpg2bVot23777Xs89q0svvjiteyEE05Ix44cOTLN/+3f/q2WnXLKKenYpuezNcme/XbBBRekYxdZpN//O5890aZZs2alefa9fMKECenYpp8fd999d5ovtdRSPVxdZ5x77rlp3nSCNjsN3HQ6ceWVV17whS0cjXui3+9mAIB2KTgAQHEUHACgOAoOAFCcIm8ynjt3bi079thj07Hf//7325o7u2F3iSWWSMf+93//d4/n3WeffdK86Wbij370oz2eewBzQ2UfOv7449O86QbhThg2bFiav/DCC332nmeffXYtGzt2bJ+9Xx+zJ9rU9IiRrbfeusdzND3S53Of+9yCLGmB/f73v0/zrbbaKs2zn4UR+aOItttuuwVfWHe5yRgAGDwUHACgOAoOAFAcBQcAKI6CAwAUZ9FuL6AvDBkypJaddNJJ6dgRI0akedNjFh555JFaln3sdUTEpz71qTTffPPNe5RF5H8W6IQDDzwwzS+++OI0f+qpp3r9nn15Wip7JENExEEHHdRn70n/t+ii+Y+57Htr06mjX//612ne9NiQ3XffvYera3baaafVsh/84Afp2KafE+eff36aD+ATU21xBQcAKI6CAwAUR8EBAIqj4AAAxVFwAIDiFPksKorhuTtdMGnSpDTvL88/e/e7353mv/rVr9L8/e9/f18uZ2GzJzokexbbiSeemI59m5+TfSJ7z+xZiBERF110UZqPHj26o2vqpzyLCgAYPBQcAKA4Cg4AUBwFBwAojpuM6c/cUNkFr732Wpp/4QtfSPObb765lr366qvp2BkzZqR5dvPkmmuumY79+c9/nubrrbdemhfGnuhDEyZMaCt/4oknejz39OnT03zLLbdM8+xm+j322CMd218OAHSJm4wBgMFDwQEAiqPgAADFUXAAgOIoOABAcZyioj9zYmSAmjp1aprvsMMOaf6lL32plp1wwgkdXVMh7AmYn1NUAMDgoeAAAMVRcACA4ig4AEBxFBwAoDhOUdGfOTEC87MnYH5OUQEAg4eCAwAUR8EBAIqj4AAAxVFwAIDiKDgAQHEUHACgOAoOAFAcBQcAKI6CAwAUR8EBAIqj4AAAxVFwAIDiKDgAQHEUHACgOAoOAFCcqtVqdXsNAAAd5QoOAFAcBQcAKI6CAwAUR8EBAIqj4AAAxVFwAIDi/D8IKU3QZ3DxRgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create train and val splits directly from the pandas dataframes (to preserve one dimensional data)\n"
      ],
      "metadata": {
        "id": "nxYX1WJmhdHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(train_df.to_numpy(), train_labels_df.to_numpy(), test_size=0.2, random_state=42)\n",
        "x_train = tf.expand_dims(x_train, axis=-1)\n",
        "x_val = tf.expand_dims(x_val, axis=-1)\n",
        "len(x_train), len(y_train), len(x_val), len(y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTVg5XOHnHpS",
        "outputId": "ad2ea36b-857b-40fe-bb99-1f9efe189e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33600, 33600, 8400, 8400)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(y_train)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up2uSYgEpIr7",
        "outputId": "ee428ebb-94d7-45e0-ea7e-b6715922d651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        6\n",
              "1        5\n",
              "2        3\n",
              "3        4\n",
              "4        7\n",
              "        ..\n",
              "33595    9\n",
              "33596    9\n",
              "33597    2\n",
              "33598    6\n",
              "33599    0\n",
              "Name: 0, Length: 33600, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encode Labels\n",
        "y_train_one_hot = pd.get_dummies(pd.DataFrame(y_train)[0]).to_numpy()\n",
        "y_val_one_hot = pd.get_dummies(pd.DataFrame(y_val)[0]).to_numpy()"
      ],
      "metadata": {
        "id": "XvjaEHy5nKQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn numpy arrays into tensorflow Datasets\n",
        "train_ds_unoptimized = tf.data.Dataset.from_tensor_slices((x_train, y_train_one_hot))\n",
        "val_ds_unoptimized = tf.data.Dataset.from_tensor_slices((x_val, y_val_one_hot))\n",
        "train_ds = train_ds_unoptimized.batch(32, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds_unoptimized.batch(32, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKh_-GNRpsm_",
        "outputId": "e9e81198-cead-4420-94fe-a50896a0b19e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset element_spec=(TensorSpec(shape=(32, 784, 1), dtype=tf.int64, name=None), TensorSpec(shape=(32, 10), dtype=tf.uint8, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start modelling experiments\n",
        "\n",
        "1. Baseline (SVC Classifier as per https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
        "2. Simple Dense Model (Two hidden layers, 10 neurons each)"
      ],
      "metadata": {
        "id": "Xap5Q7C-T1lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Baseline SVC Classifier\n",
        "Multiclass in this case with a \"one-versus-one\" approach"
      ],
      "metadata": {
        "id": "fg4nKTIqhGhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "# Create SVC Classifier\n",
        "\n",
        "model_0 = svm.SVC(decision_function_shape='ovo')\n",
        "model_0.fit(tf.squeeze(x_train), y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukwwNHtihSBI",
        "outputId": "eb9f882e-87da-4629-e9fb-950d58c434c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(decision_function_shape='ovo')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How accurate is the SVC Classifier\n",
        "model_0_results = model_0.score(tf.squeeze(x_val), y_val)\n",
        "print(f\"Baseline Accuracy: {model_0_results*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a0Vu-ruh36E",
        "outputId": "f46390e2-393c-438d-cc4e-830bd8c0a1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy: 97.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Simple Dense Model\n",
        "\n",
        "We'll make a very basic Dense model with a normalization layer to get values from 0-255 to 0-1"
      ],
      "metadata": {
        "id": "DBuwr7wRjiR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  layers.Rescaling(scale=1/255.),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(10, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_1.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDHgrCvhm3FN",
        "outputId": "3614806f-5b07-4e78-f00e-7305ea98bab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 7s 3ms/step - loss: 0.6567 - accuracy: 0.8084 - val_loss: 0.3556 - val_accuracy: 0.9011\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.3112 - accuracy: 0.9107 - val_loss: 0.3067 - val_accuracy: 0.9138\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2745 - accuracy: 0.9213 - val_loss: 0.2862 - val_accuracy: 0.9188\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 9s 9ms/step - loss: 0.2539 - accuracy: 0.9277 - val_loss: 0.2745 - val_accuracy: 0.9224\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.2395 - accuracy: 0.9325 - val_loss: 0.2675 - val_accuracy: 0.9253\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2285 - accuracy: 0.9363 - val_loss: 0.2619 - val_accuracy: 0.9269\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2196 - accuracy: 0.9387 - val_loss: 0.2581 - val_accuracy: 0.9289\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2123 - accuracy: 0.9406 - val_loss: 0.2556 - val_accuracy: 0.9288\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2063 - accuracy: 0.9420 - val_loss: 0.2537 - val_accuracy: 0.9293\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2011 - accuracy: 0.9432 - val_loss: 0.2524 - val_accuracy: 0.9292\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1967 - accuracy: 0.9446 - val_loss: 0.2517 - val_accuracy: 0.9299\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1927 - accuracy: 0.9454 - val_loss: 0.2506 - val_accuracy: 0.9292\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1890 - accuracy: 0.9466 - val_loss: 0.2505 - val_accuracy: 0.9305\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1855 - accuracy: 0.9475 - val_loss: 0.2500 - val_accuracy: 0.9303\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1824 - accuracy: 0.9483 - val_loss: 0.2498 - val_accuracy: 0.9309\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1796 - accuracy: 0.9490 - val_loss: 0.2497 - val_accuracy: 0.9308\n",
            "Epoch 17/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1771 - accuracy: 0.9494 - val_loss: 0.2499 - val_accuracy: 0.9303\n",
            "Epoch 18/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1748 - accuracy: 0.9504 - val_loss: 0.2502 - val_accuracy: 0.9302\n",
            "Epoch 19/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1725 - accuracy: 0.9509 - val_loss: 0.2507 - val_accuracy: 0.9303\n",
            "Epoch 20/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1704 - accuracy: 0.9515 - val_loss: 0.2511 - val_accuracy: 0.9305\n",
            "Epoch 21/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1685 - accuracy: 0.9519 - val_loss: 0.2520 - val_accuracy: 0.9307\n",
            "Epoch 22/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1666 - accuracy: 0.9522 - val_loss: 0.2526 - val_accuracy: 0.9302\n",
            "Epoch 23/100\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1648 - accuracy: 0.9531 - val_loss: 0.2533 - val_accuracy: 0.9308\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f08fa463b20>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results = model_1.evaluate(val_ds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX4APYdps1k3",
        "outputId": "a1a97fad-6dba-4929-bc21-aaa994946579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 2ms/step - loss: 0.2497 - accuracy: 0.9308\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2497483491897583, 0.9308205842971802]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3 : More Complex Dense Model\n",
        "We'll add two more Dense layers to model 2 and increase the number of neurons to 16 per"
      ],
      "metadata": {
        "id": "k555d0z3v2tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "  layers.Rescaling(scale=1/255.),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(16, activation=\"relu\"),\n",
        "  layers.Dense(16, activation=\"relu\"),\n",
        "  layers.Dense(16, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_2.fit(train_ds,\n",
        "            batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBTlA_ZCEjy2",
        "outputId": "b0bae3d3-aa67-4cf3-cc68-4cfd59fec5f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 5s 4ms/step - loss: 0.5803 - accuracy: 0.8233 - val_loss: 0.3227 - val_accuracy: 0.9054\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 5s 4ms/step - loss: 0.2679 - accuracy: 0.9227 - val_loss: 0.2699 - val_accuracy: 0.9181\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.2207 - accuracy: 0.9367 - val_loss: 0.2473 - val_accuracy: 0.9260\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1944 - accuracy: 0.9446 - val_loss: 0.2343 - val_accuracy: 0.9308\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1751 - accuracy: 0.9499 - val_loss: 0.2268 - val_accuracy: 0.9334\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1608 - accuracy: 0.9536 - val_loss: 0.2205 - val_accuracy: 0.9371\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1493 - accuracy: 0.9563 - val_loss: 0.2168 - val_accuracy: 0.9386\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1395 - accuracy: 0.9586 - val_loss: 0.2145 - val_accuracy: 0.9391\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1313 - accuracy: 0.9611 - val_loss: 0.2140 - val_accuracy: 0.9383\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1238 - accuracy: 0.9637 - val_loss: 0.2090 - val_accuracy: 0.9419\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1178 - accuracy: 0.9658 - val_loss: 0.2071 - val_accuracy: 0.9418\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1123 - accuracy: 0.9676 - val_loss: 0.2101 - val_accuracy: 0.9429\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1067 - accuracy: 0.9691 - val_loss: 0.2116 - val_accuracy: 0.9420\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1021 - accuracy: 0.9704 - val_loss: 0.2183 - val_accuracy: 0.9419\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0980 - accuracy: 0.9717 - val_loss: 0.2216 - val_accuracy: 0.9405\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0947 - accuracy: 0.9726 - val_loss: 0.2237 - val_accuracy: 0.9401\n",
            "Epoch 17/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0913 - accuracy: 0.9739 - val_loss: 0.2236 - val_accuracy: 0.9412\n",
            "Epoch 18/100\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.0881 - accuracy: 0.9751 - val_loss: 0.2265 - val_accuracy: 0.9398\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f08fa2708e0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results = model_2.evaluate(val_ds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dW4P1xuEtK6",
        "outputId": "11e2dd16-af5a-49bd-da8d-bde2d6d76a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 2ms/step - loss: 0.2071 - accuracy: 0.9418\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20710110664367676, 0.9417939186096191]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdfZq4_jGVBd",
        "outputId": "f13f0790-303a-4ae7-9443-04f404fdb4d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset element_spec=(TensorSpec(shape=(32, 784, 1), dtype=tf.int64, name=None), TensorSpec(shape=(32, 10), dtype=tf.uint8, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4 - CNN\n",
        "\n",
        "Create a model with convolutional layers"
      ],
      "metadata": {
        "id": "Sywk0AkYFj5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_3 = tf.keras.Sequential([\n",
        "  layers.Rescaling(scale=1/255.),\n",
        "  layers.Conv1D(filters=8, kernel_size=3, activation=\"relu\", name=\"conv_1\"),\n",
        "  layers.Conv1D(filters=8, kernel_size=3, activation=\"relu\", name=\"conv_2\"),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_3.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37AOyw5NFv-c",
        "outputId": "ac62435f-c087-4f3c-fcf6-e3bd1b7bbe33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 7s 4ms/step - loss: 0.3184 - accuracy: 0.9091 - val_loss: 0.2009 - val_accuracy: 0.9414\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1668 - accuracy: 0.9511 - val_loss: 0.1692 - val_accuracy: 0.9470\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1356 - accuracy: 0.9601 - val_loss: 0.1611 - val_accuracy: 0.9495\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1168 - accuracy: 0.9658 - val_loss: 0.1581 - val_accuracy: 0.9518\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1029 - accuracy: 0.9703 - val_loss: 0.1591 - val_accuracy: 0.9530\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0915 - accuracy: 0.9732 - val_loss: 0.1632 - val_accuracy: 0.9510\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0815 - accuracy: 0.9765 - val_loss: 0.1699 - val_accuracy: 0.9507\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 7s 6ms/step - loss: 0.0726 - accuracy: 0.9794 - val_loss: 0.1783 - val_accuracy: 0.9505\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0639 - accuracy: 0.9826 - val_loss: 0.1882 - val_accuracy: 0.9487\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0562 - accuracy: 0.9849 - val_loss: 0.2019 - val_accuracy: 0.9491\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0484 - accuracy: 0.9873 - val_loss: 0.2161 - val_accuracy: 0.9488\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f08fa0b5460>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results = model_3.evaluate(val_ds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XYzRKUBGDyn",
        "outputId": "f8b7640e-607a-4492-a107-7f935ef447de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 3ms/step - loss: 0.1581 - accuracy: 0.9518\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1581019163131714, 0.9518129825592041]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5 - More complex CNN with Dropout and Max Pooling\n"
      ],
      "metadata": {
        "id": "feRS6qV8QhkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_4 = tf.keras.Sequential([\n",
        "  layers.Rescaling(scale=1/255.),\n",
        "  layers.Conv1D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool1D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Conv1D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool1D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(256, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_4.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_4.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNxeT-mPOzB2",
        "outputId": "6890b749-cdf6-4aa2-d542-da02bf7985e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 7s 5ms/step - loss: 0.3333 - accuracy: 0.8960 - val_loss: 0.1491 - val_accuracy: 0.9536\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.1518 - accuracy: 0.9519 - val_loss: 0.1085 - val_accuracy: 0.9661\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.1159 - accuracy: 0.9628 - val_loss: 0.0967 - val_accuracy: 0.9673\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0950 - accuracy: 0.9695 - val_loss: 0.0811 - val_accuracy: 0.9699\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0804 - accuracy: 0.9741 - val_loss: 0.0840 - val_accuracy: 0.9703\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0684 - accuracy: 0.9779 - val_loss: 0.0848 - val_accuracy: 0.9705\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0606 - accuracy: 0.9804 - val_loss: 0.0669 - val_accuracy: 0.9764\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0531 - accuracy: 0.9822 - val_loss: 0.0634 - val_accuracy: 0.9785\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0485 - accuracy: 0.9844 - val_loss: 0.0695 - val_accuracy: 0.9766\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0450 - accuracy: 0.9846 - val_loss: 0.0629 - val_accuracy: 0.9804\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0422 - accuracy: 0.9856 - val_loss: 0.0793 - val_accuracy: 0.9754\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 0.0646 - val_accuracy: 0.9797\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0360 - accuracy: 0.9877 - val_loss: 0.0664 - val_accuracy: 0.9797\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0318 - accuracy: 0.9897 - val_loss: 0.0654 - val_accuracy: 0.9806\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0327 - accuracy: 0.9880 - val_loss: 0.0644 - val_accuracy: 0.9798\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0317 - accuracy: 0.9892 - val_loss: 0.0555 - val_accuracy: 0.9820\n",
            "Epoch 17/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 0.0640 - val_accuracy: 0.9802\n",
            "Epoch 18/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.0579 - val_accuracy: 0.9820\n",
            "Epoch 19/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0713 - val_accuracy: 0.9807\n",
            "Epoch 20/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.0593 - val_accuracy: 0.9834\n",
            "Epoch 21/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.0647 - val_accuracy: 0.9823\n",
            "Epoch 22/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.0612 - val_accuracy: 0.9808\n",
            "Epoch 23/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0231 - accuracy: 0.9915 - val_loss: 0.0617 - val_accuracy: 0.9831\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f08d76b0190>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_results = model_4.evaluate(val_ds)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeHrxRWyPsu2",
        "outputId": "ebcf344b-cb62-4041-9b17-e9d58605362a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 3ms/step - loss: 0.0555 - accuracy: 0.9820\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05552900582551956, 0.9819895029067993]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 6 : LSTM"
      ],
      "metadata": {
        "id": "8LRjY_pTQpES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Let's build an LSTM model with the Functional API\n",
        "inputs = layers.Input(shape=(784, 1))\n",
        "x = layers.Rescaling(scale=1/255.)(inputs)\n",
        "# print(x.shape)\n",
        "x = layers.LSTM(128, return_sequences=True, name=\"LSTM_1\")(x) # this layer will error if the inputs are not the right shape\n",
        "x = layers.LSTM(128, name=\"LSTM_2\")(x) # using the tanh loss function results in a massive error\n",
        "# print(x.shape)\n",
        "# Add another optional dense layer (you could add more of these to see if they improve model performance)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "output = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model_5 = tf.keras.Model(inputs=inputs, outputs=output, name=\"model_5_lstm\")\n",
        "\n",
        "# Compile the model\n",
        "model_5.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_5.fit(train_ds,\n",
        "            batch_size=32,\n",
        "            steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ_4F3uTQta5",
        "outputId": "ac763c86-79f3-4f10-cdc3-a31907ea7a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 12s 174ms/step - loss: 2.3032 - accuracy: 0.1074 - val_loss: 2.3040 - val_accuracy: 0.0781\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 2.3026 - accuracy: 0.1094 - val_loss: 2.2963 - val_accuracy: 0.1289\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 2.3079 - accuracy: 0.1182 - val_loss: 2.2940 - val_accuracy: 0.1211\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 2s 74ms/step - loss: 2.2992 - accuracy: 0.1133 - val_loss: 2.2532 - val_accuracy: 0.2344\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 2s 73ms/step - loss: 2.2075 - accuracy: 0.1338 - val_loss: 2.0112 - val_accuracy: 0.1953\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 2.0421 - accuracy: 0.2383 - val_loss: 1.9259 - val_accuracy: 0.3477\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 2s 74ms/step - loss: 1.9415 - accuracy: 0.2842 - val_loss: 1.7886 - val_accuracy: 0.3516\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 2s 74ms/step - loss: 1.8236 - accuracy: 0.2988 - val_loss: 1.6951 - val_accuracy: 0.3672\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 2s 71ms/step - loss: 1.7489 - accuracy: 0.3320 - val_loss: 1.6379 - val_accuracy: 0.4219\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 2s 76ms/step - loss: 1.7809 - accuracy: 0.3115 - val_loss: 1.6103 - val_accuracy: 0.4492\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 2s 73ms/step - loss: 1.8136 - accuracy: 0.2949 - val_loss: 1.7783 - val_accuracy: 0.2930\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 1.7652 - accuracy: 0.3184 - val_loss: 1.6067 - val_accuracy: 0.4531\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 2s 73ms/step - loss: 1.7175 - accuracy: 0.3232 - val_loss: 1.6218 - val_accuracy: 0.4375\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 2s 77ms/step - loss: 1.7003 - accuracy: 0.3320 - val_loss: 1.6489 - val_accuracy: 0.3984\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 2s 75ms/step - loss: 1.7221 - accuracy: 0.3604 - val_loss: 1.6283 - val_accuracy: 0.4141\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f08d79c41c0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_results = model_5.evaluate(val_ds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPF7q5o_U0ve",
        "outputId": "d9c7131c-a2fb-4eb9-be96-ea154c2ea68a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 8s 31ms/step - loss: 1.7039 - accuracy: 0.3542\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7039350271224976, 0.3542461693286896]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well that sucked, LSTMs don't seem to be helping much"
      ],
      "metadata": {
        "id": "pTWh1oYNRUg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 7 - Random Forests\n",
        "\n",
        "This will be my first time creating a random forest model, let's see how it goes. Pulling the structure from: https://www.tensorflow.org/decision_forests/tutorials/beginner_colab"
      ],
      "metadata": {
        "id": "CgMVkK4vUBhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_decision_forests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJI5rHceU67I",
        "outputId": "7e0fe977-038a-4da0-918f-47b768697700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_decision_forests in /usr/local/lib/python3.8/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (1.3.0)\n",
            "Requirement already satisfied: tensorflow~=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (2.11.0)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (3.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (1.15.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (1.21.6)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from tensorflow_decision_forests) (0.38.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (21.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (1.51.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (14.0.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (57.4.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (3.19.6)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (23.1.4)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (0.29.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (4.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (2.11.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (2.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->tensorflow_decision_forests) (2022.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow~=2.11.0->tensorflow_decision_forests) (3.0.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (5.2.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "train_ds_categorical = tf.data.Dataset.from_tensor_slices((tf.squeeze(x_train), y_train))\n",
        "val_ds_categorical = tf.data.Dataset.from_tensor_slices((tf.squeeze(x_val), y_val))\n",
        "train_ds_large_batch = train_ds_categorical.batch(1000).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds_large_batch = val_ds_categorical.batch(1000).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Specify the model.\n",
        "model_6 = tfdf.keras.RandomForestModel(verbose=2)\n",
        "\n",
        "# Train the model.\n",
        "model_6.fit(train_ds_large_batch,\n",
        "            validation_data = val_ds_large_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdB87DbYUTn8",
        "outputId": "0efbc30c-dd66-4d4f-c019-2b0a6874da1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use 2 thread(s) for training\n",
            "Use /tmp/tmp6on3prrr as temporary training directory\n",
            "Reading training dataset...\n",
            "Training tensor examples:\n",
            "Features: Tensor(\"data:0\", shape=(None, 784), dtype=int64)\n",
            "Label: Tensor(\"data_1:0\", shape=(None,), dtype=int64)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'data:0.0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice:0' shape=(None,) dtype=float32>), 'data:0.1': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_1:0' shape=(None,) dtype=float32>), 'data:0.2': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_2:0' shape=(None,) dtype=float32>), 'data:0.3': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_3:0' shape=(None,) dtype=float32>), 'data:0.4': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_4:0' shape=(None,) dtype=float32>), 'data:0.5': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_5:0' shape=(None,) dtype=float32>), 'data:0.6': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_6:0' shape=(None,) dtype=float32>), 'data:0.7': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_7:0' shape=(None,) dtype=float32>), 'data:0.8': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_8:0' shape=(None,) dtype=float32>), 'data:0.9': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_9:0' shape=(None,) dtype=float32>), 'data:0.10': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_10:0' shape=(None,) dtype=float32>), 'data:0.11': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_11:0' shape=(None,) dtype=float32>), 'data:0.12': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_12:0' shape=(None,) dtype=float32>), 'data:0.13': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_13:0' shape=(None,) dtype=float32>), 'data:0.14': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_14:0' shape=(None,) dtype=float32>), 'data:0.15': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_15:0' shape=(None,) dtype=float32>), 'data:0.16': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_16:0' shape=(None,) dtype=float32>), 'data:0.17': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_17:0' shape=(None,) dtype=float32>), 'data:0.18': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_18:0' shape=(None,) dtype=float32>), 'data:0.19': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_19:0' shape=(None,) dtype=float32>), 'data:0.20': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_20:0' shape=(None,) dtype=float32>), 'data:0.21': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_21:0' shape=(None,) dtype=float32>), 'data:0.22': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_22:0' shape=(None,) dtype=float32>), 'data:0.23': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_23:0' shape=(None,) dtype=float32>), 'data:0.24': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_24:0' shape=(None,) dtype=float32>), 'data:0.25': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_25:0' shape=(None,) dtype=float32>), 'data:0.26': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_26:0' shape=(None,) dtype=float32>), 'data:0.27': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_27:0' shape=(None,) dtype=float32>), 'data:0.28': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_28:0' shape=(None,) dtype=float32>), 'data:0.29': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_29:0' shape=(None,) dtype=float32>), 'data:0.30': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_30:0' shape=(None,) dtype=float32>), 'data:0.31': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_31:0' shape=(None,) dtype=float32>), 'data:0.32': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_32:0' shape=(None,) dtype=float32>), 'data:0.33': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_33:0' shape=(None,) dtype=float32>), 'data:0.34': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_34:0' shape=(None,) dtype=float32>), 'data:0.35': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_35:0' shape=(None,) dtype=float32>), 'data:0.36': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_36:0' shape=(None,) dtype=float32>), 'data:0.37': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_37:0' shape=(None,) dtype=float32>), 'data:0.38': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_38:0' shape=(None,) dtype=float32>), 'data:0.39': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_39:0' shape=(None,) dtype=float32>), 'data:0.40': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_40:0' shape=(None,) dtype=float32>), 'data:0.41': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_41:0' shape=(None,) dtype=float32>), 'data:0.42': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_42:0' shape=(None,) dtype=float32>), 'data:0.43': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_43:0' shape=(None,) dtype=float32>), 'data:0.44': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_44:0' shape=(None,) dtype=float32>), 'data:0.45': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_45:0' shape=(None,) dtype=float32>), 'data:0.46': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_46:0' shape=(None,) dtype=float32>), 'data:0.47': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_47:0' shape=(None,) dtype=float32>), 'data:0.48': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_48:0' shape=(None,) dtype=float32>), 'data:0.49': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_49:0' shape=(None,) dtype=float32>), 'data:0.50': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_50:0' shape=(None,) dtype=float32>), 'data:0.51': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_51:0' shape=(None,) dtype=float32>), 'data:0.52': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_52:0' shape=(None,) dtype=float32>), 'data:0.53': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_53:0' shape=(None,) dtype=float32>), 'data:0.54': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_54:0' shape=(None,) dtype=float32>), 'data:0.55': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_55:0' shape=(None,) dtype=float32>), 'data:0.56': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_56:0' shape=(None,) dtype=float32>), 'data:0.57': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_57:0' shape=(None,) dtype=float32>), 'data:0.58': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_58:0' shape=(None,) dtype=float32>), 'data:0.59': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_59:0' shape=(None,) dtype=float32>), 'data:0.60': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_60:0' shape=(None,) dtype=float32>), 'data:0.61': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_61:0' shape=(None,) dtype=float32>), 'data:0.62': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_62:0' shape=(None,) dtype=float32>), 'data:0.63': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_63:0' shape=(None,) dtype=float32>), 'data:0.64': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_64:0' shape=(None,) dtype=float32>), 'data:0.65': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_65:0' shape=(None,) dtype=float32>), 'data:0.66': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_66:0' shape=(None,) dtype=float32>), 'data:0.67': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_67:0' shape=(None,) dtype=float32>), 'data:0.68': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_68:0' shape=(None,) dtype=float32>), 'data:0.69': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_69:0' shape=(None,) dtype=float32>), 'data:0.70': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_70:0' shape=(None,) dtype=float32>), 'data:0.71': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_71:0' shape=(None,) dtype=float32>), 'data:0.72': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_72:0' shape=(None,) dtype=float32>), 'data:0.73': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_73:0' shape=(None,) dtype=float32>), 'data:0.74': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_74:0' shape=(None,) dtype=float32>), 'data:0.75': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_75:0' shape=(None,) dtype=float32>), 'data:0.76': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_76:0' shape=(None,) dtype=float32>), 'data:0.77': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_77:0' shape=(None,) dtype=float32>), 'data:0.78': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_78:0' shape=(None,) dtype=float32>), 'data:0.79': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_79:0' shape=(None,) dtype=float32>), 'data:0.80': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_80:0' shape=(None,) dtype=float32>), 'data:0.81': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_81:0' shape=(None,) dtype=float32>), 'data:0.82': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_82:0' shape=(None,) dtype=float32>), 'data:0.83': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_83:0' shape=(None,) dtype=float32>), 'data:0.84': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_84:0' shape=(None,) dtype=float32>), 'data:0.85': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_85:0' shape=(None,) dtype=float32>), 'data:0.86': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_86:0' shape=(None,) dtype=float32>), 'data:0.87': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_87:0' shape=(None,) dtype=float32>), 'data:0.88': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_88:0' shape=(None,) dtype=float32>), 'data:0.89': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_89:0' shape=(None,) dtype=float32>), 'data:0.90': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_90:0' shape=(None,) dtype=float32>), 'data:0.91': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_91:0' shape=(None,) dtype=float32>), 'data:0.92': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_92:0' shape=(None,) dtype=float32>), 'data:0.93': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_93:0' shape=(None,) dtype=float32>), 'data:0.94': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_94:0' shape=(None,) dtype=float32>), 'data:0.95': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_95:0' shape=(None,) dtype=float32>), 'data:0.96': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_96:0' shape=(None,) dtype=float32>), 'data:0.97': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_97:0' shape=(None,) dtype=float32>), 'data:0.98': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_98:0' shape=(None,) dtype=float32>), 'data:0.99': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_99:0' shape=(None,) dtype=float32>), 'data:0.100': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_100:0' shape=(None,) dtype=float32>), 'data:0.101': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_101:0' shape=(None,) dtype=float32>), 'data:0.102': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_102:0' shape=(None,) dtype=float32>), 'data:0.103': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_103:0' shape=(None,) dtype=float32>), 'data:0.104': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_104:0' shape=(None,) dtype=float32>), 'data:0.105': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_105:0' shape=(None,) dtype=float32>), 'data:0.106': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_106:0' shape=(None,) dtype=float32>), 'data:0.107': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_107:0' shape=(None,) dtype=float32>), 'data:0.108': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_108:0' shape=(None,) dtype=float32>), 'data:0.109': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_109:0' shape=(None,) dtype=float32>), 'data:0.110': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_110:0' shape=(None,) dtype=float32>), 'data:0.111': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_111:0' shape=(None,) dtype=float32>), 'data:0.112': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_112:0' shape=(None,) dtype=float32>), 'data:0.113': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_113:0' shape=(None,) dtype=float32>), 'data:0.114': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_114:0' shape=(None,) dtype=float32>), 'data:0.115': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_115:0' shape=(None,) dtype=float32>), 'data:0.116': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_116:0' shape=(None,) dtype=float32>), 'data:0.117': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_117:0' shape=(None,) dtype=float32>), 'data:0.118': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_118:0' shape=(None,) dtype=float32>), 'data:0.119': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_119:0' shape=(None,) dtype=float32>), 'data:0.120': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_120:0' shape=(None,) dtype=float32>), 'data:0.121': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_121:0' shape=(None,) dtype=float32>), 'data:0.122': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_122:0' shape=(None,) dtype=float32>), 'data:0.123': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_123:0' shape=(None,) dtype=float32>), 'data:0.124': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_124:0' shape=(None,) dtype=float32>), 'data:0.125': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_125:0' shape=(None,) dtype=float32>), 'data:0.126': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_126:0' shape=(None,) dtype=float32>), 'data:0.127': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_127:0' shape=(None,) dtype=float32>), 'data:0.128': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_128:0' shape=(None,) dtype=float32>), 'data:0.129': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_129:0' shape=(None,) dtype=float32>), 'data:0.130': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_130:0' shape=(None,) dtype=float32>), 'data:0.131': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_131:0' shape=(None,) dtype=float32>), 'data:0.132': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_132:0' shape=(None,) dtype=float32>), 'data:0.133': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_133:0' shape=(None,) dtype=float32>), 'data:0.134': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_134:0' shape=(None,) dtype=float32>), 'data:0.135': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_135:0' shape=(None,) dtype=float32>), 'data:0.136': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_136:0' shape=(None,) dtype=float32>), 'data:0.137': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_137:0' shape=(None,) dtype=float32>), 'data:0.138': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_138:0' shape=(None,) dtype=float32>), 'data:0.139': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_139:0' shape=(None,) dtype=float32>), 'data:0.140': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_140:0' shape=(None,) dtype=float32>), 'data:0.141': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_141:0' shape=(None,) dtype=float32>), 'data:0.142': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_142:0' shape=(None,) dtype=float32>), 'data:0.143': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_143:0' shape=(None,) dtype=float32>), 'data:0.144': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_144:0' shape=(None,) dtype=float32>), 'data:0.145': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_145:0' shape=(None,) dtype=float32>), 'data:0.146': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_146:0' shape=(None,) dtype=float32>), 'data:0.147': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_147:0' shape=(None,) dtype=float32>), 'data:0.148': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_148:0' shape=(None,) dtype=float32>), 'data:0.149': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_149:0' shape=(None,) dtype=float32>), 'data:0.150': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_150:0' shape=(None,) dtype=float32>), 'data:0.151': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_151:0' shape=(None,) dtype=float32>), 'data:0.152': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_152:0' shape=(None,) dtype=float32>), 'data:0.153': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_153:0' shape=(None,) dtype=float32>), 'data:0.154': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_154:0' shape=(None,) dtype=float32>), 'data:0.155': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_155:0' shape=(None,) dtype=float32>), 'data:0.156': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_156:0' shape=(None,) dtype=float32>), 'data:0.157': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_157:0' shape=(None,) dtype=float32>), 'data:0.158': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_158:0' shape=(None,) dtype=float32>), 'data:0.159': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_159:0' shape=(None,) dtype=float32>), 'data:0.160': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_160:0' shape=(None,) dtype=float32>), 'data:0.161': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_161:0' shape=(None,) dtype=float32>), 'data:0.162': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_162:0' shape=(None,) dtype=float32>), 'data:0.163': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_163:0' shape=(None,) dtype=float32>), 'data:0.164': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_164:0' shape=(None,) dtype=float32>), 'data:0.165': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_165:0' shape=(None,) dtype=float32>), 'data:0.166': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_166:0' shape=(None,) dtype=float32>), 'data:0.167': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_167:0' shape=(None,) dtype=float32>), 'data:0.168': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_168:0' shape=(None,) dtype=float32>), 'data:0.169': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_169:0' shape=(None,) dtype=float32>), 'data:0.170': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_170:0' shape=(None,) dtype=float32>), 'data:0.171': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_171:0' shape=(None,) dtype=float32>), 'data:0.172': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_172:0' shape=(None,) dtype=float32>), 'data:0.173': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_173:0' shape=(None,) dtype=float32>), 'data:0.174': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_174:0' shape=(None,) dtype=float32>), 'data:0.175': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_175:0' shape=(None,) dtype=float32>), 'data:0.176': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_176:0' shape=(None,) dtype=float32>), 'data:0.177': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_177:0' shape=(None,) dtype=float32>), 'data:0.178': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_178:0' shape=(None,) dtype=float32>), 'data:0.179': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_179:0' shape=(None,) dtype=float32>), 'data:0.180': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_180:0' shape=(None,) dtype=float32>), 'data:0.181': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_181:0' shape=(None,) dtype=float32>), 'data:0.182': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_182:0' shape=(None,) dtype=float32>), 'data:0.183': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_183:0' shape=(None,) dtype=float32>), 'data:0.184': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_184:0' shape=(None,) dtype=float32>), 'data:0.185': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_185:0' shape=(None,) dtype=float32>), 'data:0.186': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_186:0' shape=(None,) dtype=float32>), 'data:0.187': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_187:0' shape=(None,) dtype=float32>), 'data:0.188': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_188:0' shape=(None,) dtype=float32>), 'data:0.189': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_189:0' shape=(None,) dtype=float32>), 'data:0.190': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_190:0' shape=(None,) dtype=float32>), 'data:0.191': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_191:0' shape=(None,) dtype=float32>), 'data:0.192': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_192:0' shape=(None,) dtype=float32>), 'data:0.193': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_193:0' shape=(None,) dtype=float32>), 'data:0.194': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_194:0' shape=(None,) dtype=float32>), 'data:0.195': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_195:0' shape=(None,) dtype=float32>), 'data:0.196': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_196:0' shape=(None,) dtype=float32>), 'data:0.197': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_197:0' shape=(None,) dtype=float32>), 'data:0.198': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_198:0' shape=(None,) dtype=float32>), 'data:0.199': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_199:0' shape=(None,) dtype=float32>), 'data:0.200': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_200:0' shape=(None,) dtype=float32>), 'data:0.201': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_201:0' shape=(None,) dtype=float32>), 'data:0.202': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_202:0' shape=(None,) dtype=float32>), 'data:0.203': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_203:0' shape=(None,) dtype=float32>), 'data:0.204': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_204:0' shape=(None,) dtype=float32>), 'data:0.205': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_205:0' shape=(None,) dtype=float32>), 'data:0.206': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_206:0' shape=(None,) dtype=float32>), 'data:0.207': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_207:0' shape=(None,) dtype=float32>), 'data:0.208': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_208:0' shape=(None,) dtype=float32>), 'data:0.209': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_209:0' shape=(None,) dtype=float32>), 'data:0.210': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_210:0' shape=(None,) dtype=float32>), 'data:0.211': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_211:0' shape=(None,) dtype=float32>), 'data:0.212': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_212:0' shape=(None,) dtype=float32>), 'data:0.213': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_213:0' shape=(None,) dtype=float32>), 'data:0.214': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_214:0' shape=(None,) dtype=float32>), 'data:0.215': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_215:0' shape=(None,) dtype=float32>), 'data:0.216': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_216:0' shape=(None,) dtype=float32>), 'data:0.217': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_217:0' shape=(None,) dtype=float32>), 'data:0.218': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_218:0' shape=(None,) dtype=float32>), 'data:0.219': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_219:0' shape=(None,) dtype=float32>), 'data:0.220': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_220:0' shape=(None,) dtype=float32>), 'data:0.221': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_221:0' shape=(None,) dtype=float32>), 'data:0.222': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_222:0' shape=(None,) dtype=float32>), 'data:0.223': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_223:0' shape=(None,) dtype=float32>), 'data:0.224': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_224:0' shape=(None,) dtype=float32>), 'data:0.225': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_225:0' shape=(None,) dtype=float32>), 'data:0.226': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_226:0' shape=(None,) dtype=float32>), 'data:0.227': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_227:0' shape=(None,) dtype=float32>), 'data:0.228': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_228:0' shape=(None,) dtype=float32>), 'data:0.229': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_229:0' shape=(None,) dtype=float32>), 'data:0.230': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_230:0' shape=(None,) dtype=float32>), 'data:0.231': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_231:0' shape=(None,) dtype=float32>), 'data:0.232': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_232:0' shape=(None,) dtype=float32>), 'data:0.233': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_233:0' shape=(None,) dtype=float32>), 'data:0.234': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_234:0' shape=(None,) dtype=float32>), 'data:0.235': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_235:0' shape=(None,) dtype=float32>), 'data:0.236': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_236:0' shape=(None,) dtype=float32>), 'data:0.237': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_237:0' shape=(None,) dtype=float32>), 'data:0.238': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_238:0' shape=(None,) dtype=float32>), 'data:0.239': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_239:0' shape=(None,) dtype=float32>), 'data:0.240': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_240:0' shape=(None,) dtype=float32>), 'data:0.241': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_241:0' shape=(None,) dtype=float32>), 'data:0.242': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_242:0' shape=(None,) dtype=float32>), 'data:0.243': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_243:0' shape=(None,) dtype=float32>), 'data:0.244': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_244:0' shape=(None,) dtype=float32>), 'data:0.245': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_245:0' shape=(None,) dtype=float32>), 'data:0.246': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_246:0' shape=(None,) dtype=float32>), 'data:0.247': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_247:0' shape=(None,) dtype=float32>), 'data:0.248': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_248:0' shape=(None,) dtype=float32>), 'data:0.249': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_249:0' shape=(None,) dtype=float32>), 'data:0.250': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_250:0' shape=(None,) dtype=float32>), 'data:0.251': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_251:0' shape=(None,) dtype=float32>), 'data:0.252': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_252:0' shape=(None,) dtype=float32>), 'data:0.253': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_253:0' shape=(None,) dtype=float32>), 'data:0.254': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_254:0' shape=(None,) dtype=float32>), 'data:0.255': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_255:0' shape=(None,) dtype=float32>), 'data:0.256': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_256:0' shape=(None,) dtype=float32>), 'data:0.257': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_257:0' shape=(None,) dtype=float32>), 'data:0.258': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_258:0' shape=(None,) dtype=float32>), 'data:0.259': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_259:0' shape=(None,) dtype=float32>), 'data:0.260': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_260:0' shape=(None,) dtype=float32>), 'data:0.261': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_261:0' shape=(None,) dtype=float32>), 'data:0.262': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_262:0' shape=(None,) dtype=float32>), 'data:0.263': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_263:0' shape=(None,) dtype=float32>), 'data:0.264': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_264:0' shape=(None,) dtype=float32>), 'data:0.265': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_265:0' shape=(None,) dtype=float32>), 'data:0.266': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_266:0' shape=(None,) dtype=float32>), 'data:0.267': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_267:0' shape=(None,) dtype=float32>), 'data:0.268': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_268:0' shape=(None,) dtype=float32>), 'data:0.269': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_269:0' shape=(None,) dtype=float32>), 'data:0.270': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_270:0' shape=(None,) dtype=float32>), 'data:0.271': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_271:0' shape=(None,) dtype=float32>), 'data:0.272': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_272:0' shape=(None,) dtype=float32>), 'data:0.273': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_273:0' shape=(None,) dtype=float32>), 'data:0.274': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_274:0' shape=(None,) dtype=float32>), 'data:0.275': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_275:0' shape=(None,) dtype=float32>), 'data:0.276': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_276:0' shape=(None,) dtype=float32>), 'data:0.277': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_277:0' shape=(None,) dtype=float32>), 'data:0.278': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_278:0' shape=(None,) dtype=float32>), 'data:0.279': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_279:0' shape=(None,) dtype=float32>), 'data:0.280': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_280:0' shape=(None,) dtype=float32>), 'data:0.281': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_281:0' shape=(None,) dtype=float32>), 'data:0.282': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_282:0' shape=(None,) dtype=float32>), 'data:0.283': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_283:0' shape=(None,) dtype=float32>), 'data:0.284': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_284:0' shape=(None,) dtype=float32>), 'data:0.285': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_285:0' shape=(None,) dtype=float32>), 'data:0.286': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_286:0' shape=(None,) dtype=float32>), 'data:0.287': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_287:0' shape=(None,) dtype=float32>), 'data:0.288': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_288:0' shape=(None,) dtype=float32>), 'data:0.289': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_289:0' shape=(None,) dtype=float32>), 'data:0.290': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_290:0' shape=(None,) dtype=float32>), 'data:0.291': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_291:0' shape=(None,) dtype=float32>), 'data:0.292': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_292:0' shape=(None,) dtype=float32>), 'data:0.293': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_293:0' shape=(None,) dtype=float32>), 'data:0.294': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_294:0' shape=(None,) dtype=float32>), 'data:0.295': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_295:0' shape=(None,) dtype=float32>), 'data:0.296': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_296:0' shape=(None,) dtype=float32>), 'data:0.297': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_297:0' shape=(None,) dtype=float32>), 'data:0.298': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_298:0' shape=(None,) dtype=float32>), 'data:0.299': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_299:0' shape=(None,) dtype=float32>), 'data:0.300': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_300:0' shape=(None,) dtype=float32>), 'data:0.301': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_301:0' shape=(None,) dtype=float32>), 'data:0.302': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_302:0' shape=(None,) dtype=float32>), 'data:0.303': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_303:0' shape=(None,) dtype=float32>), 'data:0.304': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_304:0' shape=(None,) dtype=float32>), 'data:0.305': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_305:0' shape=(None,) dtype=float32>), 'data:0.306': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_306:0' shape=(None,) dtype=float32>), 'data:0.307': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_307:0' shape=(None,) dtype=float32>), 'data:0.308': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_308:0' shape=(None,) dtype=float32>), 'data:0.309': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_309:0' shape=(None,) dtype=float32>), 'data:0.310': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_310:0' shape=(None,) dtype=float32>), 'data:0.311': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_311:0' shape=(None,) dtype=float32>), 'data:0.312': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_312:0' shape=(None,) dtype=float32>), 'data:0.313': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_313:0' shape=(None,) dtype=float32>), 'data:0.314': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_314:0' shape=(None,) dtype=float32>), 'data:0.315': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_315:0' shape=(None,) dtype=float32>), 'data:0.316': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_316:0' shape=(None,) dtype=float32>), 'data:0.317': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_317:0' shape=(None,) dtype=float32>), 'data:0.318': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_318:0' shape=(None,) dtype=float32>), 'data:0.319': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_319:0' shape=(None,) dtype=float32>), 'data:0.320': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_320:0' shape=(None,) dtype=float32>), 'data:0.321': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_321:0' shape=(None,) dtype=float32>), 'data:0.322': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_322:0' shape=(None,) dtype=float32>), 'data:0.323': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_323:0' shape=(None,) dtype=float32>), 'data:0.324': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_324:0' shape=(None,) dtype=float32>), 'data:0.325': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_325:0' shape=(None,) dtype=float32>), 'data:0.326': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_326:0' shape=(None,) dtype=float32>), 'data:0.327': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_327:0' shape=(None,) dtype=float32>), 'data:0.328': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_328:0' shape=(None,) dtype=float32>), 'data:0.329': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_329:0' shape=(None,) dtype=float32>), 'data:0.330': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_330:0' shape=(None,) dtype=float32>), 'data:0.331': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_331:0' shape=(None,) dtype=float32>), 'data:0.332': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_332:0' shape=(None,) dtype=float32>), 'data:0.333': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_333:0' shape=(None,) dtype=float32>), 'data:0.334': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_334:0' shape=(None,) dtype=float32>), 'data:0.335': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_335:0' shape=(None,) dtype=float32>), 'data:0.336': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_336:0' shape=(None,) dtype=float32>), 'data:0.337': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_337:0' shape=(None,) dtype=float32>), 'data:0.338': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_338:0' shape=(None,) dtype=float32>), 'data:0.339': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_339:0' shape=(None,) dtype=float32>), 'data:0.340': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_340:0' shape=(None,) dtype=float32>), 'data:0.341': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_341:0' shape=(None,) dtype=float32>), 'data:0.342': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_342:0' shape=(None,) dtype=float32>), 'data:0.343': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_343:0' shape=(None,) dtype=float32>), 'data:0.344': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_344:0' shape=(None,) dtype=float32>), 'data:0.345': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_345:0' shape=(None,) dtype=float32>), 'data:0.346': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_346:0' shape=(None,) dtype=float32>), 'data:0.347': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_347:0' shape=(None,) dtype=float32>), 'data:0.348': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_348:0' shape=(None,) dtype=float32>), 'data:0.349': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_349:0' shape=(None,) dtype=float32>), 'data:0.350': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_350:0' shape=(None,) dtype=float32>), 'data:0.351': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_351:0' shape=(None,) dtype=float32>), 'data:0.352': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_352:0' shape=(None,) dtype=float32>), 'data:0.353': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_353:0' shape=(None,) dtype=float32>), 'data:0.354': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_354:0' shape=(None,) dtype=float32>), 'data:0.355': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_355:0' shape=(None,) dtype=float32>), 'data:0.356': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_356:0' shape=(None,) dtype=float32>), 'data:0.357': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_357:0' shape=(None,) dtype=float32>), 'data:0.358': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_358:0' shape=(None,) dtype=float32>), 'data:0.359': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_359:0' shape=(None,) dtype=float32>), 'data:0.360': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_360:0' shape=(None,) dtype=float32>), 'data:0.361': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_361:0' shape=(None,) dtype=float32>), 'data:0.362': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_362:0' shape=(None,) dtype=float32>), 'data:0.363': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_363:0' shape=(None,) dtype=float32>), 'data:0.364': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_364:0' shape=(None,) dtype=float32>), 'data:0.365': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_365:0' shape=(None,) dtype=float32>), 'data:0.366': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_366:0' shape=(None,) dtype=float32>), 'data:0.367': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_367:0' shape=(None,) dtype=float32>), 'data:0.368': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_368:0' shape=(None,) dtype=float32>), 'data:0.369': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_369:0' shape=(None,) dtype=float32>), 'data:0.370': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_370:0' shape=(None,) dtype=float32>), 'data:0.371': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_371:0' shape=(None,) dtype=float32>), 'data:0.372': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_372:0' shape=(None,) dtype=float32>), 'data:0.373': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_373:0' shape=(None,) dtype=float32>), 'data:0.374': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_374:0' shape=(None,) dtype=float32>), 'data:0.375': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_375:0' shape=(None,) dtype=float32>), 'data:0.376': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_376:0' shape=(None,) dtype=float32>), 'data:0.377': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_377:0' shape=(None,) dtype=float32>), 'data:0.378': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_378:0' shape=(None,) dtype=float32>), 'data:0.379': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_379:0' shape=(None,) dtype=float32>), 'data:0.380': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_380:0' shape=(None,) dtype=float32>), 'data:0.381': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_381:0' shape=(None,) dtype=float32>), 'data:0.382': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_382:0' shape=(None,) dtype=float32>), 'data:0.383': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_383:0' shape=(None,) dtype=float32>), 'data:0.384': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_384:0' shape=(None,) dtype=float32>), 'data:0.385': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_385:0' shape=(None,) dtype=float32>), 'data:0.386': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_386:0' shape=(None,) dtype=float32>), 'data:0.387': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_387:0' shape=(None,) dtype=float32>), 'data:0.388': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_388:0' shape=(None,) dtype=float32>), 'data:0.389': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_389:0' shape=(None,) dtype=float32>), 'data:0.390': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_390:0' shape=(None,) dtype=float32>), 'data:0.391': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_391:0' shape=(None,) dtype=float32>), 'data:0.392': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_392:0' shape=(None,) dtype=float32>), 'data:0.393': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_393:0' shape=(None,) dtype=float32>), 'data:0.394': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_394:0' shape=(None,) dtype=float32>), 'data:0.395': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_395:0' shape=(None,) dtype=float32>), 'data:0.396': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_396:0' shape=(None,) dtype=float32>), 'data:0.397': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_397:0' shape=(None,) dtype=float32>), 'data:0.398': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_398:0' shape=(None,) dtype=float32>), 'data:0.399': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_399:0' shape=(None,) dtype=float32>), 'data:0.400': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_400:0' shape=(None,) dtype=float32>), 'data:0.401': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_401:0' shape=(None,) dtype=float32>), 'data:0.402': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_402:0' shape=(None,) dtype=float32>), 'data:0.403': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_403:0' shape=(None,) dtype=float32>), 'data:0.404': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_404:0' shape=(None,) dtype=float32>), 'data:0.405': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_405:0' shape=(None,) dtype=float32>), 'data:0.406': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_406:0' shape=(None,) dtype=float32>), 'data:0.407': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_407:0' shape=(None,) dtype=float32>), 'data:0.408': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_408:0' shape=(None,) dtype=float32>), 'data:0.409': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_409:0' shape=(None,) dtype=float32>), 'data:0.410': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_410:0' shape=(None,) dtype=float32>), 'data:0.411': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_411:0' shape=(None,) dtype=float32>), 'data:0.412': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_412:0' shape=(None,) dtype=float32>), 'data:0.413': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_413:0' shape=(None,) dtype=float32>), 'data:0.414': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_414:0' shape=(None,) dtype=float32>), 'data:0.415': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_415:0' shape=(None,) dtype=float32>), 'data:0.416': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_416:0' shape=(None,) dtype=float32>), 'data:0.417': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_417:0' shape=(None,) dtype=float32>), 'data:0.418': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_418:0' shape=(None,) dtype=float32>), 'data:0.419': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_419:0' shape=(None,) dtype=float32>), 'data:0.420': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_420:0' shape=(None,) dtype=float32>), 'data:0.421': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_421:0' shape=(None,) dtype=float32>), 'data:0.422': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_422:0' shape=(None,) dtype=float32>), 'data:0.423': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_423:0' shape=(None,) dtype=float32>), 'data:0.424': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_424:0' shape=(None,) dtype=float32>), 'data:0.425': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_425:0' shape=(None,) dtype=float32>), 'data:0.426': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_426:0' shape=(None,) dtype=float32>), 'data:0.427': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_427:0' shape=(None,) dtype=float32>), 'data:0.428': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_428:0' shape=(None,) dtype=float32>), 'data:0.429': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_429:0' shape=(None,) dtype=float32>), 'data:0.430': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_430:0' shape=(None,) dtype=float32>), 'data:0.431': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_431:0' shape=(None,) dtype=float32>), 'data:0.432': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_432:0' shape=(None,) dtype=float32>), 'data:0.433': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_433:0' shape=(None,) dtype=float32>), 'data:0.434': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_434:0' shape=(None,) dtype=float32>), 'data:0.435': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_435:0' shape=(None,) dtype=float32>), 'data:0.436': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_436:0' shape=(None,) dtype=float32>), 'data:0.437': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_437:0' shape=(None,) dtype=float32>), 'data:0.438': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_438:0' shape=(None,) dtype=float32>), 'data:0.439': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_439:0' shape=(None,) dtype=float32>), 'data:0.440': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_440:0' shape=(None,) dtype=float32>), 'data:0.441': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_441:0' shape=(None,) dtype=float32>), 'data:0.442': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_442:0' shape=(None,) dtype=float32>), 'data:0.443': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_443:0' shape=(None,) dtype=float32>), 'data:0.444': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_444:0' shape=(None,) dtype=float32>), 'data:0.445': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_445:0' shape=(None,) dtype=float32>), 'data:0.446': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_446:0' shape=(None,) dtype=float32>), 'data:0.447': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_447:0' shape=(None,) dtype=float32>), 'data:0.448': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_448:0' shape=(None,) dtype=float32>), 'data:0.449': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_449:0' shape=(None,) dtype=float32>), 'data:0.450': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_450:0' shape=(None,) dtype=float32>), 'data:0.451': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_451:0' shape=(None,) dtype=float32>), 'data:0.452': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_452:0' shape=(None,) dtype=float32>), 'data:0.453': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_453:0' shape=(None,) dtype=float32>), 'data:0.454': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_454:0' shape=(None,) dtype=float32>), 'data:0.455': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_455:0' shape=(None,) dtype=float32>), 'data:0.456': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_456:0' shape=(None,) dtype=float32>), 'data:0.457': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_457:0' shape=(None,) dtype=float32>), 'data:0.458': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_458:0' shape=(None,) dtype=float32>), 'data:0.459': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_459:0' shape=(None,) dtype=float32>), 'data:0.460': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_460:0' shape=(None,) dtype=float32>), 'data:0.461': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_461:0' shape=(None,) dtype=float32>), 'data:0.462': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_462:0' shape=(None,) dtype=float32>), 'data:0.463': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_463:0' shape=(None,) dtype=float32>), 'data:0.464': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_464:0' shape=(None,) dtype=float32>), 'data:0.465': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_465:0' shape=(None,) dtype=float32>), 'data:0.466': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_466:0' shape=(None,) dtype=float32>), 'data:0.467': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_467:0' shape=(None,) dtype=float32>), 'data:0.468': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_468:0' shape=(None,) dtype=float32>), 'data:0.469': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_469:0' shape=(None,) dtype=float32>), 'data:0.470': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_470:0' shape=(None,) dtype=float32>), 'data:0.471': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_471:0' shape=(None,) dtype=float32>), 'data:0.472': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_472:0' shape=(None,) dtype=float32>), 'data:0.473': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_473:0' shape=(None,) dtype=float32>), 'data:0.474': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_474:0' shape=(None,) dtype=float32>), 'data:0.475': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_475:0' shape=(None,) dtype=float32>), 'data:0.476': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_476:0' shape=(None,) dtype=float32>), 'data:0.477': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_477:0' shape=(None,) dtype=float32>), 'data:0.478': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_478:0' shape=(None,) dtype=float32>), 'data:0.479': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_479:0' shape=(None,) dtype=float32>), 'data:0.480': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_480:0' shape=(None,) dtype=float32>), 'data:0.481': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_481:0' shape=(None,) dtype=float32>), 'data:0.482': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_482:0' shape=(None,) dtype=float32>), 'data:0.483': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_483:0' shape=(None,) dtype=float32>), 'data:0.484': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_484:0' shape=(None,) dtype=float32>), 'data:0.485': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_485:0' shape=(None,) dtype=float32>), 'data:0.486': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_486:0' shape=(None,) dtype=float32>), 'data:0.487': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_487:0' shape=(None,) dtype=float32>), 'data:0.488': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_488:0' shape=(None,) dtype=float32>), 'data:0.489': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_489:0' shape=(None,) dtype=float32>), 'data:0.490': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_490:0' shape=(None,) dtype=float32>), 'data:0.491': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_491:0' shape=(None,) dtype=float32>), 'data:0.492': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_492:0' shape=(None,) dtype=float32>), 'data:0.493': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_493:0' shape=(None,) dtype=float32>), 'data:0.494': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_494:0' shape=(None,) dtype=float32>), 'data:0.495': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_495:0' shape=(None,) dtype=float32>), 'data:0.496': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_496:0' shape=(None,) dtype=float32>), 'data:0.497': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_497:0' shape=(None,) dtype=float32>), 'data:0.498': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_498:0' shape=(None,) dtype=float32>), 'data:0.499': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_499:0' shape=(None,) dtype=float32>), 'data:0.500': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_500:0' shape=(None,) dtype=float32>), 'data:0.501': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_501:0' shape=(None,) dtype=float32>), 'data:0.502': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_502:0' shape=(None,) dtype=float32>), 'data:0.503': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_503:0' shape=(None,) dtype=float32>), 'data:0.504': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_504:0' shape=(None,) dtype=float32>), 'data:0.505': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_505:0' shape=(None,) dtype=float32>), 'data:0.506': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_506:0' shape=(None,) dtype=float32>), 'data:0.507': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_507:0' shape=(None,) dtype=float32>), 'data:0.508': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_508:0' shape=(None,) dtype=float32>), 'data:0.509': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_509:0' shape=(None,) dtype=float32>), 'data:0.510': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_510:0' shape=(None,) dtype=float32>), 'data:0.511': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_511:0' shape=(None,) dtype=float32>), 'data:0.512': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_512:0' shape=(None,) dtype=float32>), 'data:0.513': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_513:0' shape=(None,) dtype=float32>), 'data:0.514': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_514:0' shape=(None,) dtype=float32>), 'data:0.515': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_515:0' shape=(None,) dtype=float32>), 'data:0.516': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_516:0' shape=(None,) dtype=float32>), 'data:0.517': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_517:0' shape=(None,) dtype=float32>), 'data:0.518': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_518:0' shape=(None,) dtype=float32>), 'data:0.519': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_519:0' shape=(None,) dtype=float32>), 'data:0.520': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_520:0' shape=(None,) dtype=float32>), 'data:0.521': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_521:0' shape=(None,) dtype=float32>), 'data:0.522': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_522:0' shape=(None,) dtype=float32>), 'data:0.523': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_523:0' shape=(None,) dtype=float32>), 'data:0.524': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_524:0' shape=(None,) dtype=float32>), 'data:0.525': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_525:0' shape=(None,) dtype=float32>), 'data:0.526': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_526:0' shape=(None,) dtype=float32>), 'data:0.527': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_527:0' shape=(None,) dtype=float32>), 'data:0.528': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_528:0' shape=(None,) dtype=float32>), 'data:0.529': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_529:0' shape=(None,) dtype=float32>), 'data:0.530': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_530:0' shape=(None,) dtype=float32>), 'data:0.531': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_531:0' shape=(None,) dtype=float32>), 'data:0.532': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_532:0' shape=(None,) dtype=float32>), 'data:0.533': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_533:0' shape=(None,) dtype=float32>), 'data:0.534': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_534:0' shape=(None,) dtype=float32>), 'data:0.535': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_535:0' shape=(None,) dtype=float32>), 'data:0.536': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_536:0' shape=(None,) dtype=float32>), 'data:0.537': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_537:0' shape=(None,) dtype=float32>), 'data:0.538': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_538:0' shape=(None,) dtype=float32>), 'data:0.539': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_539:0' shape=(None,) dtype=float32>), 'data:0.540': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_540:0' shape=(None,) dtype=float32>), 'data:0.541': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_541:0' shape=(None,) dtype=float32>), 'data:0.542': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_542:0' shape=(None,) dtype=float32>), 'data:0.543': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_543:0' shape=(None,) dtype=float32>), 'data:0.544': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_544:0' shape=(None,) dtype=float32>), 'data:0.545': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_545:0' shape=(None,) dtype=float32>), 'data:0.546': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_546:0' shape=(None,) dtype=float32>), 'data:0.547': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_547:0' shape=(None,) dtype=float32>), 'data:0.548': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_548:0' shape=(None,) dtype=float32>), 'data:0.549': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_549:0' shape=(None,) dtype=float32>), 'data:0.550': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_550:0' shape=(None,) dtype=float32>), 'data:0.551': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_551:0' shape=(None,) dtype=float32>), 'data:0.552': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_552:0' shape=(None,) dtype=float32>), 'data:0.553': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_553:0' shape=(None,) dtype=float32>), 'data:0.554': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_554:0' shape=(None,) dtype=float32>), 'data:0.555': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_555:0' shape=(None,) dtype=float32>), 'data:0.556': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_556:0' shape=(None,) dtype=float32>), 'data:0.557': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_557:0' shape=(None,) dtype=float32>), 'data:0.558': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_558:0' shape=(None,) dtype=float32>), 'data:0.559': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_559:0' shape=(None,) dtype=float32>), 'data:0.560': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_560:0' shape=(None,) dtype=float32>), 'data:0.561': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_561:0' shape=(None,) dtype=float32>), 'data:0.562': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_562:0' shape=(None,) dtype=float32>), 'data:0.563': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_563:0' shape=(None,) dtype=float32>), 'data:0.564': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_564:0' shape=(None,) dtype=float32>), 'data:0.565': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_565:0' shape=(None,) dtype=float32>), 'data:0.566': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_566:0' shape=(None,) dtype=float32>), 'data:0.567': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_567:0' shape=(None,) dtype=float32>), 'data:0.568': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_568:0' shape=(None,) dtype=float32>), 'data:0.569': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_569:0' shape=(None,) dtype=float32>), 'data:0.570': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_570:0' shape=(None,) dtype=float32>), 'data:0.571': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_571:0' shape=(None,) dtype=float32>), 'data:0.572': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_572:0' shape=(None,) dtype=float32>), 'data:0.573': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_573:0' shape=(None,) dtype=float32>), 'data:0.574': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_574:0' shape=(None,) dtype=float32>), 'data:0.575': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_575:0' shape=(None,) dtype=float32>), 'data:0.576': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_576:0' shape=(None,) dtype=float32>), 'data:0.577': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_577:0' shape=(None,) dtype=float32>), 'data:0.578': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_578:0' shape=(None,) dtype=float32>), 'data:0.579': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_579:0' shape=(None,) dtype=float32>), 'data:0.580': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_580:0' shape=(None,) dtype=float32>), 'data:0.581': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_581:0' shape=(None,) dtype=float32>), 'data:0.582': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_582:0' shape=(None,) dtype=float32>), 'data:0.583': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_583:0' shape=(None,) dtype=float32>), 'data:0.584': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_584:0' shape=(None,) dtype=float32>), 'data:0.585': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_585:0' shape=(None,) dtype=float32>), 'data:0.586': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_586:0' shape=(None,) dtype=float32>), 'data:0.587': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_587:0' shape=(None,) dtype=float32>), 'data:0.588': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_588:0' shape=(None,) dtype=float32>), 'data:0.589': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_589:0' shape=(None,) dtype=float32>), 'data:0.590': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_590:0' shape=(None,) dtype=float32>), 'data:0.591': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_591:0' shape=(None,) dtype=float32>), 'data:0.592': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_592:0' shape=(None,) dtype=float32>), 'data:0.593': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_593:0' shape=(None,) dtype=float32>), 'data:0.594': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_594:0' shape=(None,) dtype=float32>), 'data:0.595': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_595:0' shape=(None,) dtype=float32>), 'data:0.596': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_596:0' shape=(None,) dtype=float32>), 'data:0.597': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_597:0' shape=(None,) dtype=float32>), 'data:0.598': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_598:0' shape=(None,) dtype=float32>), 'data:0.599': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_599:0' shape=(None,) dtype=float32>), 'data:0.600': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_600:0' shape=(None,) dtype=float32>), 'data:0.601': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_601:0' shape=(None,) dtype=float32>), 'data:0.602': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_602:0' shape=(None,) dtype=float32>), 'data:0.603': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_603:0' shape=(None,) dtype=float32>), 'data:0.604': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_604:0' shape=(None,) dtype=float32>), 'data:0.605': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_605:0' shape=(None,) dtype=float32>), 'data:0.606': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_606:0' shape=(None,) dtype=float32>), 'data:0.607': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_607:0' shape=(None,) dtype=float32>), 'data:0.608': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_608:0' shape=(None,) dtype=float32>), 'data:0.609': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_609:0' shape=(None,) dtype=float32>), 'data:0.610': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_610:0' shape=(None,) dtype=float32>), 'data:0.611': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_611:0' shape=(None,) dtype=float32>), 'data:0.612': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_612:0' shape=(None,) dtype=float32>), 'data:0.613': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_613:0' shape=(None,) dtype=float32>), 'data:0.614': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_614:0' shape=(None,) dtype=float32>), 'data:0.615': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_615:0' shape=(None,) dtype=float32>), 'data:0.616': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_616:0' shape=(None,) dtype=float32>), 'data:0.617': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_617:0' shape=(None,) dtype=float32>), 'data:0.618': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_618:0' shape=(None,) dtype=float32>), 'data:0.619': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_619:0' shape=(None,) dtype=float32>), 'data:0.620': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_620:0' shape=(None,) dtype=float32>), 'data:0.621': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_621:0' shape=(None,) dtype=float32>), 'data:0.622': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_622:0' shape=(None,) dtype=float32>), 'data:0.623': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_623:0' shape=(None,) dtype=float32>), 'data:0.624': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_624:0' shape=(None,) dtype=float32>), 'data:0.625': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_625:0' shape=(None,) dtype=float32>), 'data:0.626': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_626:0' shape=(None,) dtype=float32>), 'data:0.627': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_627:0' shape=(None,) dtype=float32>), 'data:0.628': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_628:0' shape=(None,) dtype=float32>), 'data:0.629': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_629:0' shape=(None,) dtype=float32>), 'data:0.630': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_630:0' shape=(None,) dtype=float32>), 'data:0.631': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_631:0' shape=(None,) dtype=float32>), 'data:0.632': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_632:0' shape=(None,) dtype=float32>), 'data:0.633': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_633:0' shape=(None,) dtype=float32>), 'data:0.634': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_634:0' shape=(None,) dtype=float32>), 'data:0.635': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_635:0' shape=(None,) dtype=float32>), 'data:0.636': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_636:0' shape=(None,) dtype=float32>), 'data:0.637': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_637:0' shape=(None,) dtype=float32>), 'data:0.638': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_638:0' shape=(None,) dtype=float32>), 'data:0.639': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_639:0' shape=(None,) dtype=float32>), 'data:0.640': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_640:0' shape=(None,) dtype=float32>), 'data:0.641': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_641:0' shape=(None,) dtype=float32>), 'data:0.642': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_642:0' shape=(None,) dtype=float32>), 'data:0.643': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_643:0' shape=(None,) dtype=float32>), 'data:0.644': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_644:0' shape=(None,) dtype=float32>), 'data:0.645': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_645:0' shape=(None,) dtype=float32>), 'data:0.646': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_646:0' shape=(None,) dtype=float32>), 'data:0.647': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_647:0' shape=(None,) dtype=float32>), 'data:0.648': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_648:0' shape=(None,) dtype=float32>), 'data:0.649': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_649:0' shape=(None,) dtype=float32>), 'data:0.650': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_650:0' shape=(None,) dtype=float32>), 'data:0.651': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_651:0' shape=(None,) dtype=float32>), 'data:0.652': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_652:0' shape=(None,) dtype=float32>), 'data:0.653': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_653:0' shape=(None,) dtype=float32>), 'data:0.654': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_654:0' shape=(None,) dtype=float32>), 'data:0.655': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_655:0' shape=(None,) dtype=float32>), 'data:0.656': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_656:0' shape=(None,) dtype=float32>), 'data:0.657': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_657:0' shape=(None,) dtype=float32>), 'data:0.658': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_658:0' shape=(None,) dtype=float32>), 'data:0.659': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_659:0' shape=(None,) dtype=float32>), 'data:0.660': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_660:0' shape=(None,) dtype=float32>), 'data:0.661': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_661:0' shape=(None,) dtype=float32>), 'data:0.662': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_662:0' shape=(None,) dtype=float32>), 'data:0.663': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_663:0' shape=(None,) dtype=float32>), 'data:0.664': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_664:0' shape=(None,) dtype=float32>), 'data:0.665': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_665:0' shape=(None,) dtype=float32>), 'data:0.666': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_666:0' shape=(None,) dtype=float32>), 'data:0.667': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_667:0' shape=(None,) dtype=float32>), 'data:0.668': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_668:0' shape=(None,) dtype=float32>), 'data:0.669': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_669:0' shape=(None,) dtype=float32>), 'data:0.670': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_670:0' shape=(None,) dtype=float32>), 'data:0.671': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_671:0' shape=(None,) dtype=float32>), 'data:0.672': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_672:0' shape=(None,) dtype=float32>), 'data:0.673': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_673:0' shape=(None,) dtype=float32>), 'data:0.674': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_674:0' shape=(None,) dtype=float32>), 'data:0.675': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_675:0' shape=(None,) dtype=float32>), 'data:0.676': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_676:0' shape=(None,) dtype=float32>), 'data:0.677': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_677:0' shape=(None,) dtype=float32>), 'data:0.678': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_678:0' shape=(None,) dtype=float32>), 'data:0.679': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_679:0' shape=(None,) dtype=float32>), 'data:0.680': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_680:0' shape=(None,) dtype=float32>), 'data:0.681': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_681:0' shape=(None,) dtype=float32>), 'data:0.682': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_682:0' shape=(None,) dtype=float32>), 'data:0.683': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_683:0' shape=(None,) dtype=float32>), 'data:0.684': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_684:0' shape=(None,) dtype=float32>), 'data:0.685': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_685:0' shape=(None,) dtype=float32>), 'data:0.686': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_686:0' shape=(None,) dtype=float32>), 'data:0.687': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_687:0' shape=(None,) dtype=float32>), 'data:0.688': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_688:0' shape=(None,) dtype=float32>), 'data:0.689': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_689:0' shape=(None,) dtype=float32>), 'data:0.690': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_690:0' shape=(None,) dtype=float32>), 'data:0.691': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_691:0' shape=(None,) dtype=float32>), 'data:0.692': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_692:0' shape=(None,) dtype=float32>), 'data:0.693': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_693:0' shape=(None,) dtype=float32>), 'data:0.694': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_694:0' shape=(None,) dtype=float32>), 'data:0.695': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_695:0' shape=(None,) dtype=float32>), 'data:0.696': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_696:0' shape=(None,) dtype=float32>), 'data:0.697': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_697:0' shape=(None,) dtype=float32>), 'data:0.698': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_698:0' shape=(None,) dtype=float32>), 'data:0.699': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_699:0' shape=(None,) dtype=float32>), 'data:0.700': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_700:0' shape=(None,) dtype=float32>), 'data:0.701': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_701:0' shape=(None,) dtype=float32>), 'data:0.702': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_702:0' shape=(None,) dtype=float32>), 'data:0.703': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_703:0' shape=(None,) dtype=float32>), 'data:0.704': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_704:0' shape=(None,) dtype=float32>), 'data:0.705': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_705:0' shape=(None,) dtype=float32>), 'data:0.706': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_706:0' shape=(None,) dtype=float32>), 'data:0.707': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_707:0' shape=(None,) dtype=float32>), 'data:0.708': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_708:0' shape=(None,) dtype=float32>), 'data:0.709': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_709:0' shape=(None,) dtype=float32>), 'data:0.710': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_710:0' shape=(None,) dtype=float32>), 'data:0.711': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_711:0' shape=(None,) dtype=float32>), 'data:0.712': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_712:0' shape=(None,) dtype=float32>), 'data:0.713': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_713:0' shape=(None,) dtype=float32>), 'data:0.714': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_714:0' shape=(None,) dtype=float32>), 'data:0.715': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_715:0' shape=(None,) dtype=float32>), 'data:0.716': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_716:0' shape=(None,) dtype=float32>), 'data:0.717': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_717:0' shape=(None,) dtype=float32>), 'data:0.718': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_718:0' shape=(None,) dtype=float32>), 'data:0.719': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_719:0' shape=(None,) dtype=float32>), 'data:0.720': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_720:0' shape=(None,) dtype=float32>), 'data:0.721': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_721:0' shape=(None,) dtype=float32>), 'data:0.722': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_722:0' shape=(None,) dtype=float32>), 'data:0.723': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_723:0' shape=(None,) dtype=float32>), 'data:0.724': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_724:0' shape=(None,) dtype=float32>), 'data:0.725': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_725:0' shape=(None,) dtype=float32>), 'data:0.726': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_726:0' shape=(None,) dtype=float32>), 'data:0.727': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_727:0' shape=(None,) dtype=float32>), 'data:0.728': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_728:0' shape=(None,) dtype=float32>), 'data:0.729': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_729:0' shape=(None,) dtype=float32>), 'data:0.730': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_730:0' shape=(None,) dtype=float32>), 'data:0.731': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_731:0' shape=(None,) dtype=float32>), 'data:0.732': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_732:0' shape=(None,) dtype=float32>), 'data:0.733': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_733:0' shape=(None,) dtype=float32>), 'data:0.734': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_734:0' shape=(None,) dtype=float32>), 'data:0.735': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_735:0' shape=(None,) dtype=float32>), 'data:0.736': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_736:0' shape=(None,) dtype=float32>), 'data:0.737': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_737:0' shape=(None,) dtype=float32>), 'data:0.738': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_738:0' shape=(None,) dtype=float32>), 'data:0.739': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_739:0' shape=(None,) dtype=float32>), 'data:0.740': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_740:0' shape=(None,) dtype=float32>), 'data:0.741': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_741:0' shape=(None,) dtype=float32>), 'data:0.742': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_742:0' shape=(None,) dtype=float32>), 'data:0.743': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_743:0' shape=(None,) dtype=float32>), 'data:0.744': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_744:0' shape=(None,) dtype=float32>), 'data:0.745': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_745:0' shape=(None,) dtype=float32>), 'data:0.746': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_746:0' shape=(None,) dtype=float32>), 'data:0.747': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_747:0' shape=(None,) dtype=float32>), 'data:0.748': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_748:0' shape=(None,) dtype=float32>), 'data:0.749': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_749:0' shape=(None,) dtype=float32>), 'data:0.750': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_750:0' shape=(None,) dtype=float32>), 'data:0.751': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_751:0' shape=(None,) dtype=float32>), 'data:0.752': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_752:0' shape=(None,) dtype=float32>), 'data:0.753': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_753:0' shape=(None,) dtype=float32>), 'data:0.754': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_754:0' shape=(None,) dtype=float32>), 'data:0.755': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_755:0' shape=(None,) dtype=float32>), 'data:0.756': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_756:0' shape=(None,) dtype=float32>), 'data:0.757': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_757:0' shape=(None,) dtype=float32>), 'data:0.758': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_758:0' shape=(None,) dtype=float32>), 'data:0.759': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_759:0' shape=(None,) dtype=float32>), 'data:0.760': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_760:0' shape=(None,) dtype=float32>), 'data:0.761': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_761:0' shape=(None,) dtype=float32>), 'data:0.762': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_762:0' shape=(None,) dtype=float32>), 'data:0.763': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_763:0' shape=(None,) dtype=float32>), 'data:0.764': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_764:0' shape=(None,) dtype=float32>), 'data:0.765': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_765:0' shape=(None,) dtype=float32>), 'data:0.766': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_766:0' shape=(None,) dtype=float32>), 'data:0.767': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_767:0' shape=(None,) dtype=float32>), 'data:0.768': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_768:0' shape=(None,) dtype=float32>), 'data:0.769': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_769:0' shape=(None,) dtype=float32>), 'data:0.770': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_770:0' shape=(None,) dtype=float32>), 'data:0.771': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_771:0' shape=(None,) dtype=float32>), 'data:0.772': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_772:0' shape=(None,) dtype=float32>), 'data:0.773': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_773:0' shape=(None,) dtype=float32>), 'data:0.774': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_774:0' shape=(None,) dtype=float32>), 'data:0.775': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_775:0' shape=(None,) dtype=float32>), 'data:0.776': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_776:0' shape=(None,) dtype=float32>), 'data:0.777': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_777:0' shape=(None,) dtype=float32>), 'data:0.778': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_778:0' shape=(None,) dtype=float32>), 'data:0.779': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_779:0' shape=(None,) dtype=float32>), 'data:0.780': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_780:0' shape=(None,) dtype=float32>), 'data:0.781': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_781:0' shape=(None,) dtype=float32>), 'data:0.782': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_782:0' shape=(None,) dtype=float32>), 'data:0.783': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_783:0' shape=(None,) dtype=float32>)}\n",
            "Training dataset read in 0:00:09.360524. Found 33600 examples.\n",
            "Reading validation dataset...\n",
            "Validation tensor examples:\n",
            "Features: Tensor(\"data:0\", shape=(None, 784), dtype=int64)\n",
            "Label: Tensor(\"data_1:0\", shape=(None,), dtype=int64)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'data:0.0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice:0' shape=(None,) dtype=float32>), 'data:0.1': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_1:0' shape=(None,) dtype=float32>), 'data:0.2': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_2:0' shape=(None,) dtype=float32>), 'data:0.3': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_3:0' shape=(None,) dtype=float32>), 'data:0.4': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_4:0' shape=(None,) dtype=float32>), 'data:0.5': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_5:0' shape=(None,) dtype=float32>), 'data:0.6': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_6:0' shape=(None,) dtype=float32>), 'data:0.7': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_7:0' shape=(None,) dtype=float32>), 'data:0.8': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_8:0' shape=(None,) dtype=float32>), 'data:0.9': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_9:0' shape=(None,) dtype=float32>), 'data:0.10': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_10:0' shape=(None,) dtype=float32>), 'data:0.11': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_11:0' shape=(None,) dtype=float32>), 'data:0.12': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_12:0' shape=(None,) dtype=float32>), 'data:0.13': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_13:0' shape=(None,) dtype=float32>), 'data:0.14': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_14:0' shape=(None,) dtype=float32>), 'data:0.15': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_15:0' shape=(None,) dtype=float32>), 'data:0.16': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_16:0' shape=(None,) dtype=float32>), 'data:0.17': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_17:0' shape=(None,) dtype=float32>), 'data:0.18': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_18:0' shape=(None,) dtype=float32>), 'data:0.19': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_19:0' shape=(None,) dtype=float32>), 'data:0.20': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_20:0' shape=(None,) dtype=float32>), 'data:0.21': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_21:0' shape=(None,) dtype=float32>), 'data:0.22': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_22:0' shape=(None,) dtype=float32>), 'data:0.23': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_23:0' shape=(None,) dtype=float32>), 'data:0.24': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_24:0' shape=(None,) dtype=float32>), 'data:0.25': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_25:0' shape=(None,) dtype=float32>), 'data:0.26': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_26:0' shape=(None,) dtype=float32>), 'data:0.27': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_27:0' shape=(None,) dtype=float32>), 'data:0.28': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_28:0' shape=(None,) dtype=float32>), 'data:0.29': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_29:0' shape=(None,) dtype=float32>), 'data:0.30': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_30:0' shape=(None,) dtype=float32>), 'data:0.31': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_31:0' shape=(None,) dtype=float32>), 'data:0.32': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_32:0' shape=(None,) dtype=float32>), 'data:0.33': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_33:0' shape=(None,) dtype=float32>), 'data:0.34': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_34:0' shape=(None,) dtype=float32>), 'data:0.35': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_35:0' shape=(None,) dtype=float32>), 'data:0.36': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_36:0' shape=(None,) dtype=float32>), 'data:0.37': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_37:0' shape=(None,) dtype=float32>), 'data:0.38': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_38:0' shape=(None,) dtype=float32>), 'data:0.39': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_39:0' shape=(None,) dtype=float32>), 'data:0.40': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_40:0' shape=(None,) dtype=float32>), 'data:0.41': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_41:0' shape=(None,) dtype=float32>), 'data:0.42': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_42:0' shape=(None,) dtype=float32>), 'data:0.43': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_43:0' shape=(None,) dtype=float32>), 'data:0.44': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_44:0' shape=(None,) dtype=float32>), 'data:0.45': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_45:0' shape=(None,) dtype=float32>), 'data:0.46': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_46:0' shape=(None,) dtype=float32>), 'data:0.47': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_47:0' shape=(None,) dtype=float32>), 'data:0.48': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_48:0' shape=(None,) dtype=float32>), 'data:0.49': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_49:0' shape=(None,) dtype=float32>), 'data:0.50': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_50:0' shape=(None,) dtype=float32>), 'data:0.51': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_51:0' shape=(None,) dtype=float32>), 'data:0.52': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_52:0' shape=(None,) dtype=float32>), 'data:0.53': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_53:0' shape=(None,) dtype=float32>), 'data:0.54': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_54:0' shape=(None,) dtype=float32>), 'data:0.55': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_55:0' shape=(None,) dtype=float32>), 'data:0.56': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_56:0' shape=(None,) dtype=float32>), 'data:0.57': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_57:0' shape=(None,) dtype=float32>), 'data:0.58': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_58:0' shape=(None,) dtype=float32>), 'data:0.59': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_59:0' shape=(None,) dtype=float32>), 'data:0.60': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_60:0' shape=(None,) dtype=float32>), 'data:0.61': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_61:0' shape=(None,) dtype=float32>), 'data:0.62': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_62:0' shape=(None,) dtype=float32>), 'data:0.63': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_63:0' shape=(None,) dtype=float32>), 'data:0.64': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_64:0' shape=(None,) dtype=float32>), 'data:0.65': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_65:0' shape=(None,) dtype=float32>), 'data:0.66': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_66:0' shape=(None,) dtype=float32>), 'data:0.67': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_67:0' shape=(None,) dtype=float32>), 'data:0.68': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_68:0' shape=(None,) dtype=float32>), 'data:0.69': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_69:0' shape=(None,) dtype=float32>), 'data:0.70': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_70:0' shape=(None,) dtype=float32>), 'data:0.71': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_71:0' shape=(None,) dtype=float32>), 'data:0.72': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_72:0' shape=(None,) dtype=float32>), 'data:0.73': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_73:0' shape=(None,) dtype=float32>), 'data:0.74': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_74:0' shape=(None,) dtype=float32>), 'data:0.75': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_75:0' shape=(None,) dtype=float32>), 'data:0.76': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_76:0' shape=(None,) dtype=float32>), 'data:0.77': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_77:0' shape=(None,) dtype=float32>), 'data:0.78': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_78:0' shape=(None,) dtype=float32>), 'data:0.79': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_79:0' shape=(None,) dtype=float32>), 'data:0.80': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_80:0' shape=(None,) dtype=float32>), 'data:0.81': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_81:0' shape=(None,) dtype=float32>), 'data:0.82': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_82:0' shape=(None,) dtype=float32>), 'data:0.83': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_83:0' shape=(None,) dtype=float32>), 'data:0.84': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_84:0' shape=(None,) dtype=float32>), 'data:0.85': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_85:0' shape=(None,) dtype=float32>), 'data:0.86': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_86:0' shape=(None,) dtype=float32>), 'data:0.87': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_87:0' shape=(None,) dtype=float32>), 'data:0.88': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_88:0' shape=(None,) dtype=float32>), 'data:0.89': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_89:0' shape=(None,) dtype=float32>), 'data:0.90': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_90:0' shape=(None,) dtype=float32>), 'data:0.91': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_91:0' shape=(None,) dtype=float32>), 'data:0.92': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_92:0' shape=(None,) dtype=float32>), 'data:0.93': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_93:0' shape=(None,) dtype=float32>), 'data:0.94': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_94:0' shape=(None,) dtype=float32>), 'data:0.95': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_95:0' shape=(None,) dtype=float32>), 'data:0.96': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_96:0' shape=(None,) dtype=float32>), 'data:0.97': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_97:0' shape=(None,) dtype=float32>), 'data:0.98': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_98:0' shape=(None,) dtype=float32>), 'data:0.99': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_99:0' shape=(None,) dtype=float32>), 'data:0.100': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_100:0' shape=(None,) dtype=float32>), 'data:0.101': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_101:0' shape=(None,) dtype=float32>), 'data:0.102': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_102:0' shape=(None,) dtype=float32>), 'data:0.103': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_103:0' shape=(None,) dtype=float32>), 'data:0.104': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_104:0' shape=(None,) dtype=float32>), 'data:0.105': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_105:0' shape=(None,) dtype=float32>), 'data:0.106': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_106:0' shape=(None,) dtype=float32>), 'data:0.107': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_107:0' shape=(None,) dtype=float32>), 'data:0.108': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_108:0' shape=(None,) dtype=float32>), 'data:0.109': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_109:0' shape=(None,) dtype=float32>), 'data:0.110': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_110:0' shape=(None,) dtype=float32>), 'data:0.111': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_111:0' shape=(None,) dtype=float32>), 'data:0.112': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_112:0' shape=(None,) dtype=float32>), 'data:0.113': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_113:0' shape=(None,) dtype=float32>), 'data:0.114': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_114:0' shape=(None,) dtype=float32>), 'data:0.115': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_115:0' shape=(None,) dtype=float32>), 'data:0.116': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_116:0' shape=(None,) dtype=float32>), 'data:0.117': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_117:0' shape=(None,) dtype=float32>), 'data:0.118': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_118:0' shape=(None,) dtype=float32>), 'data:0.119': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_119:0' shape=(None,) dtype=float32>), 'data:0.120': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_120:0' shape=(None,) dtype=float32>), 'data:0.121': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_121:0' shape=(None,) dtype=float32>), 'data:0.122': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_122:0' shape=(None,) dtype=float32>), 'data:0.123': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_123:0' shape=(None,) dtype=float32>), 'data:0.124': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_124:0' shape=(None,) dtype=float32>), 'data:0.125': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_125:0' shape=(None,) dtype=float32>), 'data:0.126': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_126:0' shape=(None,) dtype=float32>), 'data:0.127': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_127:0' shape=(None,) dtype=float32>), 'data:0.128': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_128:0' shape=(None,) dtype=float32>), 'data:0.129': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_129:0' shape=(None,) dtype=float32>), 'data:0.130': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_130:0' shape=(None,) dtype=float32>), 'data:0.131': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_131:0' shape=(None,) dtype=float32>), 'data:0.132': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_132:0' shape=(None,) dtype=float32>), 'data:0.133': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_133:0' shape=(None,) dtype=float32>), 'data:0.134': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_134:0' shape=(None,) dtype=float32>), 'data:0.135': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_135:0' shape=(None,) dtype=float32>), 'data:0.136': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_136:0' shape=(None,) dtype=float32>), 'data:0.137': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_137:0' shape=(None,) dtype=float32>), 'data:0.138': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_138:0' shape=(None,) dtype=float32>), 'data:0.139': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_139:0' shape=(None,) dtype=float32>), 'data:0.140': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_140:0' shape=(None,) dtype=float32>), 'data:0.141': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_141:0' shape=(None,) dtype=float32>), 'data:0.142': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_142:0' shape=(None,) dtype=float32>), 'data:0.143': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_143:0' shape=(None,) dtype=float32>), 'data:0.144': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_144:0' shape=(None,) dtype=float32>), 'data:0.145': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_145:0' shape=(None,) dtype=float32>), 'data:0.146': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_146:0' shape=(None,) dtype=float32>), 'data:0.147': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_147:0' shape=(None,) dtype=float32>), 'data:0.148': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_148:0' shape=(None,) dtype=float32>), 'data:0.149': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_149:0' shape=(None,) dtype=float32>), 'data:0.150': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_150:0' shape=(None,) dtype=float32>), 'data:0.151': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_151:0' shape=(None,) dtype=float32>), 'data:0.152': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_152:0' shape=(None,) dtype=float32>), 'data:0.153': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_153:0' shape=(None,) dtype=float32>), 'data:0.154': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_154:0' shape=(None,) dtype=float32>), 'data:0.155': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_155:0' shape=(None,) dtype=float32>), 'data:0.156': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_156:0' shape=(None,) dtype=float32>), 'data:0.157': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_157:0' shape=(None,) dtype=float32>), 'data:0.158': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_158:0' shape=(None,) dtype=float32>), 'data:0.159': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_159:0' shape=(None,) dtype=float32>), 'data:0.160': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_160:0' shape=(None,) dtype=float32>), 'data:0.161': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_161:0' shape=(None,) dtype=float32>), 'data:0.162': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_162:0' shape=(None,) dtype=float32>), 'data:0.163': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_163:0' shape=(None,) dtype=float32>), 'data:0.164': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_164:0' shape=(None,) dtype=float32>), 'data:0.165': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_165:0' shape=(None,) dtype=float32>), 'data:0.166': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_166:0' shape=(None,) dtype=float32>), 'data:0.167': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_167:0' shape=(None,) dtype=float32>), 'data:0.168': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_168:0' shape=(None,) dtype=float32>), 'data:0.169': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_169:0' shape=(None,) dtype=float32>), 'data:0.170': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_170:0' shape=(None,) dtype=float32>), 'data:0.171': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_171:0' shape=(None,) dtype=float32>), 'data:0.172': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_172:0' shape=(None,) dtype=float32>), 'data:0.173': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_173:0' shape=(None,) dtype=float32>), 'data:0.174': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_174:0' shape=(None,) dtype=float32>), 'data:0.175': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_175:0' shape=(None,) dtype=float32>), 'data:0.176': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_176:0' shape=(None,) dtype=float32>), 'data:0.177': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_177:0' shape=(None,) dtype=float32>), 'data:0.178': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_178:0' shape=(None,) dtype=float32>), 'data:0.179': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_179:0' shape=(None,) dtype=float32>), 'data:0.180': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_180:0' shape=(None,) dtype=float32>), 'data:0.181': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_181:0' shape=(None,) dtype=float32>), 'data:0.182': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_182:0' shape=(None,) dtype=float32>), 'data:0.183': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_183:0' shape=(None,) dtype=float32>), 'data:0.184': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_184:0' shape=(None,) dtype=float32>), 'data:0.185': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_185:0' shape=(None,) dtype=float32>), 'data:0.186': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_186:0' shape=(None,) dtype=float32>), 'data:0.187': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_187:0' shape=(None,) dtype=float32>), 'data:0.188': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_188:0' shape=(None,) dtype=float32>), 'data:0.189': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_189:0' shape=(None,) dtype=float32>), 'data:0.190': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_190:0' shape=(None,) dtype=float32>), 'data:0.191': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_191:0' shape=(None,) dtype=float32>), 'data:0.192': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_192:0' shape=(None,) dtype=float32>), 'data:0.193': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_193:0' shape=(None,) dtype=float32>), 'data:0.194': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_194:0' shape=(None,) dtype=float32>), 'data:0.195': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_195:0' shape=(None,) dtype=float32>), 'data:0.196': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_196:0' shape=(None,) dtype=float32>), 'data:0.197': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_197:0' shape=(None,) dtype=float32>), 'data:0.198': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_198:0' shape=(None,) dtype=float32>), 'data:0.199': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_199:0' shape=(None,) dtype=float32>), 'data:0.200': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_200:0' shape=(None,) dtype=float32>), 'data:0.201': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_201:0' shape=(None,) dtype=float32>), 'data:0.202': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_202:0' shape=(None,) dtype=float32>), 'data:0.203': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_203:0' shape=(None,) dtype=float32>), 'data:0.204': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_204:0' shape=(None,) dtype=float32>), 'data:0.205': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_205:0' shape=(None,) dtype=float32>), 'data:0.206': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_206:0' shape=(None,) dtype=float32>), 'data:0.207': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_207:0' shape=(None,) dtype=float32>), 'data:0.208': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_208:0' shape=(None,) dtype=float32>), 'data:0.209': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_209:0' shape=(None,) dtype=float32>), 'data:0.210': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_210:0' shape=(None,) dtype=float32>), 'data:0.211': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_211:0' shape=(None,) dtype=float32>), 'data:0.212': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_212:0' shape=(None,) dtype=float32>), 'data:0.213': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_213:0' shape=(None,) dtype=float32>), 'data:0.214': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_214:0' shape=(None,) dtype=float32>), 'data:0.215': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_215:0' shape=(None,) dtype=float32>), 'data:0.216': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_216:0' shape=(None,) dtype=float32>), 'data:0.217': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_217:0' shape=(None,) dtype=float32>), 'data:0.218': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_218:0' shape=(None,) dtype=float32>), 'data:0.219': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_219:0' shape=(None,) dtype=float32>), 'data:0.220': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_220:0' shape=(None,) dtype=float32>), 'data:0.221': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_221:0' shape=(None,) dtype=float32>), 'data:0.222': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_222:0' shape=(None,) dtype=float32>), 'data:0.223': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_223:0' shape=(None,) dtype=float32>), 'data:0.224': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_224:0' shape=(None,) dtype=float32>), 'data:0.225': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_225:0' shape=(None,) dtype=float32>), 'data:0.226': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_226:0' shape=(None,) dtype=float32>), 'data:0.227': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_227:0' shape=(None,) dtype=float32>), 'data:0.228': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_228:0' shape=(None,) dtype=float32>), 'data:0.229': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_229:0' shape=(None,) dtype=float32>), 'data:0.230': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_230:0' shape=(None,) dtype=float32>), 'data:0.231': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_231:0' shape=(None,) dtype=float32>), 'data:0.232': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_232:0' shape=(None,) dtype=float32>), 'data:0.233': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_233:0' shape=(None,) dtype=float32>), 'data:0.234': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_234:0' shape=(None,) dtype=float32>), 'data:0.235': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_235:0' shape=(None,) dtype=float32>), 'data:0.236': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_236:0' shape=(None,) dtype=float32>), 'data:0.237': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_237:0' shape=(None,) dtype=float32>), 'data:0.238': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_238:0' shape=(None,) dtype=float32>), 'data:0.239': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_239:0' shape=(None,) dtype=float32>), 'data:0.240': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_240:0' shape=(None,) dtype=float32>), 'data:0.241': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_241:0' shape=(None,) dtype=float32>), 'data:0.242': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_242:0' shape=(None,) dtype=float32>), 'data:0.243': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_243:0' shape=(None,) dtype=float32>), 'data:0.244': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_244:0' shape=(None,) dtype=float32>), 'data:0.245': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_245:0' shape=(None,) dtype=float32>), 'data:0.246': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_246:0' shape=(None,) dtype=float32>), 'data:0.247': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_247:0' shape=(None,) dtype=float32>), 'data:0.248': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_248:0' shape=(None,) dtype=float32>), 'data:0.249': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_249:0' shape=(None,) dtype=float32>), 'data:0.250': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_250:0' shape=(None,) dtype=float32>), 'data:0.251': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_251:0' shape=(None,) dtype=float32>), 'data:0.252': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_252:0' shape=(None,) dtype=float32>), 'data:0.253': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_253:0' shape=(None,) dtype=float32>), 'data:0.254': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_254:0' shape=(None,) dtype=float32>), 'data:0.255': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_255:0' shape=(None,) dtype=float32>), 'data:0.256': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_256:0' shape=(None,) dtype=float32>), 'data:0.257': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_257:0' shape=(None,) dtype=float32>), 'data:0.258': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_258:0' shape=(None,) dtype=float32>), 'data:0.259': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_259:0' shape=(None,) dtype=float32>), 'data:0.260': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_260:0' shape=(None,) dtype=float32>), 'data:0.261': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_261:0' shape=(None,) dtype=float32>), 'data:0.262': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_262:0' shape=(None,) dtype=float32>), 'data:0.263': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_263:0' shape=(None,) dtype=float32>), 'data:0.264': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_264:0' shape=(None,) dtype=float32>), 'data:0.265': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_265:0' shape=(None,) dtype=float32>), 'data:0.266': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_266:0' shape=(None,) dtype=float32>), 'data:0.267': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_267:0' shape=(None,) dtype=float32>), 'data:0.268': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_268:0' shape=(None,) dtype=float32>), 'data:0.269': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_269:0' shape=(None,) dtype=float32>), 'data:0.270': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_270:0' shape=(None,) dtype=float32>), 'data:0.271': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_271:0' shape=(None,) dtype=float32>), 'data:0.272': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_272:0' shape=(None,) dtype=float32>), 'data:0.273': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_273:0' shape=(None,) dtype=float32>), 'data:0.274': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_274:0' shape=(None,) dtype=float32>), 'data:0.275': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_275:0' shape=(None,) dtype=float32>), 'data:0.276': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_276:0' shape=(None,) dtype=float32>), 'data:0.277': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_277:0' shape=(None,) dtype=float32>), 'data:0.278': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_278:0' shape=(None,) dtype=float32>), 'data:0.279': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_279:0' shape=(None,) dtype=float32>), 'data:0.280': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_280:0' shape=(None,) dtype=float32>), 'data:0.281': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_281:0' shape=(None,) dtype=float32>), 'data:0.282': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_282:0' shape=(None,) dtype=float32>), 'data:0.283': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_283:0' shape=(None,) dtype=float32>), 'data:0.284': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_284:0' shape=(None,) dtype=float32>), 'data:0.285': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_285:0' shape=(None,) dtype=float32>), 'data:0.286': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_286:0' shape=(None,) dtype=float32>), 'data:0.287': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_287:0' shape=(None,) dtype=float32>), 'data:0.288': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_288:0' shape=(None,) dtype=float32>), 'data:0.289': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_289:0' shape=(None,) dtype=float32>), 'data:0.290': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_290:0' shape=(None,) dtype=float32>), 'data:0.291': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_291:0' shape=(None,) dtype=float32>), 'data:0.292': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_292:0' shape=(None,) dtype=float32>), 'data:0.293': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_293:0' shape=(None,) dtype=float32>), 'data:0.294': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_294:0' shape=(None,) dtype=float32>), 'data:0.295': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_295:0' shape=(None,) dtype=float32>), 'data:0.296': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_296:0' shape=(None,) dtype=float32>), 'data:0.297': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_297:0' shape=(None,) dtype=float32>), 'data:0.298': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_298:0' shape=(None,) dtype=float32>), 'data:0.299': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_299:0' shape=(None,) dtype=float32>), 'data:0.300': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_300:0' shape=(None,) dtype=float32>), 'data:0.301': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_301:0' shape=(None,) dtype=float32>), 'data:0.302': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_302:0' shape=(None,) dtype=float32>), 'data:0.303': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_303:0' shape=(None,) dtype=float32>), 'data:0.304': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_304:0' shape=(None,) dtype=float32>), 'data:0.305': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_305:0' shape=(None,) dtype=float32>), 'data:0.306': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_306:0' shape=(None,) dtype=float32>), 'data:0.307': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_307:0' shape=(None,) dtype=float32>), 'data:0.308': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_308:0' shape=(None,) dtype=float32>), 'data:0.309': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_309:0' shape=(None,) dtype=float32>), 'data:0.310': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_310:0' shape=(None,) dtype=float32>), 'data:0.311': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_311:0' shape=(None,) dtype=float32>), 'data:0.312': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_312:0' shape=(None,) dtype=float32>), 'data:0.313': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_313:0' shape=(None,) dtype=float32>), 'data:0.314': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_314:0' shape=(None,) dtype=float32>), 'data:0.315': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_315:0' shape=(None,) dtype=float32>), 'data:0.316': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_316:0' shape=(None,) dtype=float32>), 'data:0.317': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_317:0' shape=(None,) dtype=float32>), 'data:0.318': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_318:0' shape=(None,) dtype=float32>), 'data:0.319': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_319:0' shape=(None,) dtype=float32>), 'data:0.320': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_320:0' shape=(None,) dtype=float32>), 'data:0.321': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_321:0' shape=(None,) dtype=float32>), 'data:0.322': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_322:0' shape=(None,) dtype=float32>), 'data:0.323': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_323:0' shape=(None,) dtype=float32>), 'data:0.324': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_324:0' shape=(None,) dtype=float32>), 'data:0.325': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_325:0' shape=(None,) dtype=float32>), 'data:0.326': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_326:0' shape=(None,) dtype=float32>), 'data:0.327': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_327:0' shape=(None,) dtype=float32>), 'data:0.328': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_328:0' shape=(None,) dtype=float32>), 'data:0.329': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_329:0' shape=(None,) dtype=float32>), 'data:0.330': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_330:0' shape=(None,) dtype=float32>), 'data:0.331': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_331:0' shape=(None,) dtype=float32>), 'data:0.332': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_332:0' shape=(None,) dtype=float32>), 'data:0.333': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_333:0' shape=(None,) dtype=float32>), 'data:0.334': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_334:0' shape=(None,) dtype=float32>), 'data:0.335': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_335:0' shape=(None,) dtype=float32>), 'data:0.336': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_336:0' shape=(None,) dtype=float32>), 'data:0.337': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_337:0' shape=(None,) dtype=float32>), 'data:0.338': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_338:0' shape=(None,) dtype=float32>), 'data:0.339': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_339:0' shape=(None,) dtype=float32>), 'data:0.340': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_340:0' shape=(None,) dtype=float32>), 'data:0.341': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_341:0' shape=(None,) dtype=float32>), 'data:0.342': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_342:0' shape=(None,) dtype=float32>), 'data:0.343': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_343:0' shape=(None,) dtype=float32>), 'data:0.344': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_344:0' shape=(None,) dtype=float32>), 'data:0.345': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_345:0' shape=(None,) dtype=float32>), 'data:0.346': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_346:0' shape=(None,) dtype=float32>), 'data:0.347': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_347:0' shape=(None,) dtype=float32>), 'data:0.348': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_348:0' shape=(None,) dtype=float32>), 'data:0.349': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_349:0' shape=(None,) dtype=float32>), 'data:0.350': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_350:0' shape=(None,) dtype=float32>), 'data:0.351': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_351:0' shape=(None,) dtype=float32>), 'data:0.352': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_352:0' shape=(None,) dtype=float32>), 'data:0.353': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_353:0' shape=(None,) dtype=float32>), 'data:0.354': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_354:0' shape=(None,) dtype=float32>), 'data:0.355': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_355:0' shape=(None,) dtype=float32>), 'data:0.356': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_356:0' shape=(None,) dtype=float32>), 'data:0.357': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_357:0' shape=(None,) dtype=float32>), 'data:0.358': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_358:0' shape=(None,) dtype=float32>), 'data:0.359': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_359:0' shape=(None,) dtype=float32>), 'data:0.360': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_360:0' shape=(None,) dtype=float32>), 'data:0.361': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_361:0' shape=(None,) dtype=float32>), 'data:0.362': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_362:0' shape=(None,) dtype=float32>), 'data:0.363': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_363:0' shape=(None,) dtype=float32>), 'data:0.364': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_364:0' shape=(None,) dtype=float32>), 'data:0.365': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_365:0' shape=(None,) dtype=float32>), 'data:0.366': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_366:0' shape=(None,) dtype=float32>), 'data:0.367': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_367:0' shape=(None,) dtype=float32>), 'data:0.368': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_368:0' shape=(None,) dtype=float32>), 'data:0.369': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_369:0' shape=(None,) dtype=float32>), 'data:0.370': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_370:0' shape=(None,) dtype=float32>), 'data:0.371': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_371:0' shape=(None,) dtype=float32>), 'data:0.372': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_372:0' shape=(None,) dtype=float32>), 'data:0.373': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_373:0' shape=(None,) dtype=float32>), 'data:0.374': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_374:0' shape=(None,) dtype=float32>), 'data:0.375': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_375:0' shape=(None,) dtype=float32>), 'data:0.376': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_376:0' shape=(None,) dtype=float32>), 'data:0.377': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_377:0' shape=(None,) dtype=float32>), 'data:0.378': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_378:0' shape=(None,) dtype=float32>), 'data:0.379': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_379:0' shape=(None,) dtype=float32>), 'data:0.380': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_380:0' shape=(None,) dtype=float32>), 'data:0.381': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_381:0' shape=(None,) dtype=float32>), 'data:0.382': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_382:0' shape=(None,) dtype=float32>), 'data:0.383': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_383:0' shape=(None,) dtype=float32>), 'data:0.384': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_384:0' shape=(None,) dtype=float32>), 'data:0.385': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_385:0' shape=(None,) dtype=float32>), 'data:0.386': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_386:0' shape=(None,) dtype=float32>), 'data:0.387': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_387:0' shape=(None,) dtype=float32>), 'data:0.388': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_388:0' shape=(None,) dtype=float32>), 'data:0.389': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_389:0' shape=(None,) dtype=float32>), 'data:0.390': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_390:0' shape=(None,) dtype=float32>), 'data:0.391': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_391:0' shape=(None,) dtype=float32>), 'data:0.392': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_392:0' shape=(None,) dtype=float32>), 'data:0.393': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_393:0' shape=(None,) dtype=float32>), 'data:0.394': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_394:0' shape=(None,) dtype=float32>), 'data:0.395': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_395:0' shape=(None,) dtype=float32>), 'data:0.396': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_396:0' shape=(None,) dtype=float32>), 'data:0.397': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_397:0' shape=(None,) dtype=float32>), 'data:0.398': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_398:0' shape=(None,) dtype=float32>), 'data:0.399': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_399:0' shape=(None,) dtype=float32>), 'data:0.400': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_400:0' shape=(None,) dtype=float32>), 'data:0.401': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_401:0' shape=(None,) dtype=float32>), 'data:0.402': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_402:0' shape=(None,) dtype=float32>), 'data:0.403': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_403:0' shape=(None,) dtype=float32>), 'data:0.404': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_404:0' shape=(None,) dtype=float32>), 'data:0.405': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_405:0' shape=(None,) dtype=float32>), 'data:0.406': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_406:0' shape=(None,) dtype=float32>), 'data:0.407': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_407:0' shape=(None,) dtype=float32>), 'data:0.408': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_408:0' shape=(None,) dtype=float32>), 'data:0.409': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_409:0' shape=(None,) dtype=float32>), 'data:0.410': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_410:0' shape=(None,) dtype=float32>), 'data:0.411': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_411:0' shape=(None,) dtype=float32>), 'data:0.412': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_412:0' shape=(None,) dtype=float32>), 'data:0.413': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_413:0' shape=(None,) dtype=float32>), 'data:0.414': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_414:0' shape=(None,) dtype=float32>), 'data:0.415': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_415:0' shape=(None,) dtype=float32>), 'data:0.416': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_416:0' shape=(None,) dtype=float32>), 'data:0.417': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_417:0' shape=(None,) dtype=float32>), 'data:0.418': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_418:0' shape=(None,) dtype=float32>), 'data:0.419': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_419:0' shape=(None,) dtype=float32>), 'data:0.420': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_420:0' shape=(None,) dtype=float32>), 'data:0.421': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_421:0' shape=(None,) dtype=float32>), 'data:0.422': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_422:0' shape=(None,) dtype=float32>), 'data:0.423': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_423:0' shape=(None,) dtype=float32>), 'data:0.424': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_424:0' shape=(None,) dtype=float32>), 'data:0.425': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_425:0' shape=(None,) dtype=float32>), 'data:0.426': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_426:0' shape=(None,) dtype=float32>), 'data:0.427': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_427:0' shape=(None,) dtype=float32>), 'data:0.428': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_428:0' shape=(None,) dtype=float32>), 'data:0.429': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_429:0' shape=(None,) dtype=float32>), 'data:0.430': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_430:0' shape=(None,) dtype=float32>), 'data:0.431': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_431:0' shape=(None,) dtype=float32>), 'data:0.432': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_432:0' shape=(None,) dtype=float32>), 'data:0.433': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_433:0' shape=(None,) dtype=float32>), 'data:0.434': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_434:0' shape=(None,) dtype=float32>), 'data:0.435': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_435:0' shape=(None,) dtype=float32>), 'data:0.436': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_436:0' shape=(None,) dtype=float32>), 'data:0.437': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_437:0' shape=(None,) dtype=float32>), 'data:0.438': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_438:0' shape=(None,) dtype=float32>), 'data:0.439': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_439:0' shape=(None,) dtype=float32>), 'data:0.440': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_440:0' shape=(None,) dtype=float32>), 'data:0.441': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_441:0' shape=(None,) dtype=float32>), 'data:0.442': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_442:0' shape=(None,) dtype=float32>), 'data:0.443': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_443:0' shape=(None,) dtype=float32>), 'data:0.444': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_444:0' shape=(None,) dtype=float32>), 'data:0.445': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_445:0' shape=(None,) dtype=float32>), 'data:0.446': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_446:0' shape=(None,) dtype=float32>), 'data:0.447': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_447:0' shape=(None,) dtype=float32>), 'data:0.448': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_448:0' shape=(None,) dtype=float32>), 'data:0.449': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_449:0' shape=(None,) dtype=float32>), 'data:0.450': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_450:0' shape=(None,) dtype=float32>), 'data:0.451': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_451:0' shape=(None,) dtype=float32>), 'data:0.452': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_452:0' shape=(None,) dtype=float32>), 'data:0.453': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_453:0' shape=(None,) dtype=float32>), 'data:0.454': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_454:0' shape=(None,) dtype=float32>), 'data:0.455': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_455:0' shape=(None,) dtype=float32>), 'data:0.456': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_456:0' shape=(None,) dtype=float32>), 'data:0.457': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_457:0' shape=(None,) dtype=float32>), 'data:0.458': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_458:0' shape=(None,) dtype=float32>), 'data:0.459': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_459:0' shape=(None,) dtype=float32>), 'data:0.460': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_460:0' shape=(None,) dtype=float32>), 'data:0.461': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_461:0' shape=(None,) dtype=float32>), 'data:0.462': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_462:0' shape=(None,) dtype=float32>), 'data:0.463': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_463:0' shape=(None,) dtype=float32>), 'data:0.464': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_464:0' shape=(None,) dtype=float32>), 'data:0.465': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_465:0' shape=(None,) dtype=float32>), 'data:0.466': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_466:0' shape=(None,) dtype=float32>), 'data:0.467': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_467:0' shape=(None,) dtype=float32>), 'data:0.468': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_468:0' shape=(None,) dtype=float32>), 'data:0.469': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_469:0' shape=(None,) dtype=float32>), 'data:0.470': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_470:0' shape=(None,) dtype=float32>), 'data:0.471': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_471:0' shape=(None,) dtype=float32>), 'data:0.472': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_472:0' shape=(None,) dtype=float32>), 'data:0.473': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_473:0' shape=(None,) dtype=float32>), 'data:0.474': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_474:0' shape=(None,) dtype=float32>), 'data:0.475': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_475:0' shape=(None,) dtype=float32>), 'data:0.476': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_476:0' shape=(None,) dtype=float32>), 'data:0.477': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_477:0' shape=(None,) dtype=float32>), 'data:0.478': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_478:0' shape=(None,) dtype=float32>), 'data:0.479': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_479:0' shape=(None,) dtype=float32>), 'data:0.480': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_480:0' shape=(None,) dtype=float32>), 'data:0.481': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_481:0' shape=(None,) dtype=float32>), 'data:0.482': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_482:0' shape=(None,) dtype=float32>), 'data:0.483': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_483:0' shape=(None,) dtype=float32>), 'data:0.484': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_484:0' shape=(None,) dtype=float32>), 'data:0.485': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_485:0' shape=(None,) dtype=float32>), 'data:0.486': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_486:0' shape=(None,) dtype=float32>), 'data:0.487': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_487:0' shape=(None,) dtype=float32>), 'data:0.488': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_488:0' shape=(None,) dtype=float32>), 'data:0.489': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_489:0' shape=(None,) dtype=float32>), 'data:0.490': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_490:0' shape=(None,) dtype=float32>), 'data:0.491': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_491:0' shape=(None,) dtype=float32>), 'data:0.492': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_492:0' shape=(None,) dtype=float32>), 'data:0.493': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_493:0' shape=(None,) dtype=float32>), 'data:0.494': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_494:0' shape=(None,) dtype=float32>), 'data:0.495': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_495:0' shape=(None,) dtype=float32>), 'data:0.496': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_496:0' shape=(None,) dtype=float32>), 'data:0.497': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_497:0' shape=(None,) dtype=float32>), 'data:0.498': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_498:0' shape=(None,) dtype=float32>), 'data:0.499': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_499:0' shape=(None,) dtype=float32>), 'data:0.500': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_500:0' shape=(None,) dtype=float32>), 'data:0.501': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_501:0' shape=(None,) dtype=float32>), 'data:0.502': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_502:0' shape=(None,) dtype=float32>), 'data:0.503': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_503:0' shape=(None,) dtype=float32>), 'data:0.504': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_504:0' shape=(None,) dtype=float32>), 'data:0.505': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_505:0' shape=(None,) dtype=float32>), 'data:0.506': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_506:0' shape=(None,) dtype=float32>), 'data:0.507': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_507:0' shape=(None,) dtype=float32>), 'data:0.508': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_508:0' shape=(None,) dtype=float32>), 'data:0.509': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_509:0' shape=(None,) dtype=float32>), 'data:0.510': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_510:0' shape=(None,) dtype=float32>), 'data:0.511': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_511:0' shape=(None,) dtype=float32>), 'data:0.512': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_512:0' shape=(None,) dtype=float32>), 'data:0.513': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_513:0' shape=(None,) dtype=float32>), 'data:0.514': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_514:0' shape=(None,) dtype=float32>), 'data:0.515': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_515:0' shape=(None,) dtype=float32>), 'data:0.516': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_516:0' shape=(None,) dtype=float32>), 'data:0.517': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_517:0' shape=(None,) dtype=float32>), 'data:0.518': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_518:0' shape=(None,) dtype=float32>), 'data:0.519': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_519:0' shape=(None,) dtype=float32>), 'data:0.520': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_520:0' shape=(None,) dtype=float32>), 'data:0.521': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_521:0' shape=(None,) dtype=float32>), 'data:0.522': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_522:0' shape=(None,) dtype=float32>), 'data:0.523': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_523:0' shape=(None,) dtype=float32>), 'data:0.524': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_524:0' shape=(None,) dtype=float32>), 'data:0.525': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_525:0' shape=(None,) dtype=float32>), 'data:0.526': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_526:0' shape=(None,) dtype=float32>), 'data:0.527': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_527:0' shape=(None,) dtype=float32>), 'data:0.528': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_528:0' shape=(None,) dtype=float32>), 'data:0.529': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_529:0' shape=(None,) dtype=float32>), 'data:0.530': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_530:0' shape=(None,) dtype=float32>), 'data:0.531': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_531:0' shape=(None,) dtype=float32>), 'data:0.532': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_532:0' shape=(None,) dtype=float32>), 'data:0.533': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_533:0' shape=(None,) dtype=float32>), 'data:0.534': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_534:0' shape=(None,) dtype=float32>), 'data:0.535': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_535:0' shape=(None,) dtype=float32>), 'data:0.536': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_536:0' shape=(None,) dtype=float32>), 'data:0.537': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_537:0' shape=(None,) dtype=float32>), 'data:0.538': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_538:0' shape=(None,) dtype=float32>), 'data:0.539': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_539:0' shape=(None,) dtype=float32>), 'data:0.540': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_540:0' shape=(None,) dtype=float32>), 'data:0.541': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_541:0' shape=(None,) dtype=float32>), 'data:0.542': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_542:0' shape=(None,) dtype=float32>), 'data:0.543': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_543:0' shape=(None,) dtype=float32>), 'data:0.544': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_544:0' shape=(None,) dtype=float32>), 'data:0.545': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_545:0' shape=(None,) dtype=float32>), 'data:0.546': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_546:0' shape=(None,) dtype=float32>), 'data:0.547': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_547:0' shape=(None,) dtype=float32>), 'data:0.548': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_548:0' shape=(None,) dtype=float32>), 'data:0.549': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_549:0' shape=(None,) dtype=float32>), 'data:0.550': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_550:0' shape=(None,) dtype=float32>), 'data:0.551': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_551:0' shape=(None,) dtype=float32>), 'data:0.552': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_552:0' shape=(None,) dtype=float32>), 'data:0.553': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_553:0' shape=(None,) dtype=float32>), 'data:0.554': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_554:0' shape=(None,) dtype=float32>), 'data:0.555': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_555:0' shape=(None,) dtype=float32>), 'data:0.556': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_556:0' shape=(None,) dtype=float32>), 'data:0.557': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_557:0' shape=(None,) dtype=float32>), 'data:0.558': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_558:0' shape=(None,) dtype=float32>), 'data:0.559': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_559:0' shape=(None,) dtype=float32>), 'data:0.560': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_560:0' shape=(None,) dtype=float32>), 'data:0.561': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_561:0' shape=(None,) dtype=float32>), 'data:0.562': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_562:0' shape=(None,) dtype=float32>), 'data:0.563': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_563:0' shape=(None,) dtype=float32>), 'data:0.564': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_564:0' shape=(None,) dtype=float32>), 'data:0.565': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_565:0' shape=(None,) dtype=float32>), 'data:0.566': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_566:0' shape=(None,) dtype=float32>), 'data:0.567': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_567:0' shape=(None,) dtype=float32>), 'data:0.568': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_568:0' shape=(None,) dtype=float32>), 'data:0.569': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_569:0' shape=(None,) dtype=float32>), 'data:0.570': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_570:0' shape=(None,) dtype=float32>), 'data:0.571': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_571:0' shape=(None,) dtype=float32>), 'data:0.572': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_572:0' shape=(None,) dtype=float32>), 'data:0.573': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_573:0' shape=(None,) dtype=float32>), 'data:0.574': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_574:0' shape=(None,) dtype=float32>), 'data:0.575': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_575:0' shape=(None,) dtype=float32>), 'data:0.576': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_576:0' shape=(None,) dtype=float32>), 'data:0.577': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_577:0' shape=(None,) dtype=float32>), 'data:0.578': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_578:0' shape=(None,) dtype=float32>), 'data:0.579': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_579:0' shape=(None,) dtype=float32>), 'data:0.580': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_580:0' shape=(None,) dtype=float32>), 'data:0.581': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_581:0' shape=(None,) dtype=float32>), 'data:0.582': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_582:0' shape=(None,) dtype=float32>), 'data:0.583': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_583:0' shape=(None,) dtype=float32>), 'data:0.584': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_584:0' shape=(None,) dtype=float32>), 'data:0.585': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_585:0' shape=(None,) dtype=float32>), 'data:0.586': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_586:0' shape=(None,) dtype=float32>), 'data:0.587': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_587:0' shape=(None,) dtype=float32>), 'data:0.588': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_588:0' shape=(None,) dtype=float32>), 'data:0.589': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_589:0' shape=(None,) dtype=float32>), 'data:0.590': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_590:0' shape=(None,) dtype=float32>), 'data:0.591': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_591:0' shape=(None,) dtype=float32>), 'data:0.592': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_592:0' shape=(None,) dtype=float32>), 'data:0.593': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_593:0' shape=(None,) dtype=float32>), 'data:0.594': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_594:0' shape=(None,) dtype=float32>), 'data:0.595': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_595:0' shape=(None,) dtype=float32>), 'data:0.596': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_596:0' shape=(None,) dtype=float32>), 'data:0.597': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_597:0' shape=(None,) dtype=float32>), 'data:0.598': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_598:0' shape=(None,) dtype=float32>), 'data:0.599': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_599:0' shape=(None,) dtype=float32>), 'data:0.600': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_600:0' shape=(None,) dtype=float32>), 'data:0.601': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_601:0' shape=(None,) dtype=float32>), 'data:0.602': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_602:0' shape=(None,) dtype=float32>), 'data:0.603': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_603:0' shape=(None,) dtype=float32>), 'data:0.604': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_604:0' shape=(None,) dtype=float32>), 'data:0.605': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_605:0' shape=(None,) dtype=float32>), 'data:0.606': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_606:0' shape=(None,) dtype=float32>), 'data:0.607': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_607:0' shape=(None,) dtype=float32>), 'data:0.608': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_608:0' shape=(None,) dtype=float32>), 'data:0.609': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_609:0' shape=(None,) dtype=float32>), 'data:0.610': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_610:0' shape=(None,) dtype=float32>), 'data:0.611': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_611:0' shape=(None,) dtype=float32>), 'data:0.612': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_612:0' shape=(None,) dtype=float32>), 'data:0.613': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_613:0' shape=(None,) dtype=float32>), 'data:0.614': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_614:0' shape=(None,) dtype=float32>), 'data:0.615': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_615:0' shape=(None,) dtype=float32>), 'data:0.616': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_616:0' shape=(None,) dtype=float32>), 'data:0.617': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_617:0' shape=(None,) dtype=float32>), 'data:0.618': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_618:0' shape=(None,) dtype=float32>), 'data:0.619': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_619:0' shape=(None,) dtype=float32>), 'data:0.620': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_620:0' shape=(None,) dtype=float32>), 'data:0.621': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_621:0' shape=(None,) dtype=float32>), 'data:0.622': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_622:0' shape=(None,) dtype=float32>), 'data:0.623': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_623:0' shape=(None,) dtype=float32>), 'data:0.624': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_624:0' shape=(None,) dtype=float32>), 'data:0.625': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_625:0' shape=(None,) dtype=float32>), 'data:0.626': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_626:0' shape=(None,) dtype=float32>), 'data:0.627': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_627:0' shape=(None,) dtype=float32>), 'data:0.628': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_628:0' shape=(None,) dtype=float32>), 'data:0.629': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_629:0' shape=(None,) dtype=float32>), 'data:0.630': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_630:0' shape=(None,) dtype=float32>), 'data:0.631': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_631:0' shape=(None,) dtype=float32>), 'data:0.632': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_632:0' shape=(None,) dtype=float32>), 'data:0.633': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_633:0' shape=(None,) dtype=float32>), 'data:0.634': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_634:0' shape=(None,) dtype=float32>), 'data:0.635': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_635:0' shape=(None,) dtype=float32>), 'data:0.636': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_636:0' shape=(None,) dtype=float32>), 'data:0.637': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_637:0' shape=(None,) dtype=float32>), 'data:0.638': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_638:0' shape=(None,) dtype=float32>), 'data:0.639': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_639:0' shape=(None,) dtype=float32>), 'data:0.640': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_640:0' shape=(None,) dtype=float32>), 'data:0.641': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_641:0' shape=(None,) dtype=float32>), 'data:0.642': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_642:0' shape=(None,) dtype=float32>), 'data:0.643': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_643:0' shape=(None,) dtype=float32>), 'data:0.644': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_644:0' shape=(None,) dtype=float32>), 'data:0.645': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_645:0' shape=(None,) dtype=float32>), 'data:0.646': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_646:0' shape=(None,) dtype=float32>), 'data:0.647': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_647:0' shape=(None,) dtype=float32>), 'data:0.648': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_648:0' shape=(None,) dtype=float32>), 'data:0.649': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_649:0' shape=(None,) dtype=float32>), 'data:0.650': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_650:0' shape=(None,) dtype=float32>), 'data:0.651': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_651:0' shape=(None,) dtype=float32>), 'data:0.652': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_652:0' shape=(None,) dtype=float32>), 'data:0.653': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_653:0' shape=(None,) dtype=float32>), 'data:0.654': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_654:0' shape=(None,) dtype=float32>), 'data:0.655': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_655:0' shape=(None,) dtype=float32>), 'data:0.656': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_656:0' shape=(None,) dtype=float32>), 'data:0.657': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_657:0' shape=(None,) dtype=float32>), 'data:0.658': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_658:0' shape=(None,) dtype=float32>), 'data:0.659': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_659:0' shape=(None,) dtype=float32>), 'data:0.660': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_660:0' shape=(None,) dtype=float32>), 'data:0.661': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_661:0' shape=(None,) dtype=float32>), 'data:0.662': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_662:0' shape=(None,) dtype=float32>), 'data:0.663': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_663:0' shape=(None,) dtype=float32>), 'data:0.664': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_664:0' shape=(None,) dtype=float32>), 'data:0.665': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_665:0' shape=(None,) dtype=float32>), 'data:0.666': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_666:0' shape=(None,) dtype=float32>), 'data:0.667': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_667:0' shape=(None,) dtype=float32>), 'data:0.668': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_668:0' shape=(None,) dtype=float32>), 'data:0.669': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_669:0' shape=(None,) dtype=float32>), 'data:0.670': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_670:0' shape=(None,) dtype=float32>), 'data:0.671': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_671:0' shape=(None,) dtype=float32>), 'data:0.672': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_672:0' shape=(None,) dtype=float32>), 'data:0.673': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_673:0' shape=(None,) dtype=float32>), 'data:0.674': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_674:0' shape=(None,) dtype=float32>), 'data:0.675': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_675:0' shape=(None,) dtype=float32>), 'data:0.676': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_676:0' shape=(None,) dtype=float32>), 'data:0.677': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_677:0' shape=(None,) dtype=float32>), 'data:0.678': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_678:0' shape=(None,) dtype=float32>), 'data:0.679': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_679:0' shape=(None,) dtype=float32>), 'data:0.680': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_680:0' shape=(None,) dtype=float32>), 'data:0.681': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_681:0' shape=(None,) dtype=float32>), 'data:0.682': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_682:0' shape=(None,) dtype=float32>), 'data:0.683': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_683:0' shape=(None,) dtype=float32>), 'data:0.684': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_684:0' shape=(None,) dtype=float32>), 'data:0.685': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_685:0' shape=(None,) dtype=float32>), 'data:0.686': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_686:0' shape=(None,) dtype=float32>), 'data:0.687': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_687:0' shape=(None,) dtype=float32>), 'data:0.688': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_688:0' shape=(None,) dtype=float32>), 'data:0.689': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_689:0' shape=(None,) dtype=float32>), 'data:0.690': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_690:0' shape=(None,) dtype=float32>), 'data:0.691': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_691:0' shape=(None,) dtype=float32>), 'data:0.692': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_692:0' shape=(None,) dtype=float32>), 'data:0.693': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_693:0' shape=(None,) dtype=float32>), 'data:0.694': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_694:0' shape=(None,) dtype=float32>), 'data:0.695': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_695:0' shape=(None,) dtype=float32>), 'data:0.696': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_696:0' shape=(None,) dtype=float32>), 'data:0.697': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_697:0' shape=(None,) dtype=float32>), 'data:0.698': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_698:0' shape=(None,) dtype=float32>), 'data:0.699': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_699:0' shape=(None,) dtype=float32>), 'data:0.700': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_700:0' shape=(None,) dtype=float32>), 'data:0.701': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_701:0' shape=(None,) dtype=float32>), 'data:0.702': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_702:0' shape=(None,) dtype=float32>), 'data:0.703': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_703:0' shape=(None,) dtype=float32>), 'data:0.704': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_704:0' shape=(None,) dtype=float32>), 'data:0.705': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_705:0' shape=(None,) dtype=float32>), 'data:0.706': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_706:0' shape=(None,) dtype=float32>), 'data:0.707': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_707:0' shape=(None,) dtype=float32>), 'data:0.708': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_708:0' shape=(None,) dtype=float32>), 'data:0.709': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_709:0' shape=(None,) dtype=float32>), 'data:0.710': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_710:0' shape=(None,) dtype=float32>), 'data:0.711': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_711:0' shape=(None,) dtype=float32>), 'data:0.712': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_712:0' shape=(None,) dtype=float32>), 'data:0.713': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_713:0' shape=(None,) dtype=float32>), 'data:0.714': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_714:0' shape=(None,) dtype=float32>), 'data:0.715': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_715:0' shape=(None,) dtype=float32>), 'data:0.716': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_716:0' shape=(None,) dtype=float32>), 'data:0.717': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_717:0' shape=(None,) dtype=float32>), 'data:0.718': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_718:0' shape=(None,) dtype=float32>), 'data:0.719': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_719:0' shape=(None,) dtype=float32>), 'data:0.720': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_720:0' shape=(None,) dtype=float32>), 'data:0.721': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_721:0' shape=(None,) dtype=float32>), 'data:0.722': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_722:0' shape=(None,) dtype=float32>), 'data:0.723': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_723:0' shape=(None,) dtype=float32>), 'data:0.724': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_724:0' shape=(None,) dtype=float32>), 'data:0.725': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_725:0' shape=(None,) dtype=float32>), 'data:0.726': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_726:0' shape=(None,) dtype=float32>), 'data:0.727': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_727:0' shape=(None,) dtype=float32>), 'data:0.728': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_728:0' shape=(None,) dtype=float32>), 'data:0.729': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_729:0' shape=(None,) dtype=float32>), 'data:0.730': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_730:0' shape=(None,) dtype=float32>), 'data:0.731': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_731:0' shape=(None,) dtype=float32>), 'data:0.732': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_732:0' shape=(None,) dtype=float32>), 'data:0.733': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_733:0' shape=(None,) dtype=float32>), 'data:0.734': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_734:0' shape=(None,) dtype=float32>), 'data:0.735': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_735:0' shape=(None,) dtype=float32>), 'data:0.736': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_736:0' shape=(None,) dtype=float32>), 'data:0.737': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_737:0' shape=(None,) dtype=float32>), 'data:0.738': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_738:0' shape=(None,) dtype=float32>), 'data:0.739': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_739:0' shape=(None,) dtype=float32>), 'data:0.740': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_740:0' shape=(None,) dtype=float32>), 'data:0.741': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_741:0' shape=(None,) dtype=float32>), 'data:0.742': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_742:0' shape=(None,) dtype=float32>), 'data:0.743': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_743:0' shape=(None,) dtype=float32>), 'data:0.744': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_744:0' shape=(None,) dtype=float32>), 'data:0.745': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_745:0' shape=(None,) dtype=float32>), 'data:0.746': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_746:0' shape=(None,) dtype=float32>), 'data:0.747': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_747:0' shape=(None,) dtype=float32>), 'data:0.748': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_748:0' shape=(None,) dtype=float32>), 'data:0.749': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_749:0' shape=(None,) dtype=float32>), 'data:0.750': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_750:0' shape=(None,) dtype=float32>), 'data:0.751': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_751:0' shape=(None,) dtype=float32>), 'data:0.752': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_752:0' shape=(None,) dtype=float32>), 'data:0.753': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_753:0' shape=(None,) dtype=float32>), 'data:0.754': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_754:0' shape=(None,) dtype=float32>), 'data:0.755': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_755:0' shape=(None,) dtype=float32>), 'data:0.756': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_756:0' shape=(None,) dtype=float32>), 'data:0.757': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_757:0' shape=(None,) dtype=float32>), 'data:0.758': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_758:0' shape=(None,) dtype=float32>), 'data:0.759': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_759:0' shape=(None,) dtype=float32>), 'data:0.760': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_760:0' shape=(None,) dtype=float32>), 'data:0.761': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_761:0' shape=(None,) dtype=float32>), 'data:0.762': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_762:0' shape=(None,) dtype=float32>), 'data:0.763': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_763:0' shape=(None,) dtype=float32>), 'data:0.764': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_764:0' shape=(None,) dtype=float32>), 'data:0.765': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_765:0' shape=(None,) dtype=float32>), 'data:0.766': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_766:0' shape=(None,) dtype=float32>), 'data:0.767': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_767:0' shape=(None,) dtype=float32>), 'data:0.768': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_768:0' shape=(None,) dtype=float32>), 'data:0.769': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_769:0' shape=(None,) dtype=float32>), 'data:0.770': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_770:0' shape=(None,) dtype=float32>), 'data:0.771': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_771:0' shape=(None,) dtype=float32>), 'data:0.772': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_772:0' shape=(None,) dtype=float32>), 'data:0.773': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_773:0' shape=(None,) dtype=float32>), 'data:0.774': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_774:0' shape=(None,) dtype=float32>), 'data:0.775': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_775:0' shape=(None,) dtype=float32>), 'data:0.776': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_776:0' shape=(None,) dtype=float32>), 'data:0.777': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_777:0' shape=(None,) dtype=float32>), 'data:0.778': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_778:0' shape=(None,) dtype=float32>), 'data:0.779': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_779:0' shape=(None,) dtype=float32>), 'data:0.780': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_780:0' shape=(None,) dtype=float32>), 'data:0.781': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_781:0' shape=(None,) dtype=float32>), 'data:0.782': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_782:0' shape=(None,) dtype=float32>), 'data:0.783': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_783:0' shape=(None,) dtype=float32>)}\n",
            "Num validation examples: tf.Tensor(8400, shape=(), dtype=int32)\n",
            "Validation dataset read in 0:00:06.796968. Found 8400 examples.\n",
            "Training model...\n",
            "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training get stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO 2023-01-06T04:56:06.388995478+00:00 kernel.cc:814] Start Yggdrasil model training\n",
            "[INFO 2023-01-06T04:56:06.389197887+00:00 kernel.cc:815] Collect training examples\n",
            "[INFO 2023-01-06T04:56:06.391559655+00:00 kernel.cc:423] Number of batches: 34\n",
            "[INFO 2023-01-06T04:56:06.391579827+00:00 kernel.cc:424] Number of examples: 33600\n",
            "[INFO 2023-01-06T04:56:06.618041369+00:00 kernel.cc:837] Training dataset:\n",
            "Number of records: 33600\n",
            "Number of columns: 785\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 784 (99.8726%)\n",
            "\tCATEGORICAL: 1 (0.127389%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 784 (99.8726%)\n",
            "\t0: \"data:0.0\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t1: \"data:0.1\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t2: \"data:0.10\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t3: \"data:0.100\" NUMERICAL mean:13.2333 min:0 max:255 sd:50.272\n",
            "\t4: \"data:0.101\" NUMERICAL mean:11.7187 min:0 max:255 sd:47.4442\n",
            "\t5: \"data:0.102\" NUMERICAL mean:9.41554 min:0 max:255 sd:42.8245\n",
            "\t6: \"data:0.103\" NUMERICAL mean:6.77077 min:0 max:255 sd:36.38\n",
            "\t7: \"data:0.104\" NUMERICAL mean:4.14527 min:0 max:255 sd:28.168\n",
            "\t8: \"data:0.105\" NUMERICAL mean:2.31202 min:0 max:255 sd:21.2715\n",
            "\t9: \"data:0.106\" NUMERICAL mean:1.12911 min:0 max:255 sd:14.3882\n",
            "\t10: \"data:0.107\" NUMERICAL mean:0.420685 min:0 max:255 sd:8.84718\n",
            "\t11: \"data:0.108\" NUMERICAL mean:0.149405 min:0 max:255 sd:5.13502\n",
            "\t12: \"data:0.109\" NUMERICAL mean:0.01875 min:0 max:164 sd:1.30742\n",
            "\t13: \"data:0.11\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t14: \"data:0.110\" NUMERICAL mean:0.00360119 min:0 max:121 sd:0.660099\n",
            "\t15: \"data:0.111\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t16: \"data:0.112\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t17: \"data:0.113\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t18: \"data:0.114\" NUMERICAL mean:0.00276786 min:0 max:51 sd:0.360421\n",
            "\t19: \"data:0.115\" NUMERICAL mean:0.0163393 min:0 max:114 sd:1.11867\n",
            "\t20: \"data:0.116\" NUMERICAL mean:0.0993155 min:0 max:226 sd:3.62315\n",
            "\t21: \"data:0.117\" NUMERICAL mean:0.37125 min:0 max:255 sd:7.55932\n",
            "\t22: \"data:0.118\" NUMERICAL mean:1.00393 min:0 max:255 sd:12.851\n",
            "\t23: \"data:0.119\" NUMERICAL mean:2.43589 min:0 max:255 sd:20.8386\n",
            "\t24: \"data:0.12\" NUMERICAL mean:0.00375 min:0 max:116 sd:0.635168\n",
            "\t25: \"data:0.120\" NUMERICAL mean:4.91244 min:0 max:255 sd:30.0281\n",
            "\t26: \"data:0.121\" NUMERICAL mean:8.58845 min:0 max:255 sd:39.9165\n",
            "\t27: \"data:0.122\" NUMERICAL mean:13.7393 min:0 max:255 sd:50.6209\n",
            "\t28: \"data:0.123\" NUMERICAL mean:20.2297 min:0 max:255 sd:61.0226\n",
            "\t29: \"data:0.124\" NUMERICAL mean:27.8787 min:0 max:255 sd:70.4341\n",
            "\t30: \"data:0.125\" NUMERICAL mean:35.9304 min:0 max:255 sd:78.5346\n",
            "\t31: \"data:0.126\" NUMERICAL mean:42.6863 min:0 max:255 sd:84.4186\n",
            "\t32: \"data:0.127\" NUMERICAL mean:46.154 min:0 max:255 sd:87.4092\n",
            "\t33: \"data:0.128\" NUMERICAL mean:44.4386 min:0 max:255 sd:85.5988\n",
            "\t34: \"data:0.129\" NUMERICAL mean:39.0466 min:0 max:255 sd:81.2863\n",
            "\t35: \"data:0.13\" NUMERICAL mean:0.0139881 min:0 max:254 sd:1.81893\n",
            "\t36: \"data:0.130\" NUMERICAL mean:31.1705 min:0 max:255 sd:73.8507\n",
            "\t37: \"data:0.131\" NUMERICAL mean:23.1585 min:0 max:255 sd:64.6733\n",
            "\t38: \"data:0.132\" NUMERICAL mean:15.1844 min:0 max:255 sd:52.9694\n",
            "\t39: \"data:0.133\" NUMERICAL mean:8.78417 min:0 max:255 sd:40.2925\n",
            "\t40: \"data:0.134\" NUMERICAL mean:4.45003 min:0 max:255 sd:28.3589\n",
            "\t41: \"data:0.135\" NUMERICAL mean:1.95869 min:0 max:255 sd:18.9636\n",
            "\t42: \"data:0.136\" NUMERICAL mean:0.768988 min:0 max:255 sd:11.4638\n",
            "\t43: \"data:0.137\" NUMERICAL mean:0.196667 min:0 max:254 sd:5.45324\n",
            "\t44: \"data:0.138\" NUMERICAL mean:0.0402976 min:0 max:230 sd:2.50354\n",
            "\t45: \"data:0.139\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t46: \"data:0.14\" NUMERICAL mean:0.00642857 min:0 max:216 sd:1.17836\n",
            "\t47: \"data:0.140\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t48: \"data:0.141\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t49: \"data:0.142\" NUMERICAL mean:0.00669643 min:0 max:90 sd:0.674658\n",
            "\t50: \"data:0.143\" NUMERICAL mean:0.0496429 min:0 max:255 sd:2.35878\n",
            "\t51: \"data:0.144\" NUMERICAL mean:0.418185 min:0 max:255 sd:7.94003\n",
            "\t52: \"data:0.145\" NUMERICAL mean:1.41714 min:0 max:255 sd:15.8437\n",
            "\t53: \"data:0.146\" NUMERICAL mean:3.49985 min:0 max:255 sd:25.2999\n",
            "\t54: \"data:0.147\" NUMERICAL mean:7.07196 min:0 max:255 sd:36.2063\n",
            "\t55: \"data:0.148\" NUMERICAL mean:12.8196 min:0 max:255 sd:48.7798\n",
            "\t56: \"data:0.149\" NUMERICAL mean:21.2897 min:0 max:255 sd:62.2433\n",
            "\t57: \"data:0.15\" NUMERICAL mean:0.000267857 min:0 max:9 sd:0.0490983\n",
            "\t58: \"data:0.150\" NUMERICAL mean:32.0189 min:0 max:255 sd:75.0748\n",
            "\t59: \"data:0.151\" NUMERICAL mean:44.8998 min:0 max:255 sd:86.3084\n",
            "\t60: \"data:0.152\" NUMERICAL mean:59.5261 min:0 max:255 sd:95.9175\n",
            "\t61: \"data:0.153\" NUMERICAL mean:74.4392 min:0 max:255 sd:103.261\n",
            "\t62: \"data:0.154\" NUMERICAL mean:85.9373 min:0 max:255 sd:107.423\n",
            "\t63: \"data:0.155\" NUMERICAL mean:91.3402 min:0 max:255 sd:108.694\n",
            "\t64: \"data:0.156\" NUMERICAL mean:89.2292 min:0 max:255 sd:107.93\n",
            "\t65: \"data:0.157\" NUMERICAL mean:80.0799 min:0 max:255 sd:105.127\n",
            "\t66: \"data:0.158\" NUMERICAL mean:65.8414 min:0 max:255 sd:98.9418\n",
            "\t67: \"data:0.159\" NUMERICAL mean:49.8855 min:0 max:255 sd:89.707\n",
            "\t68: \"data:0.16\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t69: \"data:0.160\" NUMERICAL mean:34.7812 min:0 max:255 sd:77.3094\n",
            "\t70: \"data:0.161\" NUMERICAL mean:21.6643 min:0 max:255 sd:62.1849\n",
            "\t71: \"data:0.162\" NUMERICAL mean:12.1369 min:0 max:255 sd:46.8912\n",
            "\t72: \"data:0.163\" NUMERICAL mean:6.14318 min:0 max:255 sd:33.2522\n",
            "\t73: \"data:0.164\" NUMERICAL mean:2.80119 min:0 max:255 sd:21.9552\n",
            "\t74: \"data:0.165\" NUMERICAL mean:0.779583 min:0 max:255 sd:10.9801\n",
            "\t75: \"data:0.166\" NUMERICAL mean:0.121101 min:0 max:253 sd:4.1272\n",
            "\t76: \"data:0.167\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t77: \"data:0.168\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t78: \"data:0.169\" NUMERICAL mean:0.000119048 min:0 max:4 sd:0.0218215\n",
            "\t79: \"data:0.17\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t80: \"data:0.170\" NUMERICAL mean:0.0193155 min:0 max:177 sd:1.38474\n",
            "\t81: \"data:0.171\" NUMERICAL mean:0.228899 min:0 max:255 sd:6.44702\n",
            "\t82: \"data:0.172\" NUMERICAL mean:1.12301 min:0 max:255 sd:14.149\n",
            "\t83: \"data:0.173\" NUMERICAL mean:3.20321 min:0 max:255 sd:24.4044\n",
            "\t84: \"data:0.174\" NUMERICAL mean:7.30449 min:0 max:255 sd:36.8635\n",
            "\t85: \"data:0.175\" NUMERICAL mean:14.0972 min:0 max:255 sd:51.4257\n",
            "\t86: \"data:0.176\" NUMERICAL mean:24.0375 min:0 max:255 sd:66.1253\n",
            "\t87: \"data:0.177\" NUMERICAL mean:37.7143 min:0 max:255 sd:80.7949\n",
            "\t88: \"data:0.178\" NUMERICAL mean:53.7581 min:0 max:255 sd:92.8485\n",
            "\t89: \"data:0.179\" NUMERICAL mean:71.4963 min:0 max:255 sd:101.76\n",
            "\t90: \"data:0.18\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t91: \"data:0.180\" NUMERICAL mean:89.8556 min:0 max:255 sd:107.823\n",
            "\t92: \"data:0.181\" NUMERICAL mean:107.271 min:0 max:255 sd:111.23\n",
            "\t93: \"data:0.182\" NUMERICAL mean:119.632 min:0 max:255 sd:112.279\n",
            "\t94: \"data:0.183\" NUMERICAL mean:124.799 min:0 max:255 sd:112.439\n",
            "\t95: \"data:0.184\" NUMERICAL mean:121.764 min:0 max:255 sd:112.488\n",
            "\t96: \"data:0.185\" NUMERICAL mean:111.389 min:0 max:255 sd:112.082\n",
            "\t97: \"data:0.186\" NUMERICAL mean:95.3919 min:0 max:255 sd:109.803\n",
            "\t98: \"data:0.187\" NUMERICAL mean:74.6796 min:0 max:255 sd:103.541\n",
            "\t99: \"data:0.188\" NUMERICAL mean:53.8843 min:0 max:255 sd:93.2454\n",
            "\t100: \"data:0.189\" NUMERICAL mean:35.1821 min:0 max:255 sd:77.9014\n",
            "\t101: \"data:0.19\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t102: \"data:0.190\" NUMERICAL mean:20.7718 min:0 max:255 sd:61.5451\n",
            "\t103: \"data:0.191\" NUMERICAL mean:11.0771 min:0 max:255 sd:45.1294\n",
            "\t104: \"data:0.192\" NUMERICAL mean:5.25476 min:0 max:255 sd:30.8072\n",
            "\t105: \"data:0.193\" NUMERICAL mean:1.78598 min:0 max:255 sd:17.4937\n",
            "\t106: \"data:0.194\" NUMERICAL mean:0.344613 min:0 max:254 sd:7.39828\n",
            "\t107: \"data:0.195\" NUMERICAL mean:0.0197619 min:0 max:172 sd:1.50668\n",
            "\t108: \"data:0.196\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t109: \"data:0.197\" NUMERICAL mean:0.0220238 min:0 max:128 sd:1.35754\n",
            "\t110: \"data:0.198\" NUMERICAL mean:0.118899 min:0 max:254 sd:4.25426\n",
            "\t111: \"data:0.199\" NUMERICAL mean:0.617827 min:0 max:255 sd:9.98078\n",
            "\t112: \"data:0.2\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t113: \"data:0.20\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t114: \"data:0.200\" NUMERICAL mean:2.45848 min:0 max:255 sd:21.1043\n",
            "\t115: \"data:0.201\" NUMERICAL mean:5.91214 min:0 max:255 sd:33.1764\n",
            "\t116: \"data:0.202\" NUMERICAL mean:12.3165 min:0 max:255 sd:47.877\n",
            "\t117: \"data:0.203\" NUMERICAL mean:22.3037 min:0 max:255 sd:63.6384\n",
            "\t118: \"data:0.204\" NUMERICAL mean:36.6659 min:0 max:255 sd:79.2549\n",
            "\t119: \"data:0.205\" NUMERICAL mean:54.7485 min:0 max:255 sd:92.8415\n",
            "\t120: \"data:0.206\" NUMERICAL mean:74.6517 min:0 max:255 sd:101.941\n",
            "\t121: \"data:0.207\" NUMERICAL mean:95.0867 min:0 max:255 sd:107.578\n",
            "\t122: \"data:0.208\" NUMERICAL mean:112.742 min:0 max:255 sd:109.909\n",
            "\t123: \"data:0.209\" NUMERICAL mean:126.306 min:0 max:255 sd:110.57\n",
            "\t124: \"data:0.21\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t125: \"data:0.210\" NUMERICAL mean:133.766 min:0 max:255 sd:110.536\n",
            "\t126: \"data:0.211\" NUMERICAL mean:135.55 min:0 max:255 sd:110.061\n",
            "\t127: \"data:0.212\" NUMERICAL mean:132.8 min:0 max:255 sd:110.081\n",
            "\t128: \"data:0.213\" NUMERICAL mean:125.878 min:0 max:255 sd:110.671\n",
            "\t129: \"data:0.214\" NUMERICAL mean:112.529 min:0 max:255 sd:110.799\n",
            "\t130: \"data:0.215\" NUMERICAL mean:92.6063 min:0 max:255 sd:108.467\n",
            "\t131: \"data:0.216\" NUMERICAL mean:68.9234 min:0 max:255 sd:100.689\n",
            "\t132: \"data:0.217\" NUMERICAL mean:46.3398 min:0 max:255 sd:87.4366\n",
            "\t133: \"data:0.218\" NUMERICAL mean:27.7884 min:0 max:255 sd:70.3725\n",
            "\t134: \"data:0.219\" NUMERICAL mean:14.97 min:0 max:255 sd:52.4725\n",
            "\t135: \"data:0.22\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t136: \"data:0.220\" NUMERICAL mean:6.92673 min:0 max:255 sd:35.3587\n",
            "\t137: \"data:0.221\" NUMERICAL mean:2.50339 min:0 max:255 sd:21.0216\n",
            "\t138: \"data:0.222\" NUMERICAL mean:0.500804 min:0 max:255 sd:9.04059\n",
            "\t139: \"data:0.223\" NUMERICAL mean:0.021994 min:0 max:196 sd:1.7383\n",
            "\t140: \"data:0.224\" NUMERICAL mean:0.00157738 min:0 max:53 sd:0.289134\n",
            "\t141: \"data:0.225\" NUMERICAL mean:0.0725298 min:0 max:255 sd:3.55659\n",
            "\t142: \"data:0.226\" NUMERICAL mean:0.400149 min:0 max:255 sd:8.56423\n",
            "\t143: \"data:0.227\" NUMERICAL mean:1.39827 min:0 max:255 sd:16.1441\n",
            "\t144: \"data:0.228\" NUMERICAL mean:3.99101 min:0 max:255 sd:27.6336\n",
            "\t145: \"data:0.229\" NUMERICAL mean:8.6686 min:0 max:255 sd:40.6518\n",
            "\t146: \"data:0.23\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t147: \"data:0.230\" NUMERICAL mean:16.7934 min:0 max:255 sd:55.9991\n",
            "\t148: \"data:0.231\" NUMERICAL mean:29.6658 min:0 max:255 sd:72.6435\n",
            "\t149: \"data:0.232\" NUMERICAL mean:47.471 min:0 max:255 sd:88.4948\n",
            "\t150: \"data:0.233\" NUMERICAL mean:69.0889 min:0 max:255 sd:100.482\n",
            "\t151: \"data:0.234\" NUMERICAL mean:91.8268 min:0 max:255 sd:107.779\n",
            "\t152: \"data:0.235\" NUMERICAL mean:110.038 min:0 max:255 sd:110.848\n",
            "\t153: \"data:0.236\" NUMERICAL mean:120.638 min:0 max:255 sd:111.281\n",
            "\t154: \"data:0.237\" NUMERICAL mean:124.28 min:0 max:255 sd:111.643\n",
            "\t155: \"data:0.238\" NUMERICAL mean:123.652 min:0 max:255 sd:111.263\n",
            "\t156: \"data:0.239\" NUMERICAL mean:122.044 min:0 max:255 sd:110.855\n",
            "\t157: \"data:0.24\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t158: \"data:0.240\" NUMERICAL mean:122.256 min:0 max:255 sd:110.89\n",
            "\t159: \"data:0.241\" NUMERICAL mean:121.854 min:0 max:255 sd:111.056\n",
            "\t160: \"data:0.242\" NUMERICAL mean:116.048 min:0 max:255 sd:111.591\n",
            "\t161: \"data:0.243\" NUMERICAL mean:100.104 min:0 max:255 sd:110.26\n",
            "\t162: \"data:0.244\" NUMERICAL mean:76.7196 min:0 max:255 sd:104.366\n",
            "\t163: \"data:0.245\" NUMERICAL mean:52.0546 min:0 max:255 sd:91.9815\n",
            "\t164: \"data:0.246\" NUMERICAL mean:31.1459 min:0 max:255 sd:74.4165\n",
            "\t165: \"data:0.247\" NUMERICAL mean:16.0286 min:0 max:255 sd:54.2566\n",
            "\t166: \"data:0.248\" NUMERICAL mean:6.96557 min:0 max:255 sd:35.804\n",
            "\t167: \"data:0.249\" NUMERICAL mean:2.58533 min:0 max:255 sd:21.4784\n",
            "\t168: \"data:0.25\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t169: \"data:0.250\" NUMERICAL mean:0.511488 min:0 max:254 sd:8.99263\n",
            "\t170: \"data:0.251\" NUMERICAL mean:0.0195238 min:0 max:190 sd:1.67365\n",
            "\t171: \"data:0.252\" NUMERICAL mean:0.00776786 min:0 max:184 sd:1.08813\n",
            "\t172: \"data:0.253\" NUMERICAL mean:0.0997917 min:0 max:254 sd:4.20965\n",
            "\t173: \"data:0.254\" NUMERICAL mean:0.571577 min:0 max:255 sd:10.3319\n",
            "\t174: \"data:0.255\" NUMERICAL mean:1.79905 min:0 max:255 sd:18.854\n",
            "\t175: \"data:0.256\" NUMERICAL mean:4.67354 min:0 max:255 sd:30.305\n",
            "\t176: \"data:0.257\" NUMERICAL mean:9.87274 min:0 max:255 sd:43.6387\n",
            "\t177: \"data:0.258\" NUMERICAL mean:19.5085 min:0 max:255 sd:60.2835\n",
            "\t178: \"data:0.259\" NUMERICAL mean:34.4873 min:0 max:255 sd:77.9341\n",
            "\t179: \"data:0.26\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t180: \"data:0.260\" NUMERICAL mean:55.4258 min:0 max:255 sd:94.0767\n",
            "\t181: \"data:0.261\" NUMERICAL mean:79.6252 min:0 max:255 sd:104.929\n",
            "\t182: \"data:0.262\" NUMERICAL mean:100.618 min:0 max:255 sd:110.377\n",
            "\t183: \"data:0.263\" NUMERICAL mean:111.91 min:0 max:255 sd:111.634\n",
            "\t184: \"data:0.264\" NUMERICAL mean:111.491 min:0 max:255 sd:111.353\n",
            "\t185: \"data:0.265\" NUMERICAL mean:104.707 min:0 max:255 sd:110.001\n",
            "\t186: \"data:0.266\" NUMERICAL mean:99.0466 min:0 max:255 sd:108.915\n",
            "\t187: \"data:0.267\" NUMERICAL mean:99.0812 min:0 max:255 sd:108.694\n",
            "\t188: \"data:0.268\" NUMERICAL mean:104.018 min:0 max:255 sd:109.163\n",
            "\t189: \"data:0.269\" NUMERICAL mean:110.753 min:0 max:255 sd:110.489\n",
            "\t190: \"data:0.27\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t191: \"data:0.270\" NUMERICAL mean:111.193 min:0 max:255 sd:111.33\n",
            "\t192: \"data:0.271\" NUMERICAL mean:98.9119 min:0 max:255 sd:109.964\n",
            "\t193: \"data:0.272\" NUMERICAL mean:76.7089 min:0 max:255 sd:104.413\n",
            "\t194: \"data:0.273\" NUMERICAL mean:52.1287 min:0 max:255 sd:92.3131\n",
            "\t195: \"data:0.274\" NUMERICAL mean:30.8163 min:0 max:255 sd:74.0777\n",
            "\t196: \"data:0.275\" NUMERICAL mean:15.118 min:0 max:255 sd:52.788\n",
            "\t197: \"data:0.276\" NUMERICAL mean:5.94437 min:0 max:255 sd:32.9051\n",
            "\t198: \"data:0.277\" NUMERICAL mean:1.89702 min:0 max:255 sd:17.919\n",
            "\t199: \"data:0.278\" NUMERICAL mean:0.365982 min:0 max:254 sd:7.64523\n",
            "\t200: \"data:0.279\" NUMERICAL mean:0.0325893 min:0 max:220 sd:2.20238\n",
            "\t201: \"data:0.28\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t202: \"data:0.280\" NUMERICAL mean:0.011875 min:0 max:214 sd:1.54319\n",
            "\t203: \"data:0.281\" NUMERICAL mean:0.0947024 min:0 max:254 sd:4.29244\n",
            "\t204: \"data:0.282\" NUMERICAL mean:0.558214 min:0 max:255 sd:10.2423\n",
            "\t205: \"data:0.283\" NUMERICAL mean:1.72378 min:0 max:255 sd:18.3588\n",
            "\t206: \"data:0.284\" NUMERICAL mean:4.27964 min:0 max:255 sd:28.9055\n",
            "\t207: \"data:0.285\" NUMERICAL mean:9.74812 min:0 max:255 sd:43.1828\n",
            "\t208: \"data:0.286\" NUMERICAL mean:20.3891 min:0 max:255 sd:61.6249\n",
            "\t209: \"data:0.287\" NUMERICAL mean:37.2137 min:0 max:255 sd:80.2432\n",
            "\t210: \"data:0.288\" NUMERICAL mean:60.8012 min:0 max:255 sd:96.9511\n",
            "\t211: \"data:0.289\" NUMERICAL mean:84.9652 min:0 max:255 sd:107.032\n",
            "\t212: \"data:0.29\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t213: \"data:0.290\" NUMERICAL mean:101.641 min:0 max:255 sd:110.639\n",
            "\t214: \"data:0.291\" NUMERICAL mean:103.713 min:0 max:255 sd:110.68\n",
            "\t215: \"data:0.292\" NUMERICAL mean:93.5142 min:0 max:255 sd:107.702\n",
            "\t216: \"data:0.293\" NUMERICAL mean:82.7232 min:0 max:255 sd:104.037\n",
            "\t217: \"data:0.294\" NUMERICAL mean:79.5449 min:0 max:255 sd:103.048\n",
            "\t218: \"data:0.295\" NUMERICAL mean:84.4516 min:0 max:255 sd:105.33\n",
            "\t219: \"data:0.296\" NUMERICAL mean:93.903 min:0 max:255 sd:107.321\n",
            "\t220: \"data:0.297\" NUMERICAL mean:104.491 min:0 max:255 sd:109.842\n",
            "\t221: \"data:0.298\" NUMERICAL mean:106.404 min:0 max:255 sd:110.577\n",
            "\t222: \"data:0.299\" NUMERICAL mean:94.016 min:0 max:255 sd:109.215\n",
            "\t223: \"data:0.3\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t224: \"data:0.30\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t225: \"data:0.300\" NUMERICAL mean:71.3092 min:0 max:255 sd:102.367\n",
            "\t226: \"data:0.301\" NUMERICAL mean:47.937 min:0 max:255 sd:89.5763\n",
            "\t227: \"data:0.302\" NUMERICAL mean:28.1551 min:0 max:255 sd:71.4684\n",
            "\t228: \"data:0.303\" NUMERICAL mean:13.5699 min:0 max:255 sd:50.1216\n",
            "\t229: \"data:0.304\" NUMERICAL mean:4.65289 min:0 max:255 sd:28.8682\n",
            "\t230: \"data:0.305\" NUMERICAL mean:1.13485 min:0 max:255 sd:14.0808\n",
            "\t231: \"data:0.306\" NUMERICAL mean:0.209911 min:0 max:253 sd:5.96017\n",
            "\t232: \"data:0.307\" NUMERICAL mean:0.026875 min:0 max:243 sd:2.15719\n",
            "\t233: \"data:0.308\" NUMERICAL mean:0.00678571 min:0 max:150 sd:0.880551\n",
            "\t234: \"data:0.309\" NUMERICAL mean:0.0734821 min:0 max:254 sd:3.58954\n",
            "\t235: \"data:0.31\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t236: \"data:0.310\" NUMERICAL mean:0.451935 min:0 max:255 sd:9.17839\n",
            "\t237: \"data:0.311\" NUMERICAL mean:1.28625 min:0 max:255 sd:15.6125\n",
            "\t238: \"data:0.312\" NUMERICAL mean:3.52604 min:0 max:255 sd:26.0352\n",
            "\t239: \"data:0.313\" NUMERICAL mean:9.38571 min:0 max:255 sd:41.8994\n",
            "\t240: \"data:0.314\" NUMERICAL mean:20.9322 min:0 max:255 sd:62.2495\n",
            "\t241: \"data:0.315\" NUMERICAL mean:39.8388 min:0 max:255 sd:82.3651\n",
            "\t242: \"data:0.316\" NUMERICAL mean:64.9899 min:0 max:255 sd:99.3376\n",
            "\t243: \"data:0.317\" NUMERICAL mean:88.4617 min:0 max:255 sd:107.996\n",
            "\t244: \"data:0.318\" NUMERICAL mean:99.761 min:0 max:255 sd:110.37\n",
            "\t245: \"data:0.319\" NUMERICAL mean:94.9794 min:0 max:255 sd:108.925\n",
            "\t246: \"data:0.32\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t247: \"data:0.320\" NUMERICAL mean:81.5213 min:0 max:255 sd:104.102\n",
            "\t248: \"data:0.321\" NUMERICAL mean:73.6097 min:0 max:255 sd:100.319\n",
            "\t249: \"data:0.322\" NUMERICAL mean:76.5928 min:0 max:255 sd:103.114\n",
            "\t250: \"data:0.323\" NUMERICAL mean:86.0317 min:0 max:255 sd:106.686\n",
            "\t251: \"data:0.324\" NUMERICAL mean:97.9551 min:0 max:255 sd:108.044\n",
            "\t252: \"data:0.325\" NUMERICAL mean:107.941 min:0 max:255 sd:110.125\n",
            "\t253: \"data:0.326\" NUMERICAL mean:105.516 min:0 max:255 sd:110.47\n",
            "\t254: \"data:0.327\" NUMERICAL mean:88.5035 min:0 max:255 sd:107.732\n",
            "\t255: \"data:0.328\" NUMERICAL mean:64.6729 min:0 max:255 sd:99.0022\n",
            "\t256: \"data:0.329\" NUMERICAL mean:42.3384 min:0 max:255 sd:84.9236\n",
            "\t257: \"data:0.33\" NUMERICAL mean:0.000238095 min:0 max:8 sd:0.0436429\n",
            "\t258: \"data:0.330\" NUMERICAL mean:25.2057 min:0 max:255 sd:68.5474\n",
            "\t259: \"data:0.331\" NUMERICAL mean:12.6235 min:0 max:255 sd:48.8672\n",
            "\t260: \"data:0.332\" NUMERICAL mean:4.09039 min:0 max:255 sd:27.0418\n",
            "\t261: \"data:0.333\" NUMERICAL mean:0.640357 min:0 max:255 sd:10.0926\n",
            "\t262: \"data:0.334\" NUMERICAL mean:0.118185 min:0 max:253 sd:4.15236\n",
            "\t263: \"data:0.335\" NUMERICAL mean:0.00535714 min:0 max:82 sd:0.545082\n",
            "\t264: \"data:0.336\" NUMERICAL mean:0.00485119 min:0 max:163 sd:0.889225\n",
            "\t265: \"data:0.337\" NUMERICAL mean:0.0361905 min:0 max:225 sd:2.44426\n",
            "\t266: \"data:0.338\" NUMERICAL mean:0.27256 min:0 max:255 sd:7.08926\n",
            "\t267: \"data:0.339\" NUMERICAL mean:0.879405 min:0 max:255 sd:12.9391\n",
            "\t268: \"data:0.34\" NUMERICAL mean:0.0131845 min:0 max:157 sd:1.26521\n",
            "\t269: \"data:0.340\" NUMERICAL mean:2.93946 min:0 max:255 sd:23.5696\n",
            "\t270: \"data:0.341\" NUMERICAL mean:9.51128 min:0 max:255 sd:42.1695\n",
            "\t271: \"data:0.342\" NUMERICAL mean:22.671 min:0 max:255 sd:64.6793\n",
            "\t272: \"data:0.343\" NUMERICAL mean:43.6721 min:0 max:255 sd:85.8951\n",
            "\t273: \"data:0.344\" NUMERICAL mean:69.311 min:0 max:255 sd:101.663\n",
            "\t274: \"data:0.345\" NUMERICAL mean:90.9941 min:0 max:255 sd:109.099\n",
            "\t275: \"data:0.346\" NUMERICAL mean:98.7588 min:0 max:255 sd:110.579\n",
            "\t276: \"data:0.347\" NUMERICAL mean:91.52 min:0 max:255 sd:108.391\n",
            "\t277: \"data:0.348\" NUMERICAL mean:79.8767 min:0 max:255 sd:104.154\n",
            "\t278: \"data:0.349\" NUMERICAL mean:80.0765 min:0 max:255 sd:103.556\n",
            "\t279: \"data:0.35\" NUMERICAL mean:0.0336905 min:0 max:254 sd:2.58206\n",
            "\t280: \"data:0.350\" NUMERICAL mean:89.7877 min:0 max:255 sd:108.984\n",
            "\t281: \"data:0.351\" NUMERICAL mean:102.345 min:0 max:255 sd:111.047\n",
            "\t282: \"data:0.352\" NUMERICAL mean:113.959 min:0 max:255 sd:110.015\n",
            "\t283: \"data:0.353\" NUMERICAL mean:118.248 min:0 max:255 sd:111.227\n",
            "\t284: \"data:0.354\" NUMERICAL mean:107.666 min:0 max:255 sd:111.129\n",
            "\t285: \"data:0.355\" NUMERICAL mean:84.2387 min:0 max:255 sd:106.211\n",
            "\t286: \"data:0.356\" NUMERICAL mean:58.3371 min:0 max:255 sd:94.9685\n",
            "\t287: \"data:0.357\" NUMERICAL mean:38.3356 min:0 max:255 sd:81.5518\n",
            "\t288: \"data:0.358\" NUMERICAL mean:23.8837 min:0 max:255 sd:67.139\n",
            "\t289: \"data:0.359\" NUMERICAL mean:12.8812 min:0 max:255 sd:50.0675\n",
            "\t290: \"data:0.36\" NUMERICAL mean:0.0518155 min:0 max:255 sd:3.15512\n",
            "\t291: \"data:0.360\" NUMERICAL mean:4.36574 min:0 max:255 sd:28.2471\n",
            "\t292: \"data:0.361\" NUMERICAL mean:0.469345 min:0 max:255 sd:8.66619\n",
            "\t293: \"data:0.362\" NUMERICAL mean:0.0684524 min:0 max:243 sd:3.35821\n",
            "\t294: \"data:0.363\" NUMERICAL mean:0.00892857 min:0 max:110 sd:0.888607\n",
            "\t295: \"data:0.364\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t296: \"data:0.365\" NUMERICAL mean:0.0141667 min:0 max:253 sd:1.54524\n",
            "\t297: \"data:0.366\" NUMERICAL mean:0.131012 min:0 max:255 sd:5.0138\n",
            "\t298: \"data:0.367\" NUMERICAL mean:0.60622 min:0 max:255 sd:10.7424\n",
            "\t299: \"data:0.368\" NUMERICAL mean:2.80845 min:0 max:255 sd:22.8349\n",
            "\t300: \"data:0.369\" NUMERICAL mean:10.7111 min:0 max:255 sd:44.8292\n",
            "\t301: \"data:0.37\" NUMERICAL mean:0.058244 min:0 max:226 sd:2.87676\n",
            "\t302: \"data:0.370\" NUMERICAL mean:25.5399 min:0 max:255 sd:68.5123\n",
            "\t303: \"data:0.371\" NUMERICAL mean:47.669 min:0 max:255 sd:89.3994\n",
            "\t304: \"data:0.372\" NUMERICAL mean:72.5739 min:0 max:255 sd:103.295\n",
            "\t305: \"data:0.373\" NUMERICAL mean:91.878 min:0 max:255 sd:109.569\n",
            "\t306: \"data:0.374\" NUMERICAL mean:97.4444 min:0 max:255 sd:110.343\n",
            "\t307: \"data:0.375\" NUMERICAL mean:91.266 min:0 max:255 sd:108.483\n",
            "\t308: \"data:0.376\" NUMERICAL mean:86.766 min:0 max:255 sd:106.489\n",
            "\t309: \"data:0.377\" NUMERICAL mean:96.9774 min:0 max:255 sd:108.628\n",
            "\t310: \"data:0.378\" NUMERICAL mean:111.551 min:0 max:255 sd:113.758\n",
            "\t311: \"data:0.379\" NUMERICAL mean:124.426 min:0 max:255 sd:111.68\n",
            "\t312: \"data:0.38\" NUMERICAL mean:0.112738 min:0 max:255 sd:4.77002\n",
            "\t313: \"data:0.380\" NUMERICAL mean:130.512 min:0 max:255 sd:110.083\n",
            "\t314: \"data:0.381\" NUMERICAL mean:127.067 min:0 max:255 sd:112.14\n",
            "\t315: \"data:0.382\" NUMERICAL mean:109.326 min:0 max:255 sd:111.66\n",
            "\t316: \"data:0.383\" NUMERICAL mean:81.2475 min:0 max:255 sd:104.778\n",
            "\t317: \"data:0.384\" NUMERICAL mean:55.3601 min:0 max:255 sd:92.9823\n",
            "\t318: \"data:0.385\" NUMERICAL mean:37.3972 min:0 max:255 sd:80.9103\n",
            "\t319: \"data:0.386\" NUMERICAL mean:24.3111 min:0 max:255 sd:67.8392\n",
            "\t320: \"data:0.387\" NUMERICAL mean:13.8233 min:0 max:255 sd:52.1635\n",
            "\t321: \"data:0.388\" NUMERICAL mean:5.12818 min:0 max:255 sd:30.8216\n",
            "\t322: \"data:0.389\" NUMERICAL mean:0.579048 min:0 max:255 sd:9.85719\n",
            "\t323: \"data:0.39\" NUMERICAL mean:0.141012 min:0 max:255 sd:5.12131\n",
            "\t324: \"data:0.390\" NUMERICAL mean:0.0401786 min:0 max:251 sd:2.3926\n",
            "\t325: \"data:0.391\" NUMERICAL mean:0.00735119 min:0 max:247 sd:1.34748\n",
            "\t326: \"data:0.392\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t327: \"data:0.393\" NUMERICAL mean:0.00559524 min:0 max:188 sd:1.02561\n",
            "\t328: \"data:0.394\" NUMERICAL mean:0.0537202 min:0 max:254 sd:3.13624\n",
            "\t329: \"data:0.395\" NUMERICAL mean:0.423899 min:0 max:255 sd:8.65102\n",
            "\t330: \"data:0.396\" NUMERICAL mean:2.92768 min:0 max:255 sd:23.0381\n",
            "\t331: \"data:0.397\" NUMERICAL mean:12.3395 min:0 max:255 sd:47.9383\n",
            "\t332: \"data:0.398\" NUMERICAL mean:28.3698 min:0 max:255 sd:72.1591\n",
            "\t333: \"data:0.399\" NUMERICAL mean:50.3418 min:0 max:255 sd:91.4972\n",
            "\t334: \"data:0.4\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t335: \"data:0.40\" NUMERICAL mean:0.179375 min:0 max:255 sd:5.77577\n",
            "\t336: \"data:0.400\" NUMERICAL mean:73.6916 min:0 max:255 sd:104.176\n",
            "\t337: \"data:0.401\" NUMERICAL mean:90.0977 min:0 max:255 sd:109.354\n",
            "\t338: \"data:0.402\" NUMERICAL mean:94.9804 min:0 max:255 sd:109.54\n",
            "\t339: \"data:0.403\" NUMERICAL mean:92.9461 min:0 max:255 sd:108.195\n",
            "\t340: \"data:0.404\" NUMERICAL mean:97.2421 min:0 max:255 sd:108.004\n",
            "\t341: \"data:0.405\" NUMERICAL mean:115.033 min:0 max:255 sd:111.551\n",
            "\t342: \"data:0.406\" NUMERICAL mean:130.092 min:0 max:255 sd:113.969\n",
            "\t343: \"data:0.407\" NUMERICAL mean:139.867 min:0 max:255 sd:109.693\n",
            "\t344: \"data:0.408\" NUMERICAL mean:137.086 min:0 max:255 sd:109.684\n",
            "\t345: \"data:0.409\" NUMERICAL mean:128.254 min:0 max:255 sd:112.364\n",
            "\t346: \"data:0.41\" NUMERICAL mean:0.18744 min:0 max:255 sd:5.9462\n",
            "\t347: \"data:0.410\" NUMERICAL mean:107.576 min:0 max:255 sd:111.365\n",
            "\t348: \"data:0.411\" NUMERICAL mean:79.7835 min:0 max:255 sd:104.363\n",
            "\t349: \"data:0.412\" NUMERICAL mean:56.4058 min:0 max:255 sd:94.2716\n",
            "\t350: \"data:0.413\" NUMERICAL mean:39.3051 min:0 max:255 sd:82.7662\n",
            "\t351: \"data:0.414\" NUMERICAL mean:25.7093 min:0 max:255 sd:69.5055\n",
            "\t352: \"data:0.415\" NUMERICAL mean:14.7542 min:0 max:255 sd:53.8861\n",
            "\t353: \"data:0.416\" NUMERICAL mean:5.77521 min:0 max:255 sd:33.0372\n",
            "\t354: \"data:0.417\" NUMERICAL mean:0.778571 min:0 max:255 sd:11.4445\n",
            "\t355: \"data:0.418\" NUMERICAL mean:0.063244 min:0 max:209 sd:2.75623\n",
            "\t356: \"data:0.419\" NUMERICAL mean:0.00160714 min:0 max:51 sd:0.278704\n",
            "\t357: \"data:0.42\" NUMERICAL mean:0.186399 min:0 max:255 sd:5.8474\n",
            "\t358: \"data:0.420\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t359: \"data:0.421\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t360: \"data:0.422\" NUMERICAL mean:0.0352083 min:0 max:223 sd:1.95086\n",
            "\t361: \"data:0.423\" NUMERICAL mean:0.467411 min:0 max:255 sd:9.02055\n",
            "\t362: \"data:0.424\" NUMERICAL mean:3.43949 min:0 max:255 sd:24.9241\n",
            "\t363: \"data:0.425\" NUMERICAL mean:14.2985 min:0 max:255 sd:51.8565\n",
            "\t364: \"data:0.426\" NUMERICAL mean:30.642 min:0 max:255 sd:74.8066\n",
            "\t365: \"data:0.427\" NUMERICAL mean:50.8914 min:0 max:255 sd:92.2502\n",
            "\t366: \"data:0.428\" NUMERICAL mean:71.2323 min:0 max:255 sd:103.218\n",
            "\t367: \"data:0.429\" NUMERICAL mean:85.529 min:0 max:255 sd:108.062\n",
            "\t368: \"data:0.43\" NUMERICAL mean:0.165625 min:0 max:255 sd:5.70795\n",
            "\t369: \"data:0.430\" NUMERICAL mean:91.2388 min:0 max:255 sd:108.477\n",
            "\t370: \"data:0.431\" NUMERICAL mean:94.004 min:0 max:255 sd:108.398\n",
            "\t371: \"data:0.432\" NUMERICAL mean:104.945 min:0 max:255 sd:109.864\n",
            "\t372: \"data:0.433\" NUMERICAL mean:123.262 min:0 max:255 sd:112.696\n",
            "\t373: \"data:0.434\" NUMERICAL mean:135.804 min:0 max:255 sd:112.756\n",
            "\t374: \"data:0.435\" NUMERICAL mean:139.053 min:0 max:255 sd:109.632\n",
            "\t375: \"data:0.436\" NUMERICAL mean:131.528 min:0 max:255 sd:111.446\n",
            "\t376: \"data:0.437\" NUMERICAL mean:121.358 min:0 max:255 sd:112.587\n",
            "\t377: \"data:0.438\" NUMERICAL mean:101.741 min:0 max:255 sd:109.847\n",
            "\t378: \"data:0.439\" NUMERICAL mean:78.8933 min:0 max:255 sd:104.365\n",
            "\t379: \"data:0.44\" NUMERICAL mean:0.14128 min:0 max:255 sd:4.97475\n",
            "\t380: \"data:0.440\" NUMERICAL mean:58.9052 min:0 max:255 sd:95.9845\n",
            "\t381: \"data:0.441\" NUMERICAL mean:41.7271 min:0 max:255 sd:85.0528\n",
            "\t382: \"data:0.442\" NUMERICAL mean:27.0331 min:0 max:255 sd:70.8813\n",
            "\t383: \"data:0.443\" NUMERICAL mean:14.9579 min:0 max:255 sd:53.7921\n",
            "\t384: \"data:0.444\" NUMERICAL mean:5.85741 min:0 max:255 sd:33.4394\n",
            "\t385: \"data:0.445\" NUMERICAL mean:1.00598 min:0 max:255 sd:13.3727\n",
            "\t386: \"data:0.446\" NUMERICAL mean:0.15244 min:0 max:255 sd:5.27529\n",
            "\t387: \"data:0.447\" NUMERICAL mean:0.0137202 min:0 max:190 sd:1.27069\n",
            "\t388: \"data:0.448\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t389: \"data:0.449\" NUMERICAL mean:0.00139881 min:0 max:47 sd:0.256402\n",
            "\t390: \"data:0.45\" NUMERICAL mean:0.150179 min:0 max:255 sd:5.44394\n",
            "\t391: \"data:0.450\" NUMERICAL mean:0.0708036 min:0 max:254 sd:3.28862\n",
            "\t392: \"data:0.451\" NUMERICAL mean:0.648899 min:0 max:255 sd:10.4883\n",
            "\t393: \"data:0.452\" NUMERICAL mean:4.4164 min:0 max:255 sd:28.2742\n",
            "\t394: \"data:0.453\" NUMERICAL mean:16.3138 min:0 max:255 sd:55.4486\n",
            "\t395: \"data:0.454\" NUMERICAL mean:32.0114 min:0 max:255 sd:76.599\n",
            "\t396: \"data:0.455\" NUMERICAL mean:49.7718 min:0 max:255 sd:91.3787\n",
            "\t397: \"data:0.456\" NUMERICAL mean:66.4768 min:0 max:255 sd:100.868\n",
            "\t398: \"data:0.457\" NUMERICAL mean:78.0576 min:0 max:255 sd:105.358\n",
            "\t399: \"data:0.458\" NUMERICAL mean:83.7651 min:0 max:255 sd:106.172\n",
            "\t400: \"data:0.459\" NUMERICAL mean:89.1282 min:0 max:255 sd:107.126\n",
            "\t401: \"data:0.46\" NUMERICAL mean:0.116756 min:0 max:255 sd:4.75945\n",
            "\t402: \"data:0.460\" NUMERICAL mean:100.679 min:0 max:255 sd:109.848\n",
            "\t403: \"data:0.461\" NUMERICAL mean:115.579 min:0 max:255 sd:112.91\n",
            "\t404: \"data:0.462\" NUMERICAL mean:126.237 min:0 max:255 sd:112.78\n",
            "\t405: \"data:0.463\" NUMERICAL mean:127.264 min:0 max:255 sd:111.29\n",
            "\t406: \"data:0.464\" NUMERICAL mean:120.761 min:0 max:255 sd:112.29\n",
            "\t407: \"data:0.465\" NUMERICAL mean:110.964 min:0 max:255 sd:111.282\n",
            "\t408: \"data:0.466\" NUMERICAL mean:95.9019 min:0 max:255 sd:108.479\n",
            "\t409: \"data:0.467\" NUMERICAL mean:78.3639 min:0 max:255 sd:104.521\n",
            "\t410: \"data:0.468\" NUMERICAL mean:60.5561 min:0 max:255 sd:97.4087\n",
            "\t411: \"data:0.469\" NUMERICAL mean:42.5561 min:0 max:255 sd:85.7262\n",
            "\t412: \"data:0.47\" NUMERICAL mean:0.0755952 min:0 max:255 sd:3.86481\n",
            "\t413: \"data:0.470\" NUMERICAL mean:26.7201 min:0 max:255 sd:70.3526\n",
            "\t414: \"data:0.471\" NUMERICAL mean:14.1287 min:0 max:255 sd:51.9518\n",
            "\t415: \"data:0.472\" NUMERICAL mean:5.4589 min:0 max:255 sd:32.0158\n",
            "\t416: \"data:0.473\" NUMERICAL mean:1.18568 min:0 max:255 sd:14.7163\n",
            "\t417: \"data:0.474\" NUMERICAL mean:0.18744 min:0 max:253 sd:5.48571\n",
            "\t418: \"data:0.475\" NUMERICAL mean:0.0229167 min:0 max:223 sd:1.85039\n",
            "\t419: \"data:0.476\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t420: \"data:0.477\" NUMERICAL mean:0.00401786 min:0 max:71 sd:0.521458\n",
            "\t421: \"data:0.478\" NUMERICAL mean:0.11378 min:0 max:254 sd:4.46763\n",
            "\t422: \"data:0.479\" NUMERICAL mean:1.00375 min:0 max:255 sd:13.2298\n",
            "\t423: \"data:0.48\" NUMERICAL mean:0.055744 min:0 max:244 sd:3.27758\n",
            "\t424: \"data:0.480\" NUMERICAL mean:5.89152 min:0 max:255 sd:33.4171\n",
            "\t425: \"data:0.481\" NUMERICAL mean:17.9448 min:0 max:255 sd:58.307\n",
            "\t426: \"data:0.482\" NUMERICAL mean:33.1215 min:0 max:255 sd:77.6798\n",
            "\t427: \"data:0.483\" NUMERICAL mean:48.0252 min:0 max:255 sd:89.8696\n",
            "\t428: \"data:0.484\" NUMERICAL mean:60.9545 min:0 max:255 sd:97.803\n",
            "\t429: \"data:0.485\" NUMERICAL mean:69.7191 min:0 max:255 sd:101.678\n",
            "\t430: \"data:0.486\" NUMERICAL mean:74.7107 min:0 max:255 sd:103.289\n",
            "\t431: \"data:0.487\" NUMERICAL mean:80.2633 min:0 max:255 sd:105.363\n",
            "\t432: \"data:0.488\" NUMERICAL mean:89.0805 min:0 max:255 sd:108.558\n",
            "\t433: \"data:0.489\" NUMERICAL mean:101.525 min:0 max:255 sd:111.017\n",
            "\t434: \"data:0.49\" NUMERICAL mean:0.0116667 min:0 max:147 sd:1.12167\n",
            "\t435: \"data:0.490\" NUMERICAL mean:112.155 min:0 max:255 sd:111.897\n",
            "\t436: \"data:0.491\" NUMERICAL mean:115.203 min:0 max:255 sd:111.644\n",
            "\t437: \"data:0.492\" NUMERICAL mean:112.247 min:0 max:255 sd:111.077\n",
            "\t438: \"data:0.493\" NUMERICAL mean:105.027 min:0 max:255 sd:110.038\n",
            "\t439: \"data:0.494\" NUMERICAL mean:93.5892 min:0 max:255 sd:108.237\n",
            "\t440: \"data:0.495\" NUMERICAL mean:78.6817 min:0 max:255 sd:105.07\n",
            "\t441: \"data:0.496\" NUMERICAL mean:60.4658 min:0 max:255 sd:97.4281\n",
            "\t442: \"data:0.497\" NUMERICAL mean:41.4516 min:0 max:255 sd:84.8474\n",
            "\t443: \"data:0.498\" NUMERICAL mean:25.007 min:0 max:255 sd:67.7418\n",
            "\t444: \"data:0.499\" NUMERICAL mean:12.641 min:0 max:255 sd:48.88\n",
            "\t445: \"data:0.5\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t446: \"data:0.50\" NUMERICAL mean:0.00547619 min:0 max:184 sd:1.00379\n",
            "\t447: \"data:0.500\" NUMERICAL mean:4.93119 min:0 max:255 sd:29.9185\n",
            "\t448: \"data:0.501\" NUMERICAL mean:1.33211 min:0 max:255 sd:15.3396\n",
            "\t449: \"data:0.502\" NUMERICAL mean:0.218929 min:0 max:253 sd:5.83935\n",
            "\t450: \"data:0.503\" NUMERICAL mean:0.0190179 min:0 max:106 sd:1.25001\n",
            "\t451: \"data:0.504\" NUMERICAL mean:0.00330357 min:0 max:60 sd:0.429584\n",
            "\t452: \"data:0.505\" NUMERICAL mean:0.00666667 min:0 max:126 sd:0.748262\n",
            "\t453: \"data:0.506\" NUMERICAL mean:0.187619 min:0 max:255 sd:5.56764\n",
            "\t454: \"data:0.507\" NUMERICAL mean:1.59384 min:0 max:255 sd:17.0244\n",
            "\t455: \"data:0.508\" NUMERICAL mean:7.58039 min:0 max:255 sd:38.5007\n",
            "\t456: \"data:0.509\" NUMERICAL mean:19.8989 min:0 max:255 sd:61.5137\n",
            "\t457: \"data:0.51\" NUMERICAL mean:0.000446429 min:0 max:15 sd:0.0818305\n",
            "\t458: \"data:0.510\" NUMERICAL mean:34.5367 min:0 max:255 sd:79.0116\n",
            "\t459: \"data:0.511\" NUMERICAL mean:48.251 min:0 max:255 sd:90.1409\n",
            "\t460: \"data:0.512\" NUMERICAL mean:58.822 min:0 max:255 sd:96.8162\n",
            "\t461: \"data:0.513\" NUMERICAL mean:66.176 min:0 max:255 sd:100.282\n",
            "\t462: \"data:0.514\" NUMERICAL mean:71.6414 min:0 max:255 sd:102.901\n",
            "\t463: \"data:0.515\" NUMERICAL mean:76.244 min:0 max:255 sd:104.809\n",
            "\t464: \"data:0.516\" NUMERICAL mean:82.6734 min:0 max:255 sd:106.384\n",
            "\t465: \"data:0.517\" NUMERICAL mean:94.3749 min:0 max:255 sd:109.17\n",
            "\t466: \"data:0.518\" NUMERICAL mean:106.12 min:0 max:255 sd:111.156\n",
            "\t467: \"data:0.519\" NUMERICAL mean:112.514 min:0 max:255 sd:111.06\n",
            "\t468: \"data:0.52\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t469: \"data:0.520\" NUMERICAL mean:112.093 min:0 max:255 sd:110.344\n",
            "\t470: \"data:0.521\" NUMERICAL mean:106.131 min:0 max:255 sd:110.201\n",
            "\t471: \"data:0.522\" NUMERICAL mean:94.8154 min:0 max:255 sd:109.363\n",
            "\t472: \"data:0.523\" NUMERICAL mean:78.2587 min:0 max:255 sd:105.346\n",
            "\t473: \"data:0.524\" NUMERICAL mean:57.8682 min:0 max:255 sd:95.9222\n",
            "\t474: \"data:0.525\" NUMERICAL mean:38.2548 min:0 max:255 sd:81.8749\n",
            "\t475: \"data:0.526\" NUMERICAL mean:22.408 min:0 max:255 sd:64.3105\n",
            "\t476: \"data:0.527\" NUMERICAL mean:11.1231 min:0 max:255 sd:45.7128\n",
            "\t477: \"data:0.528\" NUMERICAL mean:4.4217 min:0 max:255 sd:28.6358\n",
            "\t478: \"data:0.529\" NUMERICAL mean:1.23964 min:0 max:255 sd:14.821\n",
            "\t479: \"data:0.53\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t480: \"data:0.530\" NUMERICAL mean:0.156339 min:0 max:255 sd:4.96326\n",
            "\t481: \"data:0.531\" NUMERICAL mean:0.0100595 min:0 max:151 sd:1.10672\n",
            "\t482: \"data:0.532\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t483: \"data:0.533\" NUMERICAL mean:0.011994 min:0 max:255 sd:1.50654\n",
            "\t484: \"data:0.534\" NUMERICAL mean:0.298661 min:0 max:255 sd:7.38004\n",
            "\t485: \"data:0.535\" NUMERICAL mean:2.08893 min:0 max:255 sd:19.9393\n",
            "\t486: \"data:0.536\" NUMERICAL mean:8.68565 min:0 max:255 sd:41.27\n",
            "\t487: \"data:0.537\" NUMERICAL mean:21.4035 min:0 max:255 sd:63.9457\n",
            "\t488: \"data:0.538\" NUMERICAL mean:36.6339 min:0 max:255 sd:81.3644\n",
            "\t489: \"data:0.539\" NUMERICAL mean:51.0413 min:0 max:255 sd:92.4045\n",
            "\t490: \"data:0.54\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t491: \"data:0.540\" NUMERICAL mean:62.7775 min:0 max:255 sd:98.8876\n",
            "\t492: \"data:0.541\" NUMERICAL mean:71.6662 min:0 max:255 sd:102.961\n",
            "\t493: \"data:0.542\" NUMERICAL mean:78.0703 min:0 max:255 sd:105.718\n",
            "\t494: \"data:0.543\" NUMERICAL mean:82.4221 min:0 max:255 sd:107.056\n",
            "\t495: \"data:0.544\" NUMERICAL mean:89.3511 min:0 max:255 sd:108.616\n",
            "\t496: \"data:0.545\" NUMERICAL mean:100.394 min:0 max:255 sd:110.034\n",
            "\t497: \"data:0.546\" NUMERICAL mean:112.578 min:0 max:255 sd:111.526\n",
            "\t498: \"data:0.547\" NUMERICAL mean:118.705 min:0 max:255 sd:111.348\n",
            "\t499: \"data:0.548\" NUMERICAL mean:117.385 min:0 max:255 sd:110.803\n",
            "\t500: \"data:0.549\" NUMERICAL mean:109.005 min:0 max:255 sd:111.312\n",
            "\t501: \"data:0.55\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t502: \"data:0.550\" NUMERICAL mean:93.6254 min:0 max:255 sd:109.389\n",
            "\t503: \"data:0.551\" NUMERICAL mean:73.268 min:0 max:255 sd:103.247\n",
            "\t504: \"data:0.552\" NUMERICAL mean:51.8082 min:0 max:255 sd:92.1827\n",
            "\t505: \"data:0.553\" NUMERICAL mean:33.1052 min:0 max:255 sd:76.9042\n",
            "\t506: \"data:0.554\" NUMERICAL mean:18.7232 min:0 max:255 sd:59.029\n",
            "\t507: \"data:0.555\" NUMERICAL mean:9.10679 min:0 max:255 sd:41.2591\n",
            "\t508: \"data:0.556\" NUMERICAL mean:3.56158 min:0 max:255 sd:25.5286\n",
            "\t509: \"data:0.557\" NUMERICAL mean:1.05372 min:0 max:255 sd:13.4848\n",
            "\t510: \"data:0.558\" NUMERICAL mean:0.149583 min:0 max:253 sd:5.1837\n",
            "\t511: \"data:0.559\" NUMERICAL mean:0.00297619 min:0 max:100 sd:0.545537\n",
            "\t512: \"data:0.56\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t513: \"data:0.560\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t514: \"data:0.561\" NUMERICAL mean:0.0114583 min:0 max:178 sd:1.24308\n",
            "\t515: \"data:0.562\" NUMERICAL mean:0.342946 min:0 max:255 sd:7.75725\n",
            "\t516: \"data:0.563\" NUMERICAL mean:2.28122 min:0 max:255 sd:20.8082\n",
            "\t517: \"data:0.564\" NUMERICAL mean:8.60289 min:0 max:255 sd:40.9794\n",
            "\t518: \"data:0.565\" NUMERICAL mean:20.555 min:0 max:255 sd:62.5362\n",
            "\t519: \"data:0.566\" NUMERICAL mean:36.7051 min:0 max:255 sd:81.1022\n",
            "\t520: \"data:0.567\" NUMERICAL mean:53.7453 min:0 max:255 sd:94.4042\n",
            "\t521: \"data:0.568\" NUMERICAL mean:69.1479 min:0 max:255 sd:102.619\n",
            "\t522: \"data:0.569\" NUMERICAL mean:81.6901 min:0 max:255 sd:106.996\n",
            "\t523: \"data:0.57\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t524: \"data:0.570\" NUMERICAL mean:90.695 min:0 max:255 sd:109.347\n",
            "\t525: \"data:0.571\" NUMERICAL mean:98.1082 min:0 max:255 sd:110.525\n",
            "\t526: \"data:0.572\" NUMERICAL mean:106.591 min:0 max:255 sd:111.255\n",
            "\t527: \"data:0.573\" NUMERICAL mean:116.997 min:0 max:255 sd:111.476\n",
            "\t528: \"data:0.574\" NUMERICAL mean:125.739 min:0 max:255 sd:111.438\n",
            "\t529: \"data:0.575\" NUMERICAL mean:126.893 min:0 max:255 sd:111.376\n",
            "\t530: \"data:0.576\" NUMERICAL mean:119.816 min:0 max:255 sd:111.358\n",
            "\t531: \"data:0.577\" NUMERICAL mean:105.434 min:0 max:255 sd:110.845\n",
            "\t532: \"data:0.578\" NUMERICAL mean:85.1274 min:0 max:255 sd:106.952\n",
            "\t533: \"data:0.579\" NUMERICAL mean:62.2887 min:0 max:255 sd:98.0445\n",
            "\t534: \"data:0.58\" NUMERICAL mean:0.00190476 min:0 max:64 sd:0.349143\n",
            "\t535: \"data:0.580\" NUMERICAL mean:41.4172 min:0 max:255 sd:84.2644\n",
            "\t536: \"data:0.581\" NUMERICAL mean:25.0983 min:0 max:255 sd:67.7285\n",
            "\t537: \"data:0.582\" NUMERICAL mean:13.6288 min:0 max:255 sd:50.3915\n",
            "\t538: \"data:0.583\" NUMERICAL mean:6.5444 min:0 max:255 sd:35.1151\n",
            "\t539: \"data:0.584\" NUMERICAL mean:2.72911 min:0 max:255 sd:22.6025\n",
            "\t540: \"data:0.585\" NUMERICAL mean:0.810655 min:0 max:255 sd:11.8041\n",
            "\t541: \"data:0.586\" NUMERICAL mean:0.109405 min:0 max:255 sd:4.09757\n",
            "\t542: \"data:0.587\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t543: \"data:0.588\" NUMERICAL mean:0.000952381 min:0 max:32 sd:0.174572\n",
            "\t544: \"data:0.589\" NUMERICAL mean:0.00883929 min:0 max:107 sd:0.82988\n",
            "\t545: \"data:0.59\" NUMERICAL mean:0.000863095 min:0 max:29 sd:0.158206\n",
            "\t546: \"data:0.590\" NUMERICAL mean:0.282381 min:0 max:255 sd:6.82421\n",
            "\t547: \"data:0.591\" NUMERICAL mean:1.88935 min:0 max:255 sd:18.6491\n",
            "\t548: \"data:0.592\" NUMERICAL mean:6.72202 min:0 max:255 sd:35.4604\n",
            "\t549: \"data:0.593\" NUMERICAL mean:16.8615 min:0 max:255 sd:56.4645\n",
            "\t550: \"data:0.594\" NUMERICAL mean:32.4559 min:0 max:255 sd:76.3546\n",
            "\t551: \"data:0.595\" NUMERICAL mean:51.3986 min:0 max:255 sd:92.529\n",
            "\t552: \"data:0.596\" NUMERICAL mean:70.5791 min:0 max:255 sd:103.332\n",
            "\t553: \"data:0.597\" NUMERICAL mean:87.7928 min:0 max:255 sd:109.173\n",
            "\t554: \"data:0.598\" NUMERICAL mean:101.267 min:0 max:255 sd:111.182\n",
            "\t555: \"data:0.599\" NUMERICAL mean:112.586 min:0 max:255 sd:111.516\n",
            "\t556: \"data:0.6\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t557: \"data:0.60\" NUMERICAL mean:0.00809524 min:0 max:134 sd:1.01239\n",
            "\t558: \"data:0.600\" NUMERICAL mean:122.575 min:0 max:255 sd:111.122\n",
            "\t559: \"data:0.601\" NUMERICAL mean:130.674 min:0 max:255 sd:110.478\n",
            "\t560: \"data:0.602\" NUMERICAL mean:133.159 min:0 max:255 sd:110.671\n",
            "\t561: \"data:0.603\" NUMERICAL mean:126.407 min:0 max:255 sd:111.089\n",
            "\t562: \"data:0.604\" NUMERICAL mean:111.665 min:0 max:255 sd:110.763\n",
            "\t563: \"data:0.605\" NUMERICAL mean:90.9616 min:0 max:255 sd:107.859\n",
            "\t564: \"data:0.606\" NUMERICAL mean:67.6971 min:0 max:255 sd:100.416\n",
            "\t565: \"data:0.607\" NUMERICAL mean:45.9918 min:0 max:255 sd:87.5818\n",
            "\t566: \"data:0.608\" NUMERICAL mean:28.6867 min:0 max:255 sd:71.7235\n",
            "\t567: \"data:0.609\" NUMERICAL mean:16.2451 min:0 max:255 sd:54.7879\n",
            "\t568: \"data:0.61\" NUMERICAL mean:0.00327381 min:0 max:45 sd:0.32567\n",
            "\t569: \"data:0.610\" NUMERICAL mean:8.51622 min:0 max:255 sd:40.1296\n",
            "\t570: \"data:0.611\" NUMERICAL mean:4.20723 min:0 max:255 sd:28.0844\n",
            "\t571: \"data:0.612\" NUMERICAL mean:1.7222 min:0 max:255 sd:17.6354\n",
            "\t572: \"data:0.613\" NUMERICAL mean:0.473899 min:0 max:255 sd:9.09018\n",
            "\t573: \"data:0.614\" NUMERICAL mean:0.0716369 min:0 max:251 sd:3.28334\n",
            "\t574: \"data:0.615\" NUMERICAL mean:0.00116071 min:0 max:39 sd:0.212759\n",
            "\t575: \"data:0.616\" NUMERICAL mean:0.000922619 min:0 max:31 sd:0.169116\n",
            "\t576: \"data:0.617\" NUMERICAL mean:0.000416667 min:0 max:10 sd:0.0587555\n",
            "\t577: \"data:0.618\" NUMERICAL mean:0.178006 min:0 max:255 sd:5.49289\n",
            "\t578: \"data:0.619\" NUMERICAL mean:1.15134 min:0 max:255 sd:14.3405\n",
            "\t579: \"data:0.62\" NUMERICAL mean:0.0560417 min:0 max:234 sd:2.92524\n",
            "\t580: \"data:0.620\" NUMERICAL mean:3.90729 min:0 max:255 sd:26.5477\n",
            "\t581: \"data:0.621\" NUMERICAL mean:10.6855 min:0 max:255 sd:44.2214\n",
            "\t582: \"data:0.622\" NUMERICAL mean:23.1813 min:0 max:255 sd:64.7692\n",
            "\t583: \"data:0.623\" NUMERICAL mean:40.4316 min:0 max:255 sd:83.2996\n",
            "\t584: \"data:0.624\" NUMERICAL mean:61.0104 min:0 max:255 sd:97.9803\n",
            "\t585: \"data:0.625\" NUMERICAL mean:81.1111 min:0 max:255 sd:107.208\n",
            "\t586: \"data:0.626\" NUMERICAL mean:98.9707 min:0 max:255 sd:111.694\n",
            "\t587: \"data:0.627\" NUMERICAL mean:112.792 min:0 max:255 sd:112.942\n",
            "\t588: \"data:0.628\" NUMERICAL mean:122.255 min:0 max:255 sd:112.382\n",
            "\t589: \"data:0.629\" NUMERICAL mean:125.858 min:0 max:255 sd:111.993\n",
            "\t590: \"data:0.63\" NUMERICAL mean:0.149345 min:0 max:255 sd:5.29637\n",
            "\t591: \"data:0.630\" NUMERICAL mean:121.805 min:0 max:255 sd:112.29\n",
            "\t592: \"data:0.631\" NUMERICAL mean:108.201 min:0 max:255 sd:111.351\n",
            "\t593: \"data:0.632\" NUMERICAL mean:88.8114 min:0 max:255 sd:107.436\n",
            "\t594: \"data:0.633\" NUMERICAL mean:66.7773 min:0 max:255 sd:99.2927\n",
            "\t595: \"data:0.634\" NUMERICAL mean:45.5969 min:0 max:255 sd:86.7272\n",
            "\t596: \"data:0.635\" NUMERICAL mean:28.7166 min:0 max:255 sd:71.3643\n",
            "\t597: \"data:0.636\" NUMERICAL mean:16.5714 min:0 max:255 sd:55.0548\n",
            "\t598: \"data:0.637\" NUMERICAL mean:8.87494 min:0 max:255 sd:40.706\n",
            "\t599: \"data:0.638\" NUMERICAL mean:4.54875 min:0 max:255 sd:29.0585\n",
            "\t600: \"data:0.639\" NUMERICAL mean:2.12155 min:0 max:255 sd:19.5568\n",
            "\t601: \"data:0.64\" NUMERICAL mean:0.305804 min:0 max:255 sd:7.81402\n",
            "\t602: \"data:0.640\" NUMERICAL mean:0.804613 min:0 max:255 sd:11.57\n",
            "\t603: \"data:0.641\" NUMERICAL mean:0.21247 min:0 max:253 sd:5.31596\n",
            "\t604: \"data:0.642\" NUMERICAL mean:0.0272619 min:0 max:225 sd:1.9449\n",
            "\t605: \"data:0.643\" NUMERICAL mean:0.00214286 min:0 max:72 sd:0.392786\n",
            "\t606: \"data:0.644\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t607: \"data:0.645\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t608: \"data:0.646\" NUMERICAL mean:0.0581548 min:0 max:208 sd:2.62714\n",
            "\t609: \"data:0.647\" NUMERICAL mean:0.461548 min:0 max:255 sd:8.67461\n",
            "\t610: \"data:0.648\" NUMERICAL mean:1.71211 min:0 max:255 sd:17.3128\n",
            "\t611: \"data:0.649\" NUMERICAL mean:4.87003 min:0 max:255 sd:29.3914\n",
            "\t612: \"data:0.65\" NUMERICAL mean:0.537232 min:0 max:255 sd:10.0661\n",
            "\t613: \"data:0.650\" NUMERICAL mean:11.9049 min:0 max:255 sd:45.8869\n",
            "\t614: \"data:0.651\" NUMERICAL mean:23.8272 min:0 max:255 sd:64.573\n",
            "\t615: \"data:0.652\" NUMERICAL mean:40.1661 min:0 max:255 sd:82.1806\n",
            "\t616: \"data:0.653\" NUMERICAL mean:58.6492 min:0 max:255 sd:95.5947\n",
            "\t617: \"data:0.654\" NUMERICAL mean:76.7392 min:0 max:255 sd:104.443\n",
            "\t618: \"data:0.655\" NUMERICAL mean:91.5052 min:0 max:255 sd:109.025\n",
            "\t619: \"data:0.656\" NUMERICAL mean:99.7571 min:0 max:255 sd:110.59\n",
            "\t620: \"data:0.657\" NUMERICAL mean:99.7958 min:0 max:255 sd:110.218\n",
            "\t621: \"data:0.658\" NUMERICAL mean:91.4302 min:0 max:255 sd:108.032\n",
            "\t622: \"data:0.659\" NUMERICAL mean:76.0603 min:0 max:255 sd:103.034\n",
            "\t623: \"data:0.66\" NUMERICAL mean:0.834137 min:0 max:255 sd:12.5032\n",
            "\t624: \"data:0.660\" NUMERICAL mean:57.734 min:0 max:255 sd:94.0603\n",
            "\t625: \"data:0.661\" NUMERICAL mean:40.3881 min:0 max:255 sd:81.9068\n",
            "\t626: \"data:0.662\" NUMERICAL mean:25.5141 min:0 max:255 sd:67.0533\n",
            "\t627: \"data:0.663\" NUMERICAL mean:15.1105 min:0 max:255 sd:52.6269\n",
            "\t628: \"data:0.664\" NUMERICAL mean:8.27899 min:0 max:255 sd:39.2377\n",
            "\t629: \"data:0.665\" NUMERICAL mean:4.16491 min:0 max:255 sd:27.7722\n",
            "\t630: \"data:0.666\" NUMERICAL mean:2.00018 min:0 max:255 sd:19.1258\n",
            "\t631: \"data:0.667\" NUMERICAL mean:0.885417 min:0 max:255 sd:12.5957\n",
            "\t632: \"data:0.668\" NUMERICAL mean:0.267232 min:0 max:253 sd:6.52643\n",
            "\t633: \"data:0.669\" NUMERICAL mean:0.0670536 min:0 max:241 sd:2.90194\n",
            "\t634: \"data:0.67\" NUMERICAL mean:1.32955 min:0 max:255 sd:15.7163\n",
            "\t635: \"data:0.670\" NUMERICAL mean:0.00613095 min:0 max:84 sd:0.65467\n",
            "\t636: \"data:0.671\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t637: \"data:0.672\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t638: \"data:0.673\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t639: \"data:0.674\" NUMERICAL mean:0.0156548 min:0 max:253 sd:1.57014\n",
            "\t640: \"data:0.675\" NUMERICAL mean:0.12497 min:0 max:253 sd:4.25232\n",
            "\t641: \"data:0.676\" NUMERICAL mean:0.519107 min:0 max:254 sd:9.1802\n",
            "\t642: \"data:0.677\" NUMERICAL mean:1.60815 min:0 max:255 sd:16.7968\n",
            "\t643: \"data:0.678\" NUMERICAL mean:4.08375 min:0 max:255 sd:26.8775\n",
            "\t644: \"data:0.679\" NUMERICAL mean:8.89113 min:0 max:255 sd:40.2973\n",
            "\t645: \"data:0.68\" NUMERICAL mean:1.9883 min:0 max:255 sd:19.4204\n",
            "\t646: \"data:0.680\" NUMERICAL mean:16.4567 min:0 max:255 sd:54.8841\n",
            "\t647: \"data:0.681\" NUMERICAL mean:26.4903 min:0 max:255 sd:68.9578\n",
            "\t648: \"data:0.682\" NUMERICAL mean:37.3042 min:0 max:255 sd:80.3322\n",
            "\t649: \"data:0.683\" NUMERICAL mean:46.3013 min:0 max:255 sd:87.7129\n",
            "\t650: \"data:0.684\" NUMERICAL mean:51.2849 min:0 max:255 sd:90.7557\n",
            "\t651: \"data:0.685\" NUMERICAL mean:51.2576 min:0 max:255 sd:90.7706\n",
            "\t652: \"data:0.686\" NUMERICAL mean:45.8836 min:0 max:255 sd:86.4372\n",
            "\t653: \"data:0.687\" NUMERICAL mean:36.8834 min:0 max:255 sd:78.6849\n",
            "\t654: \"data:0.688\" NUMERICAL mean:27.8483 min:0 max:255 sd:69.8196\n",
            "\t655: \"data:0.689\" NUMERICAL mean:19.3261 min:0 max:255 sd:59.1124\n",
            "\t656: \"data:0.69\" NUMERICAL mean:2.71024 min:0 max:255 sd:22.6942\n",
            "\t657: \"data:0.690\" NUMERICAL mean:12.1921 min:0 max:255 sd:47.5751\n",
            "\t658: \"data:0.691\" NUMERICAL mean:7.32804 min:0 max:255 sd:37.5364\n",
            "\t659: \"data:0.692\" NUMERICAL mean:3.92926 min:0 max:255 sd:27.2216\n",
            "\t660: \"data:0.693\" NUMERICAL mean:1.91955 min:0 max:255 sd:19.1631\n",
            "\t661: \"data:0.694\" NUMERICAL mean:0.850208 min:0 max:255 sd:12.4691\n",
            "\t662: \"data:0.695\" NUMERICAL mean:0.378214 min:0 max:255 sd:8.19304\n",
            "\t663: \"data:0.696\" NUMERICAL mean:0.0846131 min:0 max:254 sd:3.68195\n",
            "\t664: \"data:0.697\" NUMERICAL mean:0.026756 min:0 max:241 sd:2.13485\n",
            "\t665: \"data:0.698\" NUMERICAL mean:0.00345238 min:0 max:98 sd:0.543566\n",
            "\t666: \"data:0.699\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t667: \"data:0.7\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t668: \"data:0.70\" NUMERICAL mean:3.47539 min:0 max:255 sd:25.8094\n",
            "\t669: \"data:0.700\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t670: \"data:0.701\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t671: \"data:0.702\" NUMERICAL mean:0.00232143 min:0 max:42 sd:0.301772\n",
            "\t672: \"data:0.703\" NUMERICAL mean:0.011756 min:0 max:254 sd:1.44204\n",
            "\t673: \"data:0.704\" NUMERICAL mean:0.13369 min:0 max:255 sd:4.86382\n",
            "\t674: \"data:0.705\" NUMERICAL mean:0.486369 min:0 max:255 sd:9.38451\n",
            "\t675: \"data:0.706\" NUMERICAL mean:1.37997 min:0 max:255 sd:16.1316\n",
            "\t676: \"data:0.707\" NUMERICAL mean:3.04235 min:0 max:255 sd:24.2898\n",
            "\t677: \"data:0.708\" NUMERICAL mean:5.82824 min:0 max:255 sd:33.9873\n",
            "\t678: \"data:0.709\" NUMERICAL mean:9.39604 min:0 max:255 sd:43.0149\n",
            "\t679: \"data:0.71\" NUMERICAL mean:3.85943 min:0 max:255 sd:27.2423\n",
            "\t680: \"data:0.710\" NUMERICAL mean:13.4238 min:0 max:255 sd:51.2249\n",
            "\t681: \"data:0.711\" NUMERICAL mean:16.4714 min:0 max:255 sd:56.2719\n",
            "\t682: \"data:0.712\" NUMERICAL mean:18.1819 min:0 max:255 sd:59.0419\n",
            "\t683: \"data:0.713\" NUMERICAL mean:18.004 min:0 max:255 sd:58.6042\n",
            "\t684: \"data:0.714\" NUMERICAL mean:16.209 min:0 max:255 sd:55.4177\n",
            "\t685: \"data:0.715\" NUMERICAL mean:13.606 min:0 max:255 sd:50.8512\n",
            "\t686: \"data:0.716\" NUMERICAL mean:10.854 min:0 max:255 sd:45.5418\n",
            "\t687: \"data:0.717\" NUMERICAL mean:8.1678 min:0 max:255 sd:39.5627\n",
            "\t688: \"data:0.718\" NUMERICAL mean:5.49045 min:0 max:255 sd:32.8524\n",
            "\t689: \"data:0.719\" NUMERICAL mean:3.30369 min:0 max:255 sd:25.2225\n",
            "\t690: \"data:0.72\" NUMERICAL mean:3.7264 min:0 max:255 sd:26.6735\n",
            "\t691: \"data:0.720\" NUMERICAL mean:1.75711 min:0 max:255 sd:18.5159\n",
            "\t692: \"data:0.721\" NUMERICAL mean:0.850536 min:0 max:255 sd:12.8191\n",
            "\t693: \"data:0.722\" NUMERICAL mean:0.39003 min:0 max:255 sd:8.29575\n",
            "\t694: \"data:0.723\" NUMERICAL mean:0.142202 min:0 max:253 sd:4.83761\n",
            "\t695: \"data:0.724\" NUMERICAL mean:0.0205655 min:0 max:196 sd:1.55656\n",
            "\t696: \"data:0.725\" NUMERICAL mean:0.00636905 min:0 max:127 sd:0.839796\n",
            "\t697: \"data:0.726\" NUMERICAL mean:0.00309524 min:0 max:104 sd:0.567358\n",
            "\t698: \"data:0.727\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t699: \"data:0.728\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t700: \"data:0.729\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t701: \"data:0.73\" NUMERICAL mean:3.35836 min:0 max:255 sd:25.5386\n",
            "\t702: \"data:0.730\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t703: \"data:0.731\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t704: \"data:0.732\" NUMERICAL mean:0.0374107 min:0 max:255 sd:2.57435\n",
            "\t705: \"data:0.733\" NUMERICAL mean:0.150387 min:0 max:255 sd:5.04825\n",
            "\t706: \"data:0.734\" NUMERICAL mean:0.543929 min:0 max:255 sd:10.1368\n",
            "\t707: \"data:0.735\" NUMERICAL mean:1.14062 min:0 max:255 sd:14.7665\n",
            "\t708: \"data:0.736\" NUMERICAL mean:2.11128 min:0 max:255 sd:20.3732\n",
            "\t709: \"data:0.737\" NUMERICAL mean:3.15726 min:0 max:255 sd:24.7583\n",
            "\t710: \"data:0.738\" NUMERICAL mean:4.55345 min:0 max:255 sd:29.8092\n",
            "\t711: \"data:0.739\" NUMERICAL mean:5.92676 min:0 max:255 sd:34.0814\n",
            "\t712: \"data:0.74\" NUMERICAL mean:2.7614 min:0 max:255 sd:23.1668\n",
            "\t713: \"data:0.740\" NUMERICAL mean:6.60173 min:0 max:255 sd:35.7763\n",
            "\t714: \"data:0.741\" NUMERICAL mean:6.4711 min:0 max:255 sd:35.195\n",
            "\t715: \"data:0.742\" NUMERICAL mean:5.74113 min:0 max:255 sd:33.2251\n",
            "\t716: \"data:0.743\" NUMERICAL mean:4.64756 min:0 max:255 sd:29.6536\n",
            "\t717: \"data:0.744\" NUMERICAL mean:3.71622 min:0 max:255 sd:26.7135\n",
            "\t718: \"data:0.745\" NUMERICAL mean:2.7111 min:0 max:255 sd:22.6029\n",
            "\t719: \"data:0.746\" NUMERICAL mean:1.88938 min:0 max:255 sd:19.2392\n",
            "\t720: \"data:0.747\" NUMERICAL mean:1.18301 min:0 max:255 sd:14.9745\n",
            "\t721: \"data:0.748\" NUMERICAL mean:0.619613 min:0 max:255 sd:11.0297\n",
            "\t722: \"data:0.749\" NUMERICAL mean:0.268571 min:0 max:255 sd:6.84411\n",
            "\t723: \"data:0.75\" NUMERICAL mean:2.03315 min:0 max:255 sd:20.0454\n",
            "\t724: \"data:0.750\" NUMERICAL mean:0.107917 min:0 max:255 sd:4.22095\n",
            "\t725: \"data:0.751\" NUMERICAL mean:0.0310417 min:0 max:253 sd:2.06384\n",
            "\t726: \"data:0.752\" NUMERICAL mean:0.00107143 min:0 max:28 sd:0.156026\n",
            "\t727: \"data:0.753\" NUMERICAL mean:0.00175595 min:0 max:59 sd:0.321867\n",
            "\t728: \"data:0.754\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t729: \"data:0.755\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t730: \"data:0.756\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t731: \"data:0.757\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t732: \"data:0.758\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t733: \"data:0.759\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t734: \"data:0.76\" NUMERICAL mean:1.20619 min:0 max:255 sd:15.4392\n",
            "\t735: \"data:0.760\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t736: \"data:0.761\" NUMERICAL mean:0.00767857 min:0 max:177 sd:1.06189\n",
            "\t737: \"data:0.762\" NUMERICAL mean:0.0386607 min:0 max:231 sd:2.37595\n",
            "\t738: \"data:0.763\" NUMERICAL mean:0.0875 min:0 max:253 sd:4.15758\n",
            "\t739: \"data:0.764\" NUMERICAL mean:0.102321 min:0 max:254 sd:4.25812\n",
            "\t740: \"data:0.765\" NUMERICAL mean:0.163363 min:0 max:253 sd:5.56798\n",
            "\t741: \"data:0.766\" NUMERICAL mean:0.281905 min:0 max:255 sd:7.00511\n",
            "\t742: \"data:0.767\" NUMERICAL mean:0.38872 min:0 max:255 sd:8.62031\n",
            "\t743: \"data:0.768\" NUMERICAL mean:0.501131 min:0 max:255 sd:9.86183\n",
            "\t744: \"data:0.769\" NUMERICAL mean:0.543095 min:0 max:255 sd:9.98467\n",
            "\t745: \"data:0.77\" NUMERICAL mean:0.63247 min:0 max:255 sd:11.0907\n",
            "\t746: \"data:0.770\" NUMERICAL mean:0.67253 min:0 max:255 sd:11.2382\n",
            "\t747: \"data:0.771\" NUMERICAL mean:0.611071 min:0 max:254 sd:10.862\n",
            "\t748: \"data:0.772\" NUMERICAL mean:0.474821 min:0 max:254 sd:9.24206\n",
            "\t749: \"data:0.773\" NUMERICAL mean:0.315268 min:0 max:254 sd:7.48636\n",
            "\t750: \"data:0.774\" NUMERICAL mean:0.232589 min:0 max:254 sd:6.68949\n",
            "\t751: \"data:0.775\" NUMERICAL mean:0.123899 min:0 max:254 sd:4.62565\n",
            "\t752: \"data:0.776\" NUMERICAL mean:0.0660417 min:0 max:253 sd:3.52088\n",
            "\t753: \"data:0.777\" NUMERICAL mean:0.0252381 min:0 max:253 sd:1.96754\n",
            "\t754: \"data:0.778\" NUMERICAL mean:0.0215476 min:0 max:254 sd:2.11807\n",
            "\t755: \"data:0.779\" NUMERICAL mean:0.00357143 min:0 max:62 sd:0.463153\n",
            "\t756: \"data:0.78\" NUMERICAL mean:0.31128 min:0 max:255 sd:7.70931\n",
            "\t757: \"data:0.780\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t758: \"data:0.781\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t759: \"data:0.782\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t760: \"data:0.783\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t761: \"data:0.79\" NUMERICAL mean:0.0953869 min:0 max:255 sd:4.04425\n",
            "\t762: \"data:0.8\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t763: \"data:0.80\" NUMERICAL mean:0.0329762 min:0 max:255 sd:2.43284\n",
            "\t764: \"data:0.81\" NUMERICAL mean:0.00886905 min:0 max:165 sd:1.12704\n",
            "\t765: \"data:0.82\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t766: \"data:0.83\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t767: \"data:0.84\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t768: \"data:0.85\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t769: \"data:0.86\" NUMERICAL mean:0.00452381 min:0 max:141 sd:0.771542\n",
            "\t770: \"data:0.87\" NUMERICAL mean:0.00508929 min:0 max:84 sd:0.586407\n",
            "\t771: \"data:0.88\" NUMERICAL mean:0.0182738 min:0 max:139 sd:1.22779\n",
            "\t772: \"data:0.89\" NUMERICAL mean:0.0854762 min:0 max:253 sd:3.42034\n",
            "\t773: \"data:0.9\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t774: \"data:0.90\" NUMERICAL mean:0.235476 min:0 max:255 sd:6.53087\n",
            "\t775: \"data:0.91\" NUMERICAL mean:0.54994 min:0 max:255 sd:9.68512\n",
            "\t776: \"data:0.92\" NUMERICAL mean:1.21821 min:0 max:255 sd:14.8473\n",
            "\t777: \"data:0.93\" NUMERICAL mean:2.3031 min:0 max:255 sd:21.0773\n",
            "\t778: \"data:0.94\" NUMERICAL mean:3.74545 min:0 max:255 sd:26.7695\n",
            "\t779: \"data:0.95\" NUMERICAL mean:5.76068 min:0 max:255 sd:33.3078\n",
            "\t780: \"data:0.96\" NUMERICAL mean:7.88613 min:0 max:255 sd:38.9708\n",
            "\t781: \"data:0.97\" NUMERICAL mean:10.1247 min:0 max:255 sd:44.2213\n",
            "\t782: \"data:0.98\" NUMERICAL mean:12.1728 min:0 max:255 sd:48.296\n",
            "\t783: \"data:0.99\" NUMERICAL mean:13.4966 min:0 max:255 sd:51.073\n",
            "\n",
            "CATEGORICAL: 1 (0.127389%)\n",
            "\t784: \"__LABEL\" CATEGORICAL integerized vocab-size:11 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO 2023-01-06T04:56:06.619560384+00:00 kernel.cc:842] Collect validation dataset\n",
            "[INFO 2023-01-06T04:56:06.620817005+00:00 kernel.cc:423] Number of batches: 9\n",
            "[INFO 2023-01-06T04:56:06.620838056+00:00 kernel.cc:424] Number of examples: 8400\n",
            "[INFO 2023-01-06T04:56:06.715944009+00:00 kernel.cc:853] Validation dataset:\n",
            "Number of records: 8400\n",
            "Number of columns: 785\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 784 (99.8726%)\n",
            "\tCATEGORICAL: 1 (0.127389%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 784 (99.8726%)\n",
            "\t0: \"data:0.0\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t1: \"data:0.1\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t2: \"data:0.10\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t3: \"data:0.100\" NUMERICAL mean:12.4302 min:0 max:255 sd:48.703\n",
            "\t4: \"data:0.101\" NUMERICAL mean:10.9943 min:0 max:255 sd:46.1182\n",
            "\t5: \"data:0.102\" NUMERICAL mean:8.81536 min:0 max:255 sd:41.2765\n",
            "\t6: \"data:0.103\" NUMERICAL mean:6.45857 min:0 max:255 sd:35.7301\n",
            "\t7: \"data:0.104\" NUMERICAL mean:4.11905 min:0 max:255 sd:28.3831\n",
            "\t8: \"data:0.105\" NUMERICAL mean:2.09976 min:0 max:255 sd:19.9151\n",
            "\t9: \"data:0.106\" NUMERICAL mean:0.943095 min:0 max:255 sd:12.9498\n",
            "\t10: \"data:0.107\" NUMERICAL mean:0.440238 min:0 max:255 sd:9.21048\n",
            "\t11: \"data:0.108\" NUMERICAL mean:0.242262 min:0 max:255 sd:7.04614\n",
            "\t12: \"data:0.109\" NUMERICAL mean:0.0436905 min:0 max:146 sd:2.12219\n",
            "\t13: \"data:0.11\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t14: \"data:0.110\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t15: \"data:0.111\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t16: \"data:0.112\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t17: \"data:0.113\" NUMERICAL mean:0.00452381 min:0 max:38 sd:0.414589\n",
            "\t18: \"data:0.114\" NUMERICAL mean:0.00261905 min:0 max:22 sd:0.240025\n",
            "\t19: \"data:0.115\" NUMERICAL mean:0.015 min:0 max:101 sd:1.12187\n",
            "\t20: \"data:0.116\" NUMERICAL mean:0.0440476 min:0 max:192 sd:2.2918\n",
            "\t21: \"data:0.117\" NUMERICAL mean:0.458452 min:0 max:255 sd:8.93241\n",
            "\t22: \"data:0.118\" NUMERICAL mean:1.13452 min:0 max:255 sd:13.9523\n",
            "\t23: \"data:0.119\" NUMERICAL mean:2.53095 min:0 max:255 sd:21.1965\n",
            "\t24: \"data:0.12\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t25: \"data:0.120\" NUMERICAL mean:5.11631 min:0 max:255 sd:31.0745\n",
            "\t26: \"data:0.121\" NUMERICAL mean:9.03095 min:0 max:255 sd:41.3885\n",
            "\t27: \"data:0.122\" NUMERICAL mean:14.0404 min:0 max:255 sd:51.5912\n",
            "\t28: \"data:0.123\" NUMERICAL mean:20.7351 min:0 max:255 sd:61.4027\n",
            "\t29: \"data:0.124\" NUMERICAL mean:28.7049 min:0 max:255 sd:70.782\n",
            "\t30: \"data:0.125\" NUMERICAL mean:36.7033 min:0 max:255 sd:79.0083\n",
            "\t31: \"data:0.126\" NUMERICAL mean:42.8244 min:0 max:255 sd:84.273\n",
            "\t32: \"data:0.127\" NUMERICAL mean:45.8455 min:0 max:255 sd:86.7908\n",
            "\t33: \"data:0.128\" NUMERICAL mean:44.9579 min:0 max:255 sd:86.2978\n",
            "\t34: \"data:0.129\" NUMERICAL mean:38.5562 min:0 max:255 sd:80.968\n",
            "\t35: \"data:0.13\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t36: \"data:0.130\" NUMERICAL mean:30.1418 min:0 max:255 sd:72.7378\n",
            "\t37: \"data:0.131\" NUMERICAL mean:21.9138 min:0 max:255 sd:63.2365\n",
            "\t38: \"data:0.132\" NUMERICAL mean:13.6065 min:0 max:255 sd:49.8516\n",
            "\t39: \"data:0.133\" NUMERICAL mean:8.32143 min:0 max:255 sd:39.2623\n",
            "\t40: \"data:0.134\" NUMERICAL mean:4.95381 min:0 max:255 sd:30.5491\n",
            "\t41: \"data:0.135\" NUMERICAL mean:2.66464 min:0 max:255 sd:22.1066\n",
            "\t42: \"data:0.136\" NUMERICAL mean:1.11786 min:0 max:255 sd:14.0203\n",
            "\t43: \"data:0.137\" NUMERICAL mean:0.227143 min:0 max:251 sd:5.49773\n",
            "\t44: \"data:0.138\" NUMERICAL mean:0.0161905 min:0 max:136 sd:1.48379\n",
            "\t45: \"data:0.139\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t46: \"data:0.14\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t47: \"data:0.140\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t48: \"data:0.141\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t49: \"data:0.142\" NUMERICAL mean:0.0203571 min:0 max:95 sd:1.32726\n",
            "\t50: \"data:0.143\" NUMERICAL mean:0.0414286 min:0 max:148 sd:1.93118\n",
            "\t51: \"data:0.144\" NUMERICAL mean:0.385238 min:0 max:254 sd:7.34495\n",
            "\t52: \"data:0.145\" NUMERICAL mean:1.5231 min:0 max:255 sd:16.2519\n",
            "\t53: \"data:0.146\" NUMERICAL mean:3.78905 min:0 max:255 sd:26.3745\n",
            "\t54: \"data:0.147\" NUMERICAL mean:7.46179 min:0 max:255 sd:37.1723\n",
            "\t55: \"data:0.148\" NUMERICAL mean:13.3623 min:0 max:255 sd:49.6274\n",
            "\t56: \"data:0.149\" NUMERICAL mean:21.9406 min:0 max:255 sd:63.4342\n",
            "\t57: \"data:0.15\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t58: \"data:0.150\" NUMERICAL mean:33.0338 min:0 max:255 sd:75.6043\n",
            "\t59: \"data:0.151\" NUMERICAL mean:47.2185 min:0 max:255 sd:87.9533\n",
            "\t60: \"data:0.152\" NUMERICAL mean:62.7754 min:0 max:255 sd:97.9309\n",
            "\t61: \"data:0.153\" NUMERICAL mean:77.296 min:0 max:255 sd:104.357\n",
            "\t62: \"data:0.154\" NUMERICAL mean:87.733 min:0 max:255 sd:107.657\n",
            "\t63: \"data:0.155\" NUMERICAL mean:92.5798 min:0 max:255 sd:109.164\n",
            "\t64: \"data:0.156\" NUMERICAL mean:90.3346 min:0 max:255 sd:108.472\n",
            "\t65: \"data:0.157\" NUMERICAL mean:81.1936 min:0 max:255 sd:105.203\n",
            "\t66: \"data:0.158\" NUMERICAL mean:65.4443 min:0 max:255 sd:98.4546\n",
            "\t67: \"data:0.159\" NUMERICAL mean:48.697 min:0 max:255 sd:88.5366\n",
            "\t68: \"data:0.16\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t69: \"data:0.160\" NUMERICAL mean:32.8275 min:0 max:255 sd:74.9623\n",
            "\t70: \"data:0.161\" NUMERICAL mean:20.6304 min:0 max:255 sd:60.9823\n",
            "\t71: \"data:0.162\" NUMERICAL mean:12.5931 min:0 max:255 sd:48.4714\n",
            "\t72: \"data:0.163\" NUMERICAL mean:7.30012 min:0 max:255 sd:36.9297\n",
            "\t73: \"data:0.164\" NUMERICAL mean:3.32571 min:0 max:255 sd:24.7267\n",
            "\t74: \"data:0.165\" NUMERICAL mean:0.848452 min:0 max:254 sd:11.3037\n",
            "\t75: \"data:0.166\" NUMERICAL mean:0.145833 min:0 max:213 sd:4.5832\n",
            "\t76: \"data:0.167\" NUMERICAL mean:0.00214286 min:0 max:18 sd:0.196384\n",
            "\t77: \"data:0.168\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t78: \"data:0.169\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t79: \"data:0.17\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t80: \"data:0.170\" NUMERICAL mean:0.0382143 min:0 max:167 sd:2.0468\n",
            "\t81: \"data:0.171\" NUMERICAL mean:0.22631 min:0 max:254 sd:5.62101\n",
            "\t82: \"data:0.172\" NUMERICAL mean:1.28071 min:0 max:255 sd:15.3727\n",
            "\t83: \"data:0.173\" NUMERICAL mean:3.52726 min:0 max:255 sd:25.4939\n",
            "\t84: \"data:0.174\" NUMERICAL mean:7.61726 min:0 max:255 sd:38.2272\n",
            "\t85: \"data:0.175\" NUMERICAL mean:14.1448 min:0 max:255 sd:51.5159\n",
            "\t86: \"data:0.176\" NUMERICAL mean:24.4873 min:0 max:255 sd:66.7999\n",
            "\t87: \"data:0.177\" NUMERICAL mean:38.5602 min:0 max:255 sd:81.5728\n",
            "\t88: \"data:0.178\" NUMERICAL mean:55.0055 min:0 max:255 sd:93.5782\n",
            "\t89: \"data:0.179\" NUMERICAL mean:74.0361 min:0 max:255 sd:102.645\n",
            "\t90: \"data:0.18\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t91: \"data:0.180\" NUMERICAL mean:92.9337 min:0 max:255 sd:108.576\n",
            "\t92: \"data:0.181\" NUMERICAL mean:108.61 min:0 max:255 sd:111.213\n",
            "\t93: \"data:0.182\" NUMERICAL mean:119.969 min:0 max:255 sd:112\n",
            "\t94: \"data:0.183\" NUMERICAL mean:125.278 min:0 max:255 sd:111.982\n",
            "\t95: \"data:0.184\" NUMERICAL mean:122.424 min:0 max:255 sd:111.87\n",
            "\t96: \"data:0.185\" NUMERICAL mean:112.685 min:0 max:255 sd:112.057\n",
            "\t97: \"data:0.186\" NUMERICAL mean:96.3749 min:0 max:255 sd:109.8\n",
            "\t98: \"data:0.187\" NUMERICAL mean:74.2892 min:0 max:255 sd:103.102\n",
            "\t99: \"data:0.188\" NUMERICAL mean:53.1456 min:0 max:255 sd:92.3995\n",
            "\t100: \"data:0.189\" NUMERICAL mean:34.0564 min:0 max:255 sd:77.0848\n",
            "\t101: \"data:0.19\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t102: \"data:0.190\" NUMERICAL mean:20.3905 min:0 max:255 sd:61.1065\n",
            "\t103: \"data:0.191\" NUMERICAL mean:11.3113 min:0 max:255 sd:45.8735\n",
            "\t104: \"data:0.192\" NUMERICAL mean:5.2519 min:0 max:255 sd:30.6501\n",
            "\t105: \"data:0.193\" NUMERICAL mean:1.72321 min:0 max:255 sd:17.2626\n",
            "\t106: \"data:0.194\" NUMERICAL mean:0.350119 min:0 max:251 sd:7.47193\n",
            "\t107: \"data:0.195\" NUMERICAL mean:0.0460714 min:0 max:253 sd:2.90708\n",
            "\t108: \"data:0.196\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t109: \"data:0.197\" NUMERICAL mean:0.000952381 min:0 max:8 sd:0.087282\n",
            "\t110: \"data:0.198\" NUMERICAL mean:0.0867857 min:0 max:220 sd:3.77958\n",
            "\t111: \"data:0.199\" NUMERICAL mean:0.635714 min:0 max:255 sd:10.9574\n",
            "\t112: \"data:0.2\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t113: \"data:0.20\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t114: \"data:0.200\" NUMERICAL mean:2.42679 min:0 max:255 sd:21.5519\n",
            "\t115: \"data:0.201\" NUMERICAL mean:6.25464 min:0 max:255 sd:34.3073\n",
            "\t116: \"data:0.202\" NUMERICAL mean:12.6774 min:0 max:255 sd:48.9271\n",
            "\t117: \"data:0.203\" NUMERICAL mean:22.5621 min:0 max:255 sd:64.0245\n",
            "\t118: \"data:0.204\" NUMERICAL mean:36.3243 min:0 max:255 sd:78.9267\n",
            "\t119: \"data:0.205\" NUMERICAL mean:54.6812 min:0 max:255 sd:92.6483\n",
            "\t120: \"data:0.206\" NUMERICAL mean:75.344 min:0 max:255 sd:102.346\n",
            "\t121: \"data:0.207\" NUMERICAL mean:96.7556 min:0 max:255 sd:107.871\n",
            "\t122: \"data:0.208\" NUMERICAL mean:113.98 min:0 max:255 sd:110.035\n",
            "\t123: \"data:0.209\" NUMERICAL mean:126.058 min:0 max:255 sd:110.689\n",
            "\t124: \"data:0.21\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t125: \"data:0.210\" NUMERICAL mean:132.888 min:0 max:255 sd:110.694\n",
            "\t126: \"data:0.211\" NUMERICAL mean:135.261 min:0 max:255 sd:110.273\n",
            "\t127: \"data:0.212\" NUMERICAL mean:133.28 min:0 max:255 sd:110.357\n",
            "\t128: \"data:0.213\" NUMERICAL mean:126.468 min:0 max:255 sd:110.357\n",
            "\t129: \"data:0.214\" NUMERICAL mean:113.153 min:0 max:255 sd:110.894\n",
            "\t130: \"data:0.215\" NUMERICAL mean:93.2143 min:0 max:255 sd:108.314\n",
            "\t131: \"data:0.216\" NUMERICAL mean:68.7813 min:0 max:255 sd:100.684\n",
            "\t132: \"data:0.217\" NUMERICAL mean:45.6869 min:0 max:255 sd:87.063\n",
            "\t133: \"data:0.218\" NUMERICAL mean:26.9976 min:0 max:255 sd:69.113\n",
            "\t134: \"data:0.219\" NUMERICAL mean:14.0843 min:0 max:255 sd:51.008\n",
            "\t135: \"data:0.22\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t136: \"data:0.220\" NUMERICAL mean:6.18012 min:0 max:255 sd:33.2089\n",
            "\t137: \"data:0.221\" NUMERICAL mean:1.88988 min:0 max:254 sd:17.7981\n",
            "\t138: \"data:0.222\" NUMERICAL mean:0.425595 min:0 max:255 sd:8.08499\n",
            "\t139: \"data:0.223\" NUMERICAL mean:0.0197619 min:0 max:96 sd:1.1775\n",
            "\t140: \"data:0.224\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t141: \"data:0.225\" NUMERICAL mean:0.0429762 min:0 max:201 sd:2.60228\n",
            "\t142: \"data:0.226\" NUMERICAL mean:0.3175 min:0 max:255 sd:7.72328\n",
            "\t143: \"data:0.227\" NUMERICAL mean:1.40964 min:0 max:255 sd:15.8219\n",
            "\t144: \"data:0.228\" NUMERICAL mean:3.88988 min:0 max:255 sd:27.1937\n",
            "\t145: \"data:0.229\" NUMERICAL mean:8.84488 min:0 max:255 sd:41.2472\n",
            "\t146: \"data:0.23\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t147: \"data:0.230\" NUMERICAL mean:17.3619 min:0 max:255 sd:57.2222\n",
            "\t148: \"data:0.231\" NUMERICAL mean:29.5202 min:0 max:255 sd:72.7604\n",
            "\t149: \"data:0.232\" NUMERICAL mean:47.0111 min:0 max:255 sd:87.8442\n",
            "\t150: \"data:0.233\" NUMERICAL mean:69.5252 min:0 max:255 sd:100.342\n",
            "\t151: \"data:0.234\" NUMERICAL mean:93.2811 min:0 max:255 sd:107.785\n",
            "\t152: \"data:0.235\" NUMERICAL mean:110.92 min:0 max:255 sd:110.668\n",
            "\t153: \"data:0.236\" NUMERICAL mean:120.471 min:0 max:255 sd:111.27\n",
            "\t154: \"data:0.237\" NUMERICAL mean:122.309 min:0 max:255 sd:111.489\n",
            "\t155: \"data:0.238\" NUMERICAL mean:121.543 min:0 max:255 sd:111.4\n",
            "\t156: \"data:0.239\" NUMERICAL mean:121.737 min:0 max:255 sd:111.15\n",
            "\t157: \"data:0.24\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t158: \"data:0.240\" NUMERICAL mean:122.073 min:0 max:255 sd:110.502\n",
            "\t159: \"data:0.241\" NUMERICAL mean:121.455 min:0 max:255 sd:110.712\n",
            "\t160: \"data:0.242\" NUMERICAL mean:116.423 min:0 max:255 sd:111.235\n",
            "\t161: \"data:0.243\" NUMERICAL mean:100.512 min:0 max:255 sd:109.957\n",
            "\t162: \"data:0.244\" NUMERICAL mean:76.2768 min:0 max:255 sd:104.065\n",
            "\t163: \"data:0.245\" NUMERICAL mean:51.859 min:0 max:255 sd:91.8264\n",
            "\t164: \"data:0.246\" NUMERICAL mean:31.2223 min:0 max:255 sd:74.3478\n",
            "\t165: \"data:0.247\" NUMERICAL mean:15.3538 min:0 max:255 sd:53.2836\n",
            "\t166: \"data:0.248\" NUMERICAL mean:6.70036 min:0 max:255 sd:35.1678\n",
            "\t167: \"data:0.249\" NUMERICAL mean:2.06429 min:0 max:254 sd:18.778\n",
            "\t168: \"data:0.25\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t169: \"data:0.250\" NUMERICAL mean:0.376667 min:0 max:253 sd:8.07704\n",
            "\t170: \"data:0.251\" NUMERICAL mean:0.0105952 min:0 max:63 sd:0.743548\n",
            "\t171: \"data:0.252\" NUMERICAL mean:0.0166667 min:0 max:140 sd:1.52743\n",
            "\t172: \"data:0.253\" NUMERICAL mean:0.0921429 min:0 max:250 sd:4.58801\n",
            "\t173: \"data:0.254\" NUMERICAL mean:0.472143 min:0 max:254 sd:8.89333\n",
            "\t174: \"data:0.255\" NUMERICAL mean:1.82667 min:0 max:255 sd:19.327\n",
            "\t175: \"data:0.256\" NUMERICAL mean:4.54583 min:0 max:255 sd:30.1363\n",
            "\t176: \"data:0.257\" NUMERICAL mean:9.91393 min:0 max:255 sd:43.7014\n",
            "\t177: \"data:0.258\" NUMERICAL mean:19.6894 min:0 max:255 sd:60.5834\n",
            "\t178: \"data:0.259\" NUMERICAL mean:34.6651 min:0 max:255 sd:77.7745\n",
            "\t179: \"data:0.26\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t180: \"data:0.260\" NUMERICAL mean:56.0733 min:0 max:255 sd:94.5079\n",
            "\t181: \"data:0.261\" NUMERICAL mean:80.8671 min:0 max:255 sd:105.389\n",
            "\t182: \"data:0.262\" NUMERICAL mean:102.586 min:0 max:255 sd:110.734\n",
            "\t183: \"data:0.263\" NUMERICAL mean:111.862 min:0 max:255 sd:111.754\n",
            "\t184: \"data:0.264\" NUMERICAL mean:109.624 min:0 max:255 sd:111.071\n",
            "\t185: \"data:0.265\" NUMERICAL mean:101.612 min:0 max:255 sd:109.538\n",
            "\t186: \"data:0.266\" NUMERICAL mean:96.4556 min:0 max:255 sd:108.4\n",
            "\t187: \"data:0.267\" NUMERICAL mean:98.0035 min:0 max:255 sd:108.911\n",
            "\t188: \"data:0.268\" NUMERICAL mean:103.298 min:0 max:255 sd:109.225\n",
            "\t189: \"data:0.269\" NUMERICAL mean:110.729 min:0 max:255 sd:110.437\n",
            "\t190: \"data:0.27\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t191: \"data:0.270\" NUMERICAL mean:111.658 min:0 max:255 sd:111.539\n",
            "\t192: \"data:0.271\" NUMERICAL mean:100.031 min:0 max:255 sd:110.163\n",
            "\t193: \"data:0.272\" NUMERICAL mean:76.4699 min:0 max:255 sd:104.128\n",
            "\t194: \"data:0.273\" NUMERICAL mean:51.9781 min:0 max:255 sd:92.6095\n",
            "\t195: \"data:0.274\" NUMERICAL mean:31.172 min:0 max:255 sd:74.6939\n",
            "\t196: \"data:0.275\" NUMERICAL mean:14.7412 min:0 max:255 sd:52.0798\n",
            "\t197: \"data:0.276\" NUMERICAL mean:5.47702 min:0 max:255 sd:31.1932\n",
            "\t198: \"data:0.277\" NUMERICAL mean:1.60119 min:0 max:253 sd:16.7025\n",
            "\t199: \"data:0.278\" NUMERICAL mean:0.188929 min:0 max:253 sd:5.11321\n",
            "\t200: \"data:0.279\" NUMERICAL mean:0.0260714 min:0 max:219 sd:2.38934\n",
            "\t201: \"data:0.28\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t202: \"data:0.280\" NUMERICAL mean:0.0269048 min:0 max:226 sd:2.46572\n",
            "\t203: \"data:0.281\" NUMERICAL mean:0.116905 min:0 max:255 sd:4.73977\n",
            "\t204: \"data:0.282\" NUMERICAL mean:0.468452 min:0 max:254 sd:9.01914\n",
            "\t205: \"data:0.283\" NUMERICAL mean:1.64976 min:0 max:255 sd:17.9046\n",
            "\t206: \"data:0.284\" NUMERICAL mean:4.42893 min:0 max:255 sd:29.5193\n",
            "\t207: \"data:0.285\" NUMERICAL mean:10.036 min:0 max:255 sd:43.8904\n",
            "\t208: \"data:0.286\" NUMERICAL mean:20.8271 min:0 max:255 sd:61.9645\n",
            "\t209: \"data:0.287\" NUMERICAL mean:37.8101 min:0 max:255 sd:81.0477\n",
            "\t210: \"data:0.288\" NUMERICAL mean:61.1724 min:0 max:255 sd:97.2208\n",
            "\t211: \"data:0.289\" NUMERICAL mean:86.3564 min:0 max:255 sd:106.981\n",
            "\t212: \"data:0.29\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t213: \"data:0.290\" NUMERICAL mean:102.68 min:0 max:255 sd:110.82\n",
            "\t214: \"data:0.291\" NUMERICAL mean:103.171 min:0 max:255 sd:110.787\n",
            "\t215: \"data:0.292\" NUMERICAL mean:91.847 min:0 max:255 sd:107.63\n",
            "\t216: \"data:0.293\" NUMERICAL mean:79.2468 min:0 max:255 sd:102.823\n",
            "\t217: \"data:0.294\" NUMERICAL mean:76.4362 min:0 max:255 sd:101.869\n",
            "\t218: \"data:0.295\" NUMERICAL mean:82.1287 min:0 max:255 sd:104.34\n",
            "\t219: \"data:0.296\" NUMERICAL mean:93.1807 min:0 max:255 sd:106.675\n",
            "\t220: \"data:0.297\" NUMERICAL mean:104.721 min:0 max:255 sd:109.812\n",
            "\t221: \"data:0.298\" NUMERICAL mean:107.002 min:0 max:255 sd:110.721\n",
            "\t222: \"data:0.299\" NUMERICAL mean:94.881 min:0 max:255 sd:109.071\n",
            "\t223: \"data:0.3\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t224: \"data:0.30\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t225: \"data:0.300\" NUMERICAL mean:71.7143 min:0 max:255 sd:102.074\n",
            "\t226: \"data:0.301\" NUMERICAL mean:47.7113 min:0 max:255 sd:89.5405\n",
            "\t227: \"data:0.302\" NUMERICAL mean:28.4165 min:0 max:255 sd:71.8905\n",
            "\t228: \"data:0.303\" NUMERICAL mean:13.2023 min:0 max:255 sd:49.1724\n",
            "\t229: \"data:0.304\" NUMERICAL mean:4.52464 min:0 max:255 sd:28.5013\n",
            "\t230: \"data:0.305\" NUMERICAL mean:1.24702 min:0 max:255 sd:14.8503\n",
            "\t231: \"data:0.306\" NUMERICAL mean:0.260952 min:0 max:254 sd:6.36598\n",
            "\t232: \"data:0.307\" NUMERICAL mean:0.0458333 min:0 max:133 sd:2.25001\n",
            "\t233: \"data:0.308\" NUMERICAL mean:0.00452381 min:0 max:38 sd:0.414589\n",
            "\t234: \"data:0.309\" NUMERICAL mean:0.0413095 min:0 max:128 sd:1.95961\n",
            "\t235: \"data:0.31\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t236: \"data:0.310\" NUMERICAL mean:0.391071 min:0 max:255 sd:8.59775\n",
            "\t237: \"data:0.311\" NUMERICAL mean:1.29429 min:0 max:255 sd:15.9666\n",
            "\t238: \"data:0.312\" NUMERICAL mean:3.73167 min:0 max:255 sd:26.9953\n",
            "\t239: \"data:0.313\" NUMERICAL mean:9.66119 min:0 max:255 sd:42.806\n",
            "\t240: \"data:0.314\" NUMERICAL mean:21.7051 min:0 max:255 sd:63.0441\n",
            "\t241: \"data:0.315\" NUMERICAL mean:40.9811 min:0 max:255 sd:83.563\n",
            "\t242: \"data:0.316\" NUMERICAL mean:66.0046 min:0 max:255 sd:99.7619\n",
            "\t243: \"data:0.317\" NUMERICAL mean:89.3919 min:0 max:255 sd:108.531\n",
            "\t244: \"data:0.318\" NUMERICAL mean:100.765 min:0 max:255 sd:110.897\n",
            "\t245: \"data:0.319\" NUMERICAL mean:94.7674 min:0 max:255 sd:108.59\n",
            "\t246: \"data:0.32\" NUMERICAL mean:0.00190476 min:0 max:16 sd:0.174564\n",
            "\t247: \"data:0.320\" NUMERICAL mean:79.6236 min:0 max:255 sd:103.324\n",
            "\t248: \"data:0.321\" NUMERICAL mean:70.4988 min:0 max:255 sd:98.7439\n",
            "\t249: \"data:0.322\" NUMERICAL mean:73.6545 min:0 max:255 sd:101.334\n",
            "\t250: \"data:0.323\" NUMERICAL mean:83.8502 min:0 max:255 sd:105.815\n",
            "\t251: \"data:0.324\" NUMERICAL mean:97.2993 min:0 max:255 sd:108.217\n",
            "\t252: \"data:0.325\" NUMERICAL mean:108.257 min:0 max:255 sd:109.841\n",
            "\t253: \"data:0.326\" NUMERICAL mean:106.328 min:0 max:255 sd:110.412\n",
            "\t254: \"data:0.327\" NUMERICAL mean:89.4821 min:0 max:255 sd:108.176\n",
            "\t255: \"data:0.328\" NUMERICAL mean:64.2463 min:0 max:255 sd:98.3317\n",
            "\t256: \"data:0.329\" NUMERICAL mean:42.9517 min:0 max:255 sd:85.748\n",
            "\t257: \"data:0.33\" NUMERICAL mean:0.00559524 min:0 max:47 sd:0.512782\n",
            "\t258: \"data:0.330\" NUMERICAL mean:26.0315 min:0 max:255 sd:69.6574\n",
            "\t259: \"data:0.331\" NUMERICAL mean:12.8237 min:0 max:255 sd:49.2772\n",
            "\t260: \"data:0.332\" NUMERICAL mean:4.29083 min:0 max:254 sd:27.6531\n",
            "\t261: \"data:0.333\" NUMERICAL mean:0.684762 min:0 max:253 sd:11.0686\n",
            "\t262: \"data:0.334\" NUMERICAL mean:0.202738 min:0 max:251 sd:5.96262\n",
            "\t263: \"data:0.335\" NUMERICAL mean:0.0267857 min:0 max:112 sd:1.65569\n",
            "\t264: \"data:0.336\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t265: \"data:0.337\" NUMERICAL mean:0.0303571 min:0 max:255 sd:2.78211\n",
            "\t266: \"data:0.338\" NUMERICAL mean:0.242619 min:0 max:255 sd:6.87473\n",
            "\t267: \"data:0.339\" NUMERICAL mean:0.96119 min:0 max:255 sd:14.0348\n",
            "\t268: \"data:0.34\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t269: \"data:0.340\" NUMERICAL mean:3.13119 min:0 max:255 sd:24.4863\n",
            "\t270: \"data:0.341\" NUMERICAL mean:9.74143 min:0 max:255 sd:43.0002\n",
            "\t271: \"data:0.342\" NUMERICAL mean:23.5743 min:0 max:255 sd:65.2524\n",
            "\t272: \"data:0.343\" NUMERICAL mean:45.417 min:0 max:255 sd:87.1855\n",
            "\t273: \"data:0.344\" NUMERICAL mean:70.7756 min:0 max:255 sd:102.449\n",
            "\t274: \"data:0.345\" NUMERICAL mean:91.4548 min:0 max:255 sd:109.585\n",
            "\t275: \"data:0.346\" NUMERICAL mean:99.4927 min:0 max:255 sd:110.324\n",
            "\t276: \"data:0.347\" NUMERICAL mean:91.0369 min:0 max:255 sd:107.981\n",
            "\t277: \"data:0.348\" NUMERICAL mean:79.3036 min:0 max:255 sd:103.791\n",
            "\t278: \"data:0.349\" NUMERICAL mean:78.2039 min:0 max:255 sd:102.853\n",
            "\t279: \"data:0.35\" NUMERICAL mean:0.00154762 min:0 max:13 sd:0.141833\n",
            "\t280: \"data:0.350\" NUMERICAL mean:88.3782 min:0 max:255 sd:108.951\n",
            "\t281: \"data:0.351\" NUMERICAL mean:101.242 min:0 max:255 sd:110.61\n",
            "\t282: \"data:0.352\" NUMERICAL mean:113.796 min:0 max:255 sd:110.017\n",
            "\t283: \"data:0.353\" NUMERICAL mean:119.326 min:0 max:255 sd:111.066\n",
            "\t284: \"data:0.354\" NUMERICAL mean:108.468 min:0 max:255 sd:111.2\n",
            "\t285: \"data:0.355\" NUMERICAL mean:84.3701 min:0 max:255 sd:105.855\n",
            "\t286: \"data:0.356\" NUMERICAL mean:58.4963 min:0 max:255 sd:94.8068\n",
            "\t287: \"data:0.357\" NUMERICAL mean:38.4425 min:0 max:255 sd:81.619\n",
            "\t288: \"data:0.358\" NUMERICAL mean:24.3913 min:0 max:255 sd:68.0457\n",
            "\t289: \"data:0.359\" NUMERICAL mean:13.2465 min:0 max:255 sd:51.3265\n",
            "\t290: \"data:0.36\" NUMERICAL mean:0.0472619 min:0 max:252 sd:2.98485\n",
            "\t291: \"data:0.360\" NUMERICAL mean:4.8344 min:0 max:255 sd:29.5756\n",
            "\t292: \"data:0.361\" NUMERICAL mean:0.502381 min:0 max:253 sd:8.84643\n",
            "\t293: \"data:0.362\" NUMERICAL mean:0.0984524 min:0 max:252 sd:4.02734\n",
            "\t294: \"data:0.363\" NUMERICAL mean:0.0188095 min:0 max:100 sd:1.26119\n",
            "\t295: \"data:0.364\" NUMERICAL mean:0.00380952 min:0 max:32 sd:0.349128\n",
            "\t296: \"data:0.365\" NUMERICAL mean:0.0108333 min:0 max:76 sd:0.845155\n",
            "\t297: \"data:0.366\" NUMERICAL mean:0.121786 min:0 max:235 sd:4.27936\n",
            "\t298: \"data:0.367\" NUMERICAL mean:0.640595 min:0 max:254 sd:10.7175\n",
            "\t299: \"data:0.368\" NUMERICAL mean:2.84107 min:0 max:255 sd:23.0211\n",
            "\t300: \"data:0.369\" NUMERICAL mean:10.6569 min:0 max:255 sd:44.4853\n",
            "\t301: \"data:0.37\" NUMERICAL mean:0.0990476 min:0 max:243 sd:4.47258\n",
            "\t302: \"data:0.370\" NUMERICAL mean:26.3485 min:0 max:255 sd:69.1637\n",
            "\t303: \"data:0.371\" NUMERICAL mean:48.9939 min:0 max:255 sd:90.2171\n",
            "\t304: \"data:0.372\" NUMERICAL mean:73.8352 min:0 max:255 sd:104.352\n",
            "\t305: \"data:0.373\" NUMERICAL mean:91.3113 min:0 max:255 sd:109.085\n",
            "\t306: \"data:0.374\" NUMERICAL mean:95.962 min:0 max:255 sd:109.617\n",
            "\t307: \"data:0.375\" NUMERICAL mean:90.5288 min:0 max:255 sd:107.706\n",
            "\t308: \"data:0.376\" NUMERICAL mean:87.1369 min:0 max:255 sd:106.725\n",
            "\t309: \"data:0.377\" NUMERICAL mean:96.47 min:0 max:255 sd:108.754\n",
            "\t310: \"data:0.378\" NUMERICAL mean:111.091 min:0 max:255 sd:113.522\n",
            "\t311: \"data:0.379\" NUMERICAL mean:124.828 min:0 max:255 sd:111.541\n",
            "\t312: \"data:0.38\" NUMERICAL mean:0.196905 min:0 max:224 sd:5.79863\n",
            "\t313: \"data:0.380\" NUMERICAL mean:131.24 min:0 max:255 sd:109.866\n",
            "\t314: \"data:0.381\" NUMERICAL mean:129.256 min:0 max:255 sd:112.048\n",
            "\t315: \"data:0.382\" NUMERICAL mean:110.235 min:0 max:255 sd:111.832\n",
            "\t316: \"data:0.383\" NUMERICAL mean:81.3669 min:0 max:255 sd:104.321\n",
            "\t317: \"data:0.384\" NUMERICAL mean:55.397 min:0 max:255 sd:93.5136\n",
            "\t318: \"data:0.385\" NUMERICAL mean:37.7921 min:0 max:255 sd:81.3365\n",
            "\t319: \"data:0.386\" NUMERICAL mean:24.2082 min:0 max:255 sd:67.7353\n",
            "\t320: \"data:0.387\" NUMERICAL mean:14.2287 min:0 max:255 sd:53.1029\n",
            "\t321: \"data:0.388\" NUMERICAL mean:5.77405 min:0 max:255 sd:33.1595\n",
            "\t322: \"data:0.389\" NUMERICAL mean:0.764048 min:0 max:255 sd:11.1195\n",
            "\t323: \"data:0.39\" NUMERICAL mean:0.306548 min:0 max:253 sd:7.99364\n",
            "\t324: \"data:0.390\" NUMERICAL mean:0.201905 min:0 max:252 sd:5.96302\n",
            "\t325: \"data:0.391\" NUMERICAL mean:0.035 min:0 max:243 sd:2.70889\n",
            "\t326: \"data:0.392\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t327: \"data:0.393\" NUMERICAL mean:0.00261905 min:0 max:22 sd:0.240025\n",
            "\t328: \"data:0.394\" NUMERICAL mean:0.0475 min:0 max:162 sd:2.16135\n",
            "\t329: \"data:0.395\" NUMERICAL mean:0.464881 min:0 max:253 sd:8.76562\n",
            "\t330: \"data:0.396\" NUMERICAL mean:2.97107 min:0 max:255 sd:23.3739\n",
            "\t331: \"data:0.397\" NUMERICAL mean:12.4496 min:0 max:255 sd:48.209\n",
            "\t332: \"data:0.398\" NUMERICAL mean:29.0981 min:0 max:255 sd:72.7354\n",
            "\t333: \"data:0.399\" NUMERICAL mean:51.4836 min:0 max:255 sd:92.6867\n",
            "\t334: \"data:0.4\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t335: \"data:0.40\" NUMERICAL mean:0.239048 min:0 max:255 sd:6.80205\n",
            "\t336: \"data:0.400\" NUMERICAL mean:73.11 min:0 max:255 sd:104.194\n",
            "\t337: \"data:0.401\" NUMERICAL mean:88.265 min:0 max:255 sd:108.618\n",
            "\t338: \"data:0.402\" NUMERICAL mean:92.8693 min:0 max:255 sd:109.212\n",
            "\t339: \"data:0.403\" NUMERICAL mean:91.5923 min:0 max:255 sd:108.129\n",
            "\t340: \"data:0.404\" NUMERICAL mean:96.8488 min:0 max:255 sd:108.151\n",
            "\t341: \"data:0.405\" NUMERICAL mean:114.661 min:0 max:255 sd:111.567\n",
            "\t342: \"data:0.406\" NUMERICAL mean:130.332 min:0 max:255 sd:113.368\n",
            "\t343: \"data:0.407\" NUMERICAL mean:139.661 min:0 max:255 sd:109.471\n",
            "\t344: \"data:0.408\" NUMERICAL mean:138.748 min:0 max:255 sd:109.83\n",
            "\t345: \"data:0.409\" NUMERICAL mean:130.255 min:0 max:255 sd:112.739\n",
            "\t346: \"data:0.41\" NUMERICAL mean:0.203214 min:0 max:253 sd:5.7638\n",
            "\t347: \"data:0.410\" NUMERICAL mean:108.114 min:0 max:255 sd:111.338\n",
            "\t348: \"data:0.411\" NUMERICAL mean:79.6186 min:0 max:255 sd:103.982\n",
            "\t349: \"data:0.412\" NUMERICAL mean:55.9507 min:0 max:255 sd:93.9489\n",
            "\t350: \"data:0.413\" NUMERICAL mean:39.0027 min:0 max:255 sd:82.9253\n",
            "\t351: \"data:0.414\" NUMERICAL mean:25.9342 min:0 max:255 sd:69.9587\n",
            "\t352: \"data:0.415\" NUMERICAL mean:15.2763 min:0 max:255 sd:54.5378\n",
            "\t353: \"data:0.416\" NUMERICAL mean:6.12155 min:0 max:255 sd:34.2955\n",
            "\t354: \"data:0.417\" NUMERICAL mean:1.03393 min:0 max:254 sd:13.2056\n",
            "\t355: \"data:0.418\" NUMERICAL mean:0.11869 min:0 max:156 sd:3.7338\n",
            "\t356: \"data:0.419\" NUMERICAL mean:0.00321429 min:0 max:27 sd:0.294577\n",
            "\t357: \"data:0.42\" NUMERICAL mean:0.234643 min:0 max:254 sd:6.68558\n",
            "\t358: \"data:0.420\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t359: \"data:0.421\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t360: \"data:0.422\" NUMERICAL mean:0.0375 min:0 max:254 sd:2.82373\n",
            "\t361: \"data:0.423\" NUMERICAL mean:0.524167 min:0 max:255 sd:9.55003\n",
            "\t362: \"data:0.424\" NUMERICAL mean:3.6275 min:0 max:255 sd:25.7637\n",
            "\t363: \"data:0.425\" NUMERICAL mean:14.378 min:0 max:255 sd:51.9862\n",
            "\t364: \"data:0.426\" NUMERICAL mean:31.3488 min:0 max:255 sd:75.6579\n",
            "\t365: \"data:0.427\" NUMERICAL mean:51.5336 min:0 max:255 sd:92.898\n",
            "\t366: \"data:0.428\" NUMERICAL mean:70.5645 min:0 max:255 sd:102.76\n",
            "\t367: \"data:0.429\" NUMERICAL mean:83.5594 min:0 max:255 sd:107.165\n",
            "\t368: \"data:0.43\" NUMERICAL mean:0.194286 min:0 max:253 sd:5.79898\n",
            "\t369: \"data:0.430\" NUMERICAL mean:88.9454 min:0 max:255 sd:107.844\n",
            "\t370: \"data:0.431\" NUMERICAL mean:92.6574 min:0 max:255 sd:107.803\n",
            "\t371: \"data:0.432\" NUMERICAL mean:103.28 min:0 max:255 sd:109.267\n",
            "\t372: \"data:0.433\" NUMERICAL mean:122.429 min:0 max:255 sd:112.931\n",
            "\t373: \"data:0.434\" NUMERICAL mean:134.393 min:0 max:255 sd:112.712\n",
            "\t374: \"data:0.435\" NUMERICAL mean:139.154 min:0 max:255 sd:109.206\n",
            "\t375: \"data:0.436\" NUMERICAL mean:133.882 min:0 max:255 sd:111.189\n",
            "\t376: \"data:0.437\" NUMERICAL mean:123.063 min:0 max:255 sd:112.541\n",
            "\t377: \"data:0.438\" NUMERICAL mean:102.627 min:0 max:255 sd:110.014\n",
            "\t378: \"data:0.439\" NUMERICAL mean:78.7177 min:0 max:255 sd:104.306\n",
            "\t379: \"data:0.44\" NUMERICAL mean:0.257262 min:0 max:246 sd:7.2878\n",
            "\t380: \"data:0.440\" NUMERICAL mean:58.6161 min:0 max:255 sd:95.984\n",
            "\t381: \"data:0.441\" NUMERICAL mean:41.7455 min:0 max:255 sd:84.8125\n",
            "\t382: \"data:0.442\" NUMERICAL mean:27.7019 min:0 max:255 sd:71.6721\n",
            "\t383: \"data:0.443\" NUMERICAL mean:15.6504 min:0 max:255 sd:54.5033\n",
            "\t384: \"data:0.444\" NUMERICAL mean:6.04429 min:0 max:255 sd:33.7781\n",
            "\t385: \"data:0.445\" NUMERICAL mean:1.26667 min:0 max:254 sd:15.4918\n",
            "\t386: \"data:0.446\" NUMERICAL mean:0.109167 min:0 max:244 sd:4.17314\n",
            "\t387: \"data:0.447\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t388: \"data:0.448\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t389: \"data:0.449\" NUMERICAL mean:0.00380952 min:0 max:32 sd:0.349128\n",
            "\t390: \"data:0.45\" NUMERICAL mean:0.157857 min:0 max:255 sd:5.40598\n",
            "\t391: \"data:0.450\" NUMERICAL mean:0.0497619 min:0 max:228 sd:2.88744\n",
            "\t392: \"data:0.451\" NUMERICAL mean:0.641548 min:0 max:255 sd:10.735\n",
            "\t393: \"data:0.452\" NUMERICAL mean:4.57833 min:0 max:255 sd:29.3253\n",
            "\t394: \"data:0.453\" NUMERICAL mean:16.5017 min:0 max:255 sd:55.4141\n",
            "\t395: \"data:0.454\" NUMERICAL mean:33.2106 min:0 max:255 sd:77.986\n",
            "\t396: \"data:0.455\" NUMERICAL mean:49.7031 min:0 max:255 sd:91.6467\n",
            "\t397: \"data:0.456\" NUMERICAL mean:65.0757 min:0 max:255 sd:100.022\n",
            "\t398: \"data:0.457\" NUMERICAL mean:76.2713 min:0 max:255 sd:104.454\n",
            "\t399: \"data:0.458\" NUMERICAL mean:82.7038 min:0 max:255 sd:106.597\n",
            "\t400: \"data:0.459\" NUMERICAL mean:87.863 min:0 max:255 sd:107.618\n",
            "\t401: \"data:0.46\" NUMERICAL mean:0.0595238 min:0 max:211 sd:3.10963\n",
            "\t402: \"data:0.460\" NUMERICAL mean:99.8387 min:0 max:255 sd:109.997\n",
            "\t403: \"data:0.461\" NUMERICAL mean:114.476 min:0 max:255 sd:112.935\n",
            "\t404: \"data:0.462\" NUMERICAL mean:125.111 min:0 max:255 sd:112.313\n",
            "\t405: \"data:0.463\" NUMERICAL mean:128.205 min:0 max:255 sd:111.386\n",
            "\t406: \"data:0.464\" NUMERICAL mean:123.552 min:0 max:255 sd:112.434\n",
            "\t407: \"data:0.465\" NUMERICAL mean:112.954 min:0 max:255 sd:111.443\n",
            "\t408: \"data:0.466\" NUMERICAL mean:96.047 min:0 max:255 sd:108.024\n",
            "\t409: \"data:0.467\" NUMERICAL mean:78.3429 min:0 max:255 sd:104.443\n",
            "\t410: \"data:0.468\" NUMERICAL mean:60.3743 min:0 max:255 sd:97.3809\n",
            "\t411: \"data:0.469\" NUMERICAL mean:42.9251 min:0 max:255 sd:85.8001\n",
            "\t412: \"data:0.47\" NUMERICAL mean:0.00154762 min:0 max:13 sd:0.141833\n",
            "\t413: \"data:0.470\" NUMERICAL mean:28.3854 min:0 max:255 sd:72.4847\n",
            "\t414: \"data:0.471\" NUMERICAL mean:15.1693 min:0 max:255 sd:53.4088\n",
            "\t415: \"data:0.472\" NUMERICAL mean:6.11619 min:0 max:255 sd:33.8426\n",
            "\t416: \"data:0.473\" NUMERICAL mean:1.47286 min:0 max:255 sd:16.2278\n",
            "\t417: \"data:0.474\" NUMERICAL mean:0.193214 min:0 max:254 sd:5.71149\n",
            "\t418: \"data:0.475\" NUMERICAL mean:0.00892857 min:0 max:75 sd:0.818268\n",
            "\t419: \"data:0.476\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t420: \"data:0.477\" NUMERICAL mean:0.0025 min:0 max:21 sd:0.229115\n",
            "\t421: \"data:0.478\" NUMERICAL mean:0.0705952 min:0 max:139 sd:2.70813\n",
            "\t422: \"data:0.479\" NUMERICAL mean:0.821667 min:0 max:255 sd:12.2406\n",
            "\t423: \"data:0.48\" NUMERICAL mean:0.00238095 min:0 max:20 sd:0.218205\n",
            "\t424: \"data:0.480\" NUMERICAL mean:5.87476 min:0 max:255 sd:32.7329\n",
            "\t425: \"data:0.481\" NUMERICAL mean:19.0445 min:0 max:255 sd:59.9675\n",
            "\t426: \"data:0.482\" NUMERICAL mean:33.9204 min:0 max:255 sd:78.2468\n",
            "\t427: \"data:0.483\" NUMERICAL mean:48.0074 min:0 max:255 sd:90.0559\n",
            "\t428: \"data:0.484\" NUMERICAL mean:59.2812 min:0 max:255 sd:96.3339\n",
            "\t429: \"data:0.485\" NUMERICAL mean:68.1293 min:0 max:255 sd:100.892\n",
            "\t430: \"data:0.486\" NUMERICAL mean:74.1081 min:0 max:255 sd:103.353\n",
            "\t431: \"data:0.487\" NUMERICAL mean:80.2555 min:0 max:255 sd:105.262\n",
            "\t432: \"data:0.488\" NUMERICAL mean:88.2681 min:0 max:255 sd:108.075\n",
            "\t433: \"data:0.489\" NUMERICAL mean:99.9335 min:0 max:255 sd:110.308\n",
            "\t434: \"data:0.49\" NUMERICAL mean:0.0303571 min:0 max:255 sd:2.78211\n",
            "\t435: \"data:0.490\" NUMERICAL mean:111.874 min:0 max:255 sd:111.919\n",
            "\t436: \"data:0.491\" NUMERICAL mean:116.389 min:0 max:255 sd:112.068\n",
            "\t437: \"data:0.492\" NUMERICAL mean:114.018 min:0 max:255 sd:111.414\n",
            "\t438: \"data:0.493\" NUMERICAL mean:106.078 min:0 max:255 sd:109.804\n",
            "\t439: \"data:0.494\" NUMERICAL mean:93.2998 min:0 max:255 sd:108.288\n",
            "\t440: \"data:0.495\" NUMERICAL mean:78.5748 min:0 max:255 sd:105.478\n",
            "\t441: \"data:0.496\" NUMERICAL mean:60.1975 min:0 max:255 sd:96.9484\n",
            "\t442: \"data:0.497\" NUMERICAL mean:41.7958 min:0 max:255 sd:84.6017\n",
            "\t443: \"data:0.498\" NUMERICAL mean:26.2185 min:0 max:255 sd:69.4051\n",
            "\t444: \"data:0.499\" NUMERICAL mean:13.531 min:0 max:255 sd:50.6326\n",
            "\t445: \"data:0.5\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t446: \"data:0.50\" NUMERICAL mean:0.0307143 min:0 max:141 sd:1.99887\n",
            "\t447: \"data:0.500\" NUMERICAL mean:5.5356 min:0 max:255 sd:31.7302\n",
            "\t448: \"data:0.501\" NUMERICAL mean:1.31107 min:0 max:253 sd:15.1443\n",
            "\t449: \"data:0.502\" NUMERICAL mean:0.145714 min:0 max:248 sd:5.23868\n",
            "\t450: \"data:0.503\" NUMERICAL mean:0.0144048 min:0 max:121 sd:1.32014\n",
            "\t451: \"data:0.504\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t452: \"data:0.505\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t453: \"data:0.506\" NUMERICAL mean:0.107381 min:0 max:241 sd:3.7432\n",
            "\t454: \"data:0.507\" NUMERICAL mean:1.16988 min:0 max:255 sd:14.1499\n",
            "\t455: \"data:0.508\" NUMERICAL mean:7.29357 min:0 max:255 sd:36.5939\n",
            "\t456: \"data:0.509\" NUMERICAL mean:21.1469 min:0 max:255 sd:63.3973\n",
            "\t457: \"data:0.51\" NUMERICAL mean:0.0234524 min:0 max:197 sd:2.14932\n",
            "\t458: \"data:0.510\" NUMERICAL mean:35.4601 min:0 max:255 sd:80.3665\n",
            "\t459: \"data:0.511\" NUMERICAL mean:48.4995 min:0 max:255 sd:90.7088\n",
            "\t460: \"data:0.512\" NUMERICAL mean:57.5068 min:0 max:255 sd:95.1309\n",
            "\t461: \"data:0.513\" NUMERICAL mean:64.5875 min:0 max:255 sd:99.2996\n",
            "\t462: \"data:0.514\" NUMERICAL mean:70.733 min:0 max:255 sd:102.291\n",
            "\t463: \"data:0.515\" NUMERICAL mean:76.3633 min:0 max:255 sd:104.984\n",
            "\t464: \"data:0.516\" NUMERICAL mean:82.4114 min:0 max:255 sd:106.407\n",
            "\t465: \"data:0.517\" NUMERICAL mean:94.2254 min:0 max:255 sd:109.013\n",
            "\t466: \"data:0.518\" NUMERICAL mean:105.924 min:0 max:255 sd:110.976\n",
            "\t467: \"data:0.519\" NUMERICAL mean:112.902 min:0 max:255 sd:111.272\n",
            "\t468: \"data:0.52\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t469: \"data:0.520\" NUMERICAL mean:112.377 min:0 max:255 sd:110.189\n",
            "\t470: \"data:0.521\" NUMERICAL mean:105.425 min:0 max:255 sd:109.848\n",
            "\t471: \"data:0.522\" NUMERICAL mean:93.7414 min:0 max:255 sd:109.025\n",
            "\t472: \"data:0.523\" NUMERICAL mean:77.4429 min:0 max:255 sd:105.419\n",
            "\t473: \"data:0.524\" NUMERICAL mean:57.5762 min:0 max:255 sd:95.8016\n",
            "\t474: \"data:0.525\" NUMERICAL mean:38.9686 min:0 max:255 sd:82.3627\n",
            "\t475: \"data:0.526\" NUMERICAL mean:23.7489 min:0 max:255 sd:66.2488\n",
            "\t476: \"data:0.527\" NUMERICAL mean:11.9558 min:0 max:255 sd:47.5533\n",
            "\t477: \"data:0.528\" NUMERICAL mean:4.57929 min:0 max:255 sd:28.5427\n",
            "\t478: \"data:0.529\" NUMERICAL mean:1.27369 min:0 max:255 sd:15.3498\n",
            "\t479: \"data:0.53\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t480: \"data:0.530\" NUMERICAL mean:0.185 min:0 max:240 sd:5.34142\n",
            "\t481: \"data:0.531\" NUMERICAL mean:0.0152381 min:0 max:128 sd:1.39651\n",
            "\t482: \"data:0.532\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t483: \"data:0.533\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t484: \"data:0.534\" NUMERICAL mean:0.183929 min:0 max:247 sd:5.50425\n",
            "\t485: \"data:0.535\" NUMERICAL mean:1.82786 min:0 max:255 sd:17.7234\n",
            "\t486: \"data:0.536\" NUMERICAL mean:8.37679 min:0 max:255 sd:40.0884\n",
            "\t487: \"data:0.537\" NUMERICAL mean:22.3232 min:0 max:255 sd:64.7141\n",
            "\t488: \"data:0.538\" NUMERICAL mean:37.8551 min:0 max:255 sd:82.6063\n",
            "\t489: \"data:0.539\" NUMERICAL mean:51.4408 min:0 max:255 sd:93.0392\n",
            "\t490: \"data:0.54\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t491: \"data:0.540\" NUMERICAL mean:61.9214 min:0 max:255 sd:98.6263\n",
            "\t492: \"data:0.541\" NUMERICAL mean:69.7124 min:0 max:255 sd:102.222\n",
            "\t493: \"data:0.542\" NUMERICAL mean:75.7795 min:0 max:255 sd:104.339\n",
            "\t494: \"data:0.543\" NUMERICAL mean:81.1357 min:0 max:255 sd:106.869\n",
            "\t495: \"data:0.544\" NUMERICAL mean:88.9161 min:0 max:255 sd:108.453\n",
            "\t496: \"data:0.545\" NUMERICAL mean:100.098 min:0 max:255 sd:110.32\n",
            "\t497: \"data:0.546\" NUMERICAL mean:111.818 min:0 max:255 sd:111.737\n",
            "\t498: \"data:0.547\" NUMERICAL mean:118.423 min:0 max:255 sd:111.153\n",
            "\t499: \"data:0.548\" NUMERICAL mean:116.39 min:0 max:255 sd:110.154\n",
            "\t500: \"data:0.549\" NUMERICAL mean:107.386 min:0 max:255 sd:110.626\n",
            "\t501: \"data:0.55\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t502: \"data:0.550\" NUMERICAL mean:92.6702 min:0 max:255 sd:109.667\n",
            "\t503: \"data:0.551\" NUMERICAL mean:73.023 min:0 max:255 sd:102.981\n",
            "\t504: \"data:0.552\" NUMERICAL mean:51.9956 min:0 max:255 sd:92.1432\n",
            "\t505: \"data:0.553\" NUMERICAL mean:34.0537 min:0 max:255 sd:78.306\n",
            "\t506: \"data:0.554\" NUMERICAL mean:19.8379 min:0 max:255 sd:61.0251\n",
            "\t507: \"data:0.555\" NUMERICAL mean:9.22131 min:0 max:255 sd:41.2903\n",
            "\t508: \"data:0.556\" NUMERICAL mean:3.43143 min:0 max:255 sd:24.7272\n",
            "\t509: \"data:0.557\" NUMERICAL mean:0.913571 min:0 max:255 sd:12.972\n",
            "\t510: \"data:0.558\" NUMERICAL mean:0.200714 min:0 max:253 sd:5.87587\n",
            "\t511: \"data:0.559\" NUMERICAL mean:0.0152381 min:0 max:128 sd:1.39651\n",
            "\t512: \"data:0.56\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t513: \"data:0.560\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t514: \"data:0.561\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t515: \"data:0.562\" NUMERICAL mean:0.246071 min:0 max:255 sd:6.48664\n",
            "\t516: \"data:0.563\" NUMERICAL mean:2.34667 min:0 max:255 sd:21.2393\n",
            "\t517: \"data:0.564\" NUMERICAL mean:8.47238 min:0 max:255 sd:40.7813\n",
            "\t518: \"data:0.565\" NUMERICAL mean:21.0896 min:0 max:255 sd:62.8291\n",
            "\t519: \"data:0.566\" NUMERICAL mean:37.7006 min:0 max:255 sd:82.3443\n",
            "\t520: \"data:0.567\" NUMERICAL mean:53.732 min:0 max:255 sd:94.9219\n",
            "\t521: \"data:0.568\" NUMERICAL mean:68.3432 min:0 max:255 sd:102.07\n",
            "\t522: \"data:0.569\" NUMERICAL mean:80.0019 min:0 max:255 sd:106.621\n",
            "\t523: \"data:0.57\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t524: \"data:0.570\" NUMERICAL mean:88.2635 min:0 max:255 sd:108.268\n",
            "\t525: \"data:0.571\" NUMERICAL mean:95.6724 min:0 max:255 sd:109.425\n",
            "\t526: \"data:0.572\" NUMERICAL mean:104.875 min:0 max:255 sd:110.789\n",
            "\t527: \"data:0.573\" NUMERICAL mean:116.812 min:0 max:255 sd:111.47\n",
            "\t528: \"data:0.574\" NUMERICAL mean:124.838 min:0 max:255 sd:111.34\n",
            "\t529: \"data:0.575\" NUMERICAL mean:126.082 min:0 max:255 sd:111.291\n",
            "\t530: \"data:0.576\" NUMERICAL mean:119.085 min:0 max:255 sd:111.123\n",
            "\t531: \"data:0.577\" NUMERICAL mean:104.544 min:0 max:255 sd:110.674\n",
            "\t532: \"data:0.578\" NUMERICAL mean:84.9526 min:0 max:255 sd:106.949\n",
            "\t533: \"data:0.579\" NUMERICAL mean:62.3514 min:0 max:255 sd:98.201\n",
            "\t534: \"data:0.58\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t535: \"data:0.580\" NUMERICAL mean:41.6763 min:0 max:255 sd:84.6214\n",
            "\t536: \"data:0.581\" NUMERICAL mean:25.7455 min:0 max:255 sd:68.6294\n",
            "\t537: \"data:0.582\" NUMERICAL mean:13.7662 min:0 max:255 sd:50.9507\n",
            "\t538: \"data:0.583\" NUMERICAL mean:6.32524 min:0 max:255 sd:34.4957\n",
            "\t539: \"data:0.584\" NUMERICAL mean:2.25167 min:0 max:255 sd:19.6096\n",
            "\t540: \"data:0.585\" NUMERICAL mean:0.532143 min:0 max:255 sd:9.80432\n",
            "\t541: \"data:0.586\" NUMERICAL mean:0.0834524 min:0 max:184 sd:3.21497\n",
            "\t542: \"data:0.587\" NUMERICAL mean:0.00595238 min:0 max:50 sd:0.545512\n",
            "\t543: \"data:0.588\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t544: \"data:0.589\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t545: \"data:0.59\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t546: \"data:0.590\" NUMERICAL mean:0.232143 min:0 max:255 sd:6.54828\n",
            "\t547: \"data:0.591\" NUMERICAL mean:1.9781 min:0 max:255 sd:19.0033\n",
            "\t548: \"data:0.592\" NUMERICAL mean:6.89071 min:0 max:255 sd:36.4702\n",
            "\t549: \"data:0.593\" NUMERICAL mean:17.2942 min:0 max:255 sd:56.8438\n",
            "\t550: \"data:0.594\" NUMERICAL mean:32.9737 min:0 max:255 sd:76.906\n",
            "\t551: \"data:0.595\" NUMERICAL mean:51.346 min:0 max:255 sd:92.7566\n",
            "\t552: \"data:0.596\" NUMERICAL mean:69.9327 min:0 max:255 sd:103.326\n",
            "\t553: \"data:0.597\" NUMERICAL mean:86.0668 min:0 max:255 sd:108.726\n",
            "\t554: \"data:0.598\" NUMERICAL mean:100.017 min:0 max:255 sd:111.038\n",
            "\t555: \"data:0.599\" NUMERICAL mean:111.531 min:0 max:255 sd:111.602\n",
            "\t556: \"data:0.6\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t557: \"data:0.60\" NUMERICAL mean:0.00428571 min:0 max:26 sd:0.303912\n",
            "\t558: \"data:0.600\" NUMERICAL mean:122.643 min:0 max:255 sd:111.351\n",
            "\t559: \"data:0.601\" NUMERICAL mean:131.368 min:0 max:255 sd:110.331\n",
            "\t560: \"data:0.602\" NUMERICAL mean:132.274 min:0 max:255 sd:110.209\n",
            "\t561: \"data:0.603\" NUMERICAL mean:126.082 min:0 max:255 sd:110.529\n",
            "\t562: \"data:0.604\" NUMERICAL mean:111.423 min:0 max:255 sd:110.363\n",
            "\t563: \"data:0.605\" NUMERICAL mean:90.8842 min:0 max:255 sd:107.805\n",
            "\t564: \"data:0.606\" NUMERICAL mean:67.7424 min:0 max:255 sd:100.447\n",
            "\t565: \"data:0.607\" NUMERICAL mean:46.9683 min:0 max:255 sd:88.6957\n",
            "\t566: \"data:0.608\" NUMERICAL mean:29.3556 min:0 max:255 sd:72.5163\n",
            "\t567: \"data:0.609\" NUMERICAL mean:16.1894 min:0 max:255 sd:54.394\n",
            "\t568: \"data:0.61\" NUMERICAL mean:0.0320238 min:0 max:128 sd:1.64086\n",
            "\t569: \"data:0.610\" NUMERICAL mean:7.92179 min:0 max:255 sd:38.491\n",
            "\t570: \"data:0.611\" NUMERICAL mean:3.78012 min:0 max:255 sd:26.4237\n",
            "\t571: \"data:0.612\" NUMERICAL mean:1.28429 min:0 max:255 sd:14.4498\n",
            "\t572: \"data:0.613\" NUMERICAL mean:0.250357 min:0 max:253 sd:6.15514\n",
            "\t573: \"data:0.614\" NUMERICAL mean:0.0420238 min:0 max:196 sd:2.44395\n",
            "\t574: \"data:0.615\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t575: \"data:0.616\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t576: \"data:0.617\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t577: \"data:0.618\" NUMERICAL mean:0.140476 min:0 max:192 sd:4.45381\n",
            "\t578: \"data:0.619\" NUMERICAL mean:1.18452 min:0 max:255 sd:14.086\n",
            "\t579: \"data:0.62\" NUMERICAL mean:0.0814286 min:0 max:212 sd:3.63217\n",
            "\t580: \"data:0.620\" NUMERICAL mean:4.52107 min:0 max:255 sd:28.7359\n",
            "\t581: \"data:0.621\" NUMERICAL mean:11.7989 min:0 max:255 sd:46.9603\n",
            "\t582: \"data:0.622\" NUMERICAL mean:23.564 min:0 max:255 sd:65.4792\n",
            "\t583: \"data:0.623\" NUMERICAL mean:39.4985 min:0 max:255 sd:82.8282\n",
            "\t584: \"data:0.624\" NUMERICAL mean:59.4008 min:0 max:255 sd:97.2919\n",
            "\t585: \"data:0.625\" NUMERICAL mean:79.4974 min:0 max:255 sd:106.414\n",
            "\t586: \"data:0.626\" NUMERICAL mean:98.6989 min:0 max:255 sd:111.487\n",
            "\t587: \"data:0.627\" NUMERICAL mean:113.845 min:0 max:255 sd:113.203\n",
            "\t588: \"data:0.628\" NUMERICAL mean:124.251 min:0 max:255 sd:113.062\n",
            "\t589: \"data:0.629\" NUMERICAL mean:126.722 min:0 max:255 sd:112.23\n",
            "\t590: \"data:0.63\" NUMERICAL mean:0.157976 min:0 max:255 sd:5.8784\n",
            "\t591: \"data:0.630\" NUMERICAL mean:122.213 min:0 max:255 sd:112.076\n",
            "\t592: \"data:0.631\" NUMERICAL mean:109.513 min:0 max:255 sd:111.197\n",
            "\t593: \"data:0.632\" NUMERICAL mean:90.0626 min:0 max:255 sd:107.81\n",
            "\t594: \"data:0.633\" NUMERICAL mean:67.0851 min:0 max:255 sd:100.051\n",
            "\t595: \"data:0.634\" NUMERICAL mean:46.2721 min:0 max:255 sd:87.0464\n",
            "\t596: \"data:0.635\" NUMERICAL mean:29.427 min:0 max:255 sd:72.1082\n",
            "\t597: \"data:0.636\" NUMERICAL mean:17.1442 min:0 max:255 sd:56.148\n",
            "\t598: \"data:0.637\" NUMERICAL mean:9.06976 min:0 max:255 sd:40.9449\n",
            "\t599: \"data:0.638\" NUMERICAL mean:4.54369 min:0 max:255 sd:28.6734\n",
            "\t600: \"data:0.639\" NUMERICAL mean:2.02464 min:0 max:255 sd:19.8151\n",
            "\t601: \"data:0.64\" NUMERICAL mean:0.256071 min:0 max:253 sd:6.30017\n",
            "\t602: \"data:0.640\" NUMERICAL mean:0.767143 min:0 max:255 sd:11.7563\n",
            "\t603: \"data:0.641\" NUMERICAL mean:0.159524 min:0 max:200 sd:4.76036\n",
            "\t604: \"data:0.642\" NUMERICAL mean:0.00761905 min:0 max:32 sd:0.460009\n",
            "\t605: \"data:0.643\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t606: \"data:0.644\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t607: \"data:0.645\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t608: \"data:0.646\" NUMERICAL mean:0.0708333 min:0 max:217 sd:2.99096\n",
            "\t609: \"data:0.647\" NUMERICAL mean:0.518095 min:0 max:253 sd:8.81918\n",
            "\t610: \"data:0.648\" NUMERICAL mean:2.19524 min:0 max:255 sd:19.8373\n",
            "\t611: \"data:0.649\" NUMERICAL mean:5.6519 min:0 max:255 sd:31.7298\n",
            "\t612: \"data:0.65\" NUMERICAL mean:0.519405 min:0 max:255 sd:9.78966\n",
            "\t613: \"data:0.650\" NUMERICAL mean:12.4182 min:0 max:255 sd:47.196\n",
            "\t614: \"data:0.651\" NUMERICAL mean:23.235 min:0 max:255 sd:64.0017\n",
            "\t615: \"data:0.652\" NUMERICAL mean:38.5246 min:0 max:255 sd:79.8725\n",
            "\t616: \"data:0.653\" NUMERICAL mean:56.863 min:0 max:255 sd:94.2871\n",
            "\t617: \"data:0.654\" NUMERICAL mean:75.898 min:0 max:255 sd:103.677\n",
            "\t618: \"data:0.655\" NUMERICAL mean:92.0968 min:0 max:255 sd:108.408\n",
            "\t619: \"data:0.656\" NUMERICAL mean:100.489 min:0 max:255 sd:110.318\n",
            "\t620: \"data:0.657\" NUMERICAL mean:99.91 min:0 max:255 sd:110.232\n",
            "\t621: \"data:0.658\" NUMERICAL mean:92.1487 min:0 max:255 sd:108.147\n",
            "\t622: \"data:0.659\" NUMERICAL mean:78.1085 min:0 max:255 sd:104.13\n",
            "\t623: \"data:0.66\" NUMERICAL mean:1.01036 min:0 max:255 sd:14.2831\n",
            "\t624: \"data:0.660\" NUMERICAL mean:59.8723 min:0 max:255 sd:94.9472\n",
            "\t625: \"data:0.661\" NUMERICAL mean:41.4224 min:0 max:255 sd:82.5035\n",
            "\t626: \"data:0.662\" NUMERICAL mean:26.3765 min:0 max:255 sd:68.1844\n",
            "\t627: \"data:0.663\" NUMERICAL mean:15.5889 min:0 max:255 sd:53.1734\n",
            "\t628: \"data:0.664\" NUMERICAL mean:8.95274 min:0 max:255 sd:41.3291\n",
            "\t629: \"data:0.665\" NUMERICAL mean:4.71512 min:0 max:255 sd:30.2096\n",
            "\t630: \"data:0.666\" NUMERICAL mean:2.52524 min:0 max:255 sd:22.1458\n",
            "\t631: \"data:0.667\" NUMERICAL mean:1.21143 min:0 max:255 sd:15.3626\n",
            "\t632: \"data:0.668\" NUMERICAL mean:0.47881 min:0 max:255 sd:9.28023\n",
            "\t633: \"data:0.669\" NUMERICAL mean:0.0553571 min:0 max:229 sd:2.9974\n",
            "\t634: \"data:0.67\" NUMERICAL mean:1.41286 min:0 max:255 sd:16.6028\n",
            "\t635: \"data:0.670\" NUMERICAL mean:0.037381 min:0 max:150 sd:1.99721\n",
            "\t636: \"data:0.671\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t637: \"data:0.672\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t638: \"data:0.673\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t639: \"data:0.674\" NUMERICAL mean:0.027619 min:0 max:217 sd:2.37315\n",
            "\t640: \"data:0.675\" NUMERICAL mean:0.194405 min:0 max:253 sd:5.80277\n",
            "\t641: \"data:0.676\" NUMERICAL mean:0.707143 min:0 max:255 sd:10.6489\n",
            "\t642: \"data:0.677\" NUMERICAL mean:1.75429 min:0 max:255 sd:17.8693\n",
            "\t643: \"data:0.678\" NUMERICAL mean:4.42452 min:0 max:255 sd:28.1998\n",
            "\t644: \"data:0.679\" NUMERICAL mean:9.06226 min:0 max:255 sd:40.8605\n",
            "\t645: \"data:0.68\" NUMERICAL mean:1.95393 min:0 max:255 sd:19.2727\n",
            "\t646: \"data:0.680\" NUMERICAL mean:16.2552 min:0 max:255 sd:54.6009\n",
            "\t647: \"data:0.681\" NUMERICAL mean:26.0294 min:0 max:255 sd:68.8437\n",
            "\t648: \"data:0.682\" NUMERICAL mean:36.4849 min:0 max:255 sd:79.4139\n",
            "\t649: \"data:0.683\" NUMERICAL mean:45.8055 min:0 max:255 sd:87.3958\n",
            "\t650: \"data:0.684\" NUMERICAL mean:51.036 min:0 max:255 sd:90.7626\n",
            "\t651: \"data:0.685\" NUMERICAL mean:50.1602 min:0 max:255 sd:90.1168\n",
            "\t652: \"data:0.686\" NUMERICAL mean:46.1352 min:0 max:255 sd:86.8579\n",
            "\t653: \"data:0.687\" NUMERICAL mean:38.922 min:0 max:255 sd:80.6156\n",
            "\t654: \"data:0.688\" NUMERICAL mean:28.6869 min:0 max:255 sd:70.1776\n",
            "\t655: \"data:0.689\" NUMERICAL mean:19.8837 min:0 max:255 sd:59.7623\n",
            "\t656: \"data:0.69\" NUMERICAL mean:2.65202 min:0 max:255 sd:22.6264\n",
            "\t657: \"data:0.690\" NUMERICAL mean:12.0318 min:0 max:255 sd:47.0889\n",
            "\t658: \"data:0.691\" NUMERICAL mean:7.25321 min:0 max:255 sd:36.9827\n",
            "\t659: \"data:0.692\" NUMERICAL mean:4.28548 min:0 max:255 sd:28.4258\n",
            "\t660: \"data:0.693\" NUMERICAL mean:2.28262 min:0 max:255 sd:21.3547\n",
            "\t661: \"data:0.694\" NUMERICAL mean:1.26286 min:0 max:255 sd:15.2509\n",
            "\t662: \"data:0.695\" NUMERICAL mean:0.508333 min:0 max:255 sd:9.6612\n",
            "\t663: \"data:0.696\" NUMERICAL mean:0.162857 min:0 max:252 sd:4.7498\n",
            "\t664: \"data:0.697\" NUMERICAL mean:0.00833333 min:0 max:70 sd:0.763717\n",
            "\t665: \"data:0.698\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t666: \"data:0.699\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t667: \"data:0.7\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t668: \"data:0.70\" NUMERICAL mean:3.04905 min:0 max:255 sd:24.203\n",
            "\t669: \"data:0.700\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t670: \"data:0.701\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t671: \"data:0.702\" NUMERICAL mean:0.00190476 min:0 max:16 sd:0.174564\n",
            "\t672: \"data:0.703\" NUMERICAL mean:0.0575 min:0 max:175 sd:2.79824\n",
            "\t673: \"data:0.704\" NUMERICAL mean:0.209881 min:0 max:253 sd:6.23394\n",
            "\t674: \"data:0.705\" NUMERICAL mean:0.418929 min:0 max:254 sd:8.89519\n",
            "\t675: \"data:0.706\" NUMERICAL mean:1.00869 min:0 max:255 sd:13.1066\n",
            "\t676: \"data:0.707\" NUMERICAL mean:2.78321 min:0 max:255 sd:22.655\n",
            "\t677: \"data:0.708\" NUMERICAL mean:5.9019 min:0 max:255 sd:34.3869\n",
            "\t678: \"data:0.709\" NUMERICAL mean:9.60929 min:0 max:255 sd:43.5204\n",
            "\t679: \"data:0.71\" NUMERICAL mean:3.5706 min:0 max:255 sd:25.7744\n",
            "\t680: \"data:0.710\" NUMERICAL mean:13.7156 min:0 max:255 sd:51.722\n",
            "\t681: \"data:0.711\" NUMERICAL mean:16.8948 min:0 max:255 sd:56.993\n",
            "\t682: \"data:0.712\" NUMERICAL mean:17.9011 min:0 max:255 sd:58.4478\n",
            "\t683: \"data:0.713\" NUMERICAL mean:17.4796 min:0 max:255 sd:58.1936\n",
            "\t684: \"data:0.714\" NUMERICAL mean:15.7045 min:0 max:255 sd:54.1858\n",
            "\t685: \"data:0.715\" NUMERICAL mean:13.7964 min:0 max:255 sd:51.2781\n",
            "\t686: \"data:0.716\" NUMERICAL mean:11.0536 min:0 max:255 sd:46.181\n",
            "\t687: \"data:0.717\" NUMERICAL mean:7.60405 min:0 max:255 sd:38.0425\n",
            "\t688: \"data:0.718\" NUMERICAL mean:4.70655 min:0 max:255 sd:29.9226\n",
            "\t689: \"data:0.719\" NUMERICAL mean:2.71738 min:0 max:255 sd:23.2535\n",
            "\t690: \"data:0.72\" NUMERICAL mean:3.79476 min:0 max:255 sd:27.5091\n",
            "\t691: \"data:0.720\" NUMERICAL mean:1.57714 min:0 max:255 sd:17.1154\n",
            "\t692: \"data:0.721\" NUMERICAL mean:0.773571 min:0 max:255 sd:12.5843\n",
            "\t693: \"data:0.722\" NUMERICAL mean:0.333571 min:0 max:255 sd:7.39739\n",
            "\t694: \"data:0.723\" NUMERICAL mean:0.161786 min:0 max:255 sd:5.58658\n",
            "\t695: \"data:0.724\" NUMERICAL mean:0.0397619 min:0 max:145 sd:2.07791\n",
            "\t696: \"data:0.725\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t697: \"data:0.726\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t698: \"data:0.727\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t699: \"data:0.728\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t700: \"data:0.729\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t701: \"data:0.73\" NUMERICAL mean:3.2306 min:0 max:255 sd:25.2785\n",
            "\t702: \"data:0.730\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t703: \"data:0.731\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t704: \"data:0.732\" NUMERICAL mean:0.0255952 min:0 max:140 sd:1.6666\n",
            "\t705: \"data:0.733\" NUMERICAL mean:0.0967857 min:0 max:199 sd:3.74964\n",
            "\t706: \"data:0.734\" NUMERICAL mean:0.339762 min:0 max:253 sd:7.17015\n",
            "\t707: \"data:0.735\" NUMERICAL mean:1.16917 min:0 max:253 sd:14.9992\n",
            "\t708: \"data:0.736\" NUMERICAL mean:2.36381 min:0 max:255 sd:21.8658\n",
            "\t709: \"data:0.737\" NUMERICAL mean:3.58821 min:0 max:255 sd:26.5243\n",
            "\t710: \"data:0.738\" NUMERICAL mean:4.97226 min:0 max:255 sd:31.2133\n",
            "\t711: \"data:0.739\" NUMERICAL mean:6.19048 min:0 max:255 sd:34.3529\n",
            "\t712: \"data:0.74\" NUMERICAL mean:2.3769 min:0 max:255 sd:21.1447\n",
            "\t713: \"data:0.740\" NUMERICAL mean:6.61857 min:0 max:255 sd:35.9309\n",
            "\t714: \"data:0.741\" NUMERICAL mean:6.33357 min:0 max:255 sd:34.8236\n",
            "\t715: \"data:0.742\" NUMERICAL mean:5.44095 min:0 max:255 sd:32.1849\n",
            "\t716: \"data:0.743\" NUMERICAL mean:4.69452 min:0 max:255 sd:29.9415\n",
            "\t717: \"data:0.744\" NUMERICAL mean:3.99774 min:0 max:255 sd:27.9112\n",
            "\t718: \"data:0.745\" NUMERICAL mean:2.90012 min:0 max:255 sd:23.951\n",
            "\t719: \"data:0.746\" NUMERICAL mean:1.42476 min:0 max:255 sd:15.7511\n",
            "\t720: \"data:0.747\" NUMERICAL mean:0.7175 min:0 max:255 sd:12.0258\n",
            "\t721: \"data:0.748\" NUMERICAL mean:0.3375 min:0 max:253 sd:8.15039\n",
            "\t722: \"data:0.749\" NUMERICAL mean:0.123571 min:0 max:253 sd:4.67664\n",
            "\t723: \"data:0.75\" NUMERICAL mean:1.83048 min:0 max:255 sd:19.0556\n",
            "\t724: \"data:0.750\" NUMERICAL mean:0.0359524 min:0 max:253 sd:2.78984\n",
            "\t725: \"data:0.751\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t726: \"data:0.752\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t727: \"data:0.753\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t728: \"data:0.754\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t729: \"data:0.755\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t730: \"data:0.756\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t731: \"data:0.757\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t732: \"data:0.758\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t733: \"data:0.759\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t734: \"data:0.76\" NUMERICAL mean:1.15452 min:0 max:255 sd:14.8889\n",
            "\t735: \"data:0.760\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t736: \"data:0.761\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t737: \"data:0.762\" NUMERICAL mean:0.0245238 min:0 max:206 sd:2.24751\n",
            "\t738: \"data:0.763\" NUMERICAL mean:0.0617857 min:0 max:173 sd:2.87201\n",
            "\t739: \"data:0.764\" NUMERICAL mean:0.165238 min:0 max:253 sd:5.53976\n",
            "\t740: \"data:0.765\" NUMERICAL mean:0.240119 min:0 max:254 sd:6.89132\n",
            "\t741: \"data:0.766\" NUMERICAL mean:0.379643 min:0 max:255 sd:8.02019\n",
            "\t742: \"data:0.767\" NUMERICAL mean:0.513333 min:0 max:254 sd:10.0653\n",
            "\t743: \"data:0.768\" NUMERICAL mean:0.56381 min:0 max:255 sd:10.5531\n",
            "\t744: \"data:0.769\" NUMERICAL mean:0.621786 min:0 max:255 sd:10.6889\n",
            "\t745: \"data:0.77\" NUMERICAL mean:0.476071 min:0 max:255 sd:9.065\n",
            "\t746: \"data:0.770\" NUMERICAL mean:0.699167 min:0 max:255 sd:11.3208\n",
            "\t747: \"data:0.771\" NUMERICAL mean:0.569762 min:0 max:255 sd:10.004\n",
            "\t748: \"data:0.772\" NUMERICAL mean:0.546905 min:0 max:255 sd:10.3769\n",
            "\t749: \"data:0.773\" NUMERICAL mean:0.44 min:0 max:255 sd:9.5828\n",
            "\t750: \"data:0.774\" NUMERICAL mean:0.166071 min:0 max:204 sd:4.50081\n",
            "\t751: \"data:0.775\" NUMERICAL mean:0.089881 min:0 max:253 sd:4.66598\n",
            "\t752: \"data:0.776\" NUMERICAL mean:0.0309524 min:0 max:130 sd:2.0057\n",
            "\t753: \"data:0.777\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t754: \"data:0.778\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t755: \"data:0.779\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t756: \"data:0.78\" NUMERICAL mean:0.224048 min:0 max:254 sd:6.55849\n",
            "\t757: \"data:0.780\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t758: \"data:0.781\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t759: \"data:0.782\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t760: \"data:0.783\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t761: \"data:0.79\" NUMERICAL mean:0.110833 min:0 max:211 sd:4.44297\n",
            "\t762: \"data:0.8\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t763: \"data:0.80\" NUMERICAL mean:0.0428571 min:0 max:254 sd:2.95439\n",
            "\t764: \"data:0.81\" NUMERICAL mean:0.00654762 min:0 max:55 sd:0.600063\n",
            "\t765: \"data:0.82\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t766: \"data:0.83\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t767: \"data:0.84\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t768: \"data:0.85\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t769: \"data:0.86\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t770: \"data:0.87\" NUMERICAL mean:0.00047619 min:0 max:4 sd:0.043641\n",
            "\t771: \"data:0.88\" NUMERICAL mean:0.00892857 min:0 max:58 sd:0.659395\n",
            "\t772: \"data:0.89\" NUMERICAL mean:0.106905 min:0 max:255 sd:4.05298\n",
            "\t773: \"data:0.9\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t774: \"data:0.90\" NUMERICAL mean:0.237262 min:0 max:255 sd:6.59262\n",
            "\t775: \"data:0.91\" NUMERICAL mean:0.503929 min:0 max:255 sd:9.83581\n",
            "\t776: \"data:0.92\" NUMERICAL mean:1.09131 min:0 max:255 sd:14.0543\n",
            "\t777: \"data:0.93\" NUMERICAL mean:2.2519 min:0 max:255 sd:20.5751\n",
            "\t778: \"data:0.94\" NUMERICAL mean:3.86012 min:0 max:255 sd:27.6924\n",
            "\t779: \"data:0.95\" NUMERICAL mean:5.52667 min:0 max:255 sd:33.181\n",
            "\t780: \"data:0.96\" NUMERICAL mean:7.21167 min:0 max:255 sd:37.1248\n",
            "\t781: \"data:0.97\" NUMERICAL mean:9.7456 min:0 max:255 sd:43.3272\n",
            "\t782: \"data:0.98\" NUMERICAL mean:11.6476 min:0 max:255 sd:47.4034\n",
            "\t783: \"data:0.99\" NUMERICAL mean:13.0385 min:0 max:255 sd:50.1679\n",
            "\n",
            "CATEGORICAL: 1 (0.127389%)\n",
            "\t784: \"__LABEL\" CATEGORICAL integerized vocab-size:11 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO 2023-01-06T04:56:06.716708668+00:00 kernel.cc:883] Configure learner\n",
            "[INFO 2023-01-06T04:56:06.71804893+00:00 kernel.cc:913] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"data:0\\\\.0\"\n",
            "features: \"data:0\\\\.1\"\n",
            "features: \"data:0\\\\.10\"\n",
            "features: \"data:0\\\\.100\"\n",
            "features: \"data:0\\\\.101\"\n",
            "features: \"data:0\\\\.102\"\n",
            "features: \"data:0\\\\.103\"\n",
            "features: \"data:0\\\\.104\"\n",
            "features: \"data:0\\\\.105\"\n",
            "features: \"data:0\\\\.106\"\n",
            "features: \"data:0\\\\.107\"\n",
            "features: \"data:0\\\\.108\"\n",
            "features: \"data:0\\\\.109\"\n",
            "features: \"data:0\\\\.11\"\n",
            "features: \"data:0\\\\.110\"\n",
            "features: \"data:0\\\\.111\"\n",
            "features: \"data:0\\\\.112\"\n",
            "features: \"data:0\\\\.113\"\n",
            "features: \"data:0\\\\.114\"\n",
            "features: \"data:0\\\\.115\"\n",
            "features: \"data:0\\\\.116\"\n",
            "features: \"data:0\\\\.117\"\n",
            "features: \"data:0\\\\.118\"\n",
            "features: \"data:0\\\\.119\"\n",
            "features: \"data:0\\\\.12\"\n",
            "features: \"data:0\\\\.120\"\n",
            "features: \"data:0\\\\.121\"\n",
            "features: \"data:0\\\\.122\"\n",
            "features: \"data:0\\\\.123\"\n",
            "features: \"data:0\\\\.124\"\n",
            "features: \"data:0\\\\.125\"\n",
            "features: \"data:0\\\\.126\"\n",
            "features: \"data:0\\\\.127\"\n",
            "features: \"data:0\\\\.128\"\n",
            "features: \"data:0\\\\.129\"\n",
            "features: \"data:0\\\\.13\"\n",
            "features: \"data:0\\\\.130\"\n",
            "features: \"data:0\\\\.131\"\n",
            "features: \"data:0\\\\.132\"\n",
            "features: \"data:0\\\\.133\"\n",
            "features: \"data:0\\\\.134\"\n",
            "features: \"data:0\\\\.135\"\n",
            "features: \"data:0\\\\.136\"\n",
            "features: \"data:0\\\\.137\"\n",
            "features: \"data:0\\\\.138\"\n",
            "features: \"data:0\\\\.139\"\n",
            "features: \"data:0\\\\.14\"\n",
            "features: \"data:0\\\\.140\"\n",
            "features: \"data:0\\\\.141\"\n",
            "features: \"data:0\\\\.142\"\n",
            "features: \"data:0\\\\.143\"\n",
            "features: \"data:0\\\\.144\"\n",
            "features: \"data:0\\\\.145\"\n",
            "features: \"data:0\\\\.146\"\n",
            "features: \"data:0\\\\.147\"\n",
            "features: \"data:0\\\\.148\"\n",
            "features: \"data:0\\\\.149\"\n",
            "features: \"data:0\\\\.15\"\n",
            "features: \"data:0\\\\.150\"\n",
            "features: \"data:0\\\\.151\"\n",
            "features: \"data:0\\\\.152\"\n",
            "features: \"data:0\\\\.153\"\n",
            "features: \"data:0\\\\.154\"\n",
            "features: \"data:0\\\\.155\"\n",
            "features: \"data:0\\\\.156\"\n",
            "features: \"data:0\\\\.157\"\n",
            "features: \"data:0\\\\.158\"\n",
            "features: \"data:0\\\\.159\"\n",
            "features: \"data:0\\\\.16\"\n",
            "features: \"data:0\\\\.160\"\n",
            "features: \"data:0\\\\.161\"\n",
            "features: \"data:0\\\\.162\"\n",
            "features: \"data:0\\\\.163\"\n",
            "features: \"data:0\\\\.164\"\n",
            "features: \"data:0\\\\.165\"\n",
            "features: \"data:0\\\\.166\"\n",
            "features: \"data:0\\\\.167\"\n",
            "features: \"data:0\\\\.168\"\n",
            "features: \"data:0\\\\.169\"\n",
            "features: \"data:0\\\\.17\"\n",
            "features: \"data:0\\\\.170\"\n",
            "features: \"data:0\\\\.171\"\n",
            "features: \"data:0\\\\.172\"\n",
            "features: \"data:0\\\\.173\"\n",
            "features: \"data:0\\\\.174\"\n",
            "features: \"data:0\\\\.175\"\n",
            "features: \"data:0\\\\.176\"\n",
            "features: \"data:0\\\\.177\"\n",
            "features: \"data:0\\\\.178\"\n",
            "features: \"data:0\\\\.179\"\n",
            "features: \"data:0\\\\.18\"\n",
            "features: \"data:0\\\\.180\"\n",
            "features: \"data:0\\\\.181\"\n",
            "features: \"data:0\\\\.182\"\n",
            "features: \"data:0\\\\.183\"\n",
            "features: \"data:0\\\\.184\"\n",
            "features: \"data:0\\\\.185\"\n",
            "features: \"data:0\\\\.186\"\n",
            "features: \"data:0\\\\.187\"\n",
            "features: \"data:0\\\\.188\"\n",
            "features: \"data:0\\\\.189\"\n",
            "features: \"data:0\\\\.19\"\n",
            "features: \"data:0\\\\.190\"\n",
            "features: \"data:0\\\\.191\"\n",
            "features: \"data:0\\\\.192\"\n",
            "features: \"data:0\\\\.193\"\n",
            "features: \"data:0\\\\.194\"\n",
            "features: \"data:0\\\\.195\"\n",
            "features: \"data:0\\\\.196\"\n",
            "features: \"data:0\\\\.197\"\n",
            "features: \"data:0\\\\.198\"\n",
            "features: \"data:0\\\\.199\"\n",
            "features: \"data:0\\\\.2\"\n",
            "features: \"data:0\\\\.20\"\n",
            "features: \"data:0\\\\.200\"\n",
            "features: \"data:0\\\\.201\"\n",
            "features: \"data:0\\\\.202\"\n",
            "features: \"data:0\\\\.203\"\n",
            "features: \"data:0\\\\.204\"\n",
            "features: \"data:0\\\\.205\"\n",
            "features: \"data:0\\\\.206\"\n",
            "features: \"data:0\\\\.207\"\n",
            "features: \"data:0\\\\.208\"\n",
            "features: \"data:0\\\\.209\"\n",
            "features: \"data:0\\\\.21\"\n",
            "features: \"data:0\\\\.210\"\n",
            "features: \"data:0\\\\.211\"\n",
            "features: \"data:0\\\\.212\"\n",
            "features: \"data:0\\\\.213\"\n",
            "features: \"data:0\\\\.214\"\n",
            "features: \"data:0\\\\.215\"\n",
            "features: \"data:0\\\\.216\"\n",
            "features: \"data:0\\\\.217\"\n",
            "features: \"data:0\\\\.218\"\n",
            "features: \"data:0\\\\.219\"\n",
            "features: \"data:0\\\\.22\"\n",
            "features: \"data:0\\\\.220\"\n",
            "features: \"data:0\\\\.221\"\n",
            "features: \"data:0\\\\.222\"\n",
            "features: \"data:0\\\\.223\"\n",
            "features: \"data:0\\\\.224\"\n",
            "features: \"data:0\\\\.225\"\n",
            "features: \"data:0\\\\.226\"\n",
            "features: \"data:0\\\\.227\"\n",
            "features: \"data:0\\\\.228\"\n",
            "features: \"data:0\\\\.229\"\n",
            "features: \"data:0\\\\.23\"\n",
            "features: \"data:0\\\\.230\"\n",
            "features: \"data:0\\\\.231\"\n",
            "features: \"data:0\\\\.232\"\n",
            "features: \"data:0\\\\.233\"\n",
            "features: \"data:0\\\\.234\"\n",
            "features: \"data:0\\\\.235\"\n",
            "features: \"data:0\\\\.236\"\n",
            "features: \"data:0\\\\.237\"\n",
            "features: \"data:0\\\\.238\"\n",
            "features: \"data:0\\\\.239\"\n",
            "features: \"data:0\\\\.24\"\n",
            "features: \"data:0\\\\.240\"\n",
            "features: \"data:0\\\\.241\"\n",
            "features: \"data:0\\\\.242\"\n",
            "features: \"data:0\\\\.243\"\n",
            "features: \"data:0\\\\.244\"\n",
            "features: \"data:0\\\\.245\"\n",
            "features: \"data:0\\\\.246\"\n",
            "features: \"data:0\\\\.247\"\n",
            "features: \"data:0\\\\.248\"\n",
            "features: \"data:0\\\\.249\"\n",
            "features: \"data:0\\\\.25\"\n",
            "features: \"data:0\\\\.250\"\n",
            "features: \"data:0\\\\.251\"\n",
            "features: \"data:0\\\\.252\"\n",
            "features: \"data:0\\\\.253\"\n",
            "features: \"data:0\\\\.254\"\n",
            "features: \"data:0\\\\.255\"\n",
            "features: \"data:0\\\\.256\"\n",
            "features: \"data:0\\\\.257\"\n",
            "features: \"data:0\\\\.258\"\n",
            "features: \"data:0\\\\.259\"\n",
            "features: \"data:0\\\\.26\"\n",
            "features: \"data:0\\\\.260\"\n",
            "features: \"data:0\\\\.261\"\n",
            "features: \"data:0\\\\.262\"\n",
            "features: \"data:0\\\\.263\"\n",
            "features: \"data:0\\\\.264\"\n",
            "features: \"data:0\\\\.265\"\n",
            "features: \"data:0\\\\.266\"\n",
            "features: \"data:0\\\\.267\"\n",
            "features: \"data:0\\\\.268\"\n",
            "features: \"data:0\\\\.269\"\n",
            "features: \"data:0\\\\.27\"\n",
            "features: \"data:0\\\\.270\"\n",
            "features: \"data:0\\\\.271\"\n",
            "features: \"data:0\\\\.272\"\n",
            "features: \"data:0\\\\.273\"\n",
            "features: \"data:0\\\\.274\"\n",
            "features: \"data:0\\\\.275\"\n",
            "features: \"data:0\\\\.276\"\n",
            "features: \"data:0\\\\.277\"\n",
            "features: \"data:0\\\\.278\"\n",
            "features: \"data:0\\\\.279\"\n",
            "features: \"data:0\\\\.28\"\n",
            "features: \"data:0\\\\.280\"\n",
            "features: \"data:0\\\\.281\"\n",
            "features: \"data:0\\\\.282\"\n",
            "features: \"data:0\\\\.283\"\n",
            "features: \"data:0\\\\.284\"\n",
            "features: \"data:0\\\\.285\"\n",
            "features: \"data:0\\\\.286\"\n",
            "features: \"data:0\\\\.287\"\n",
            "features: \"data:0\\\\.288\"\n",
            "features: \"data:0\\\\.289\"\n",
            "features: \"data:0\\\\.29\"\n",
            "features: \"data:0\\\\.290\"\n",
            "features: \"data:0\\\\.291\"\n",
            "features: \"data:0\\\\.292\"\n",
            "features: \"data:0\\\\.293\"\n",
            "features: \"data:0\\\\.294\"\n",
            "features: \"data:0\\\\.295\"\n",
            "features: \"data:0\\\\.296\"\n",
            "features: \"data:0\\\\.297\"\n",
            "features: \"data:0\\\\.298\"\n",
            "features: \"data:0\\\\.299\"\n",
            "features: \"data:0\\\\.3\"\n",
            "features: \"data:0\\\\.30\"\n",
            "features: \"data:0\\\\.300\"\n",
            "features: \"data:0\\\\.301\"\n",
            "features: \"data:0\\\\.302\"\n",
            "features: \"data:0\\\\.303\"\n",
            "features: \"data:0\\\\.304\"\n",
            "features: \"data:0\\\\.305\"\n",
            "features: \"data:0\\\\.306\"\n",
            "features: \"data:0\\\\.307\"\n",
            "features: \"data:0\\\\.308\"\n",
            "features: \"data:0\\\\.309\"\n",
            "features: \"data:0\\\\.31\"\n",
            "features: \"data:0\\\\.310\"\n",
            "features: \"data:0\\\\.311\"\n",
            "features: \"data:0\\\\.312\"\n",
            "features: \"data:0\\\\.313\"\n",
            "features: \"data:0\\\\.314\"\n",
            "features: \"data:0\\\\.315\"\n",
            "features: \"data:0\\\\.316\"\n",
            "features: \"data:0\\\\.317\"\n",
            "features: \"data:0\\\\.318\"\n",
            "features: \"data:0\\\\.319\"\n",
            "features: \"data:0\\\\.32\"\n",
            "features: \"data:0\\\\.320\"\n",
            "features: \"data:0\\\\.321\"\n",
            "features: \"data:0\\\\.322\"\n",
            "features: \"data:0\\\\.323\"\n",
            "features: \"data:0\\\\.324\"\n",
            "features: \"data:0\\\\.325\"\n",
            "features: \"data:0\\\\.326\"\n",
            "features: \"data:0\\\\.327\"\n",
            "features: \"data:0\\\\.328\"\n",
            "features: \"data:0\\\\.329\"\n",
            "features: \"data:0\\\\.33\"\n",
            "features: \"data:0\\\\.330\"\n",
            "features: \"data:0\\\\.331\"\n",
            "features: \"data:0\\\\.332\"\n",
            "features: \"data:0\\\\.333\"\n",
            "features: \"data:0\\\\.334\"\n",
            "features: \"data:0\\\\.335\"\n",
            "features: \"data:0\\\\.336\"\n",
            "features: \"data:0\\\\.337\"\n",
            "features: \"data:0\\\\.338\"\n",
            "features: \"data:0\\\\.339\"\n",
            "features: \"data:0\\\\.34\"\n",
            "features: \"data:0\\\\.340\"\n",
            "features: \"data:0\\\\.341\"\n",
            "features: \"data:0\\\\.342\"\n",
            "features: \"data:0\\\\.343\"\n",
            "features: \"data:0\\\\.344\"\n",
            "features: \"data:0\\\\.345\"\n",
            "features: \"data:0\\\\.346\"\n",
            "features: \"data:0\\\\.347\"\n",
            "features: \"data:0\\\\.348\"\n",
            "features: \"data:0\\\\.349\"\n",
            "features: \"data:0\\\\.35\"\n",
            "features: \"data:0\\\\.350\"\n",
            "features: \"data:0\\\\.351\"\n",
            "features: \"data:0\\\\.352\"\n",
            "features: \"data:0\\\\.353\"\n",
            "features: \"data:0\\\\.354\"\n",
            "features: \"data:0\\\\.355\"\n",
            "features: \"data:0\\\\.356\"\n",
            "features: \"data:0\\\\.357\"\n",
            "features: \"data:0\\\\.358\"\n",
            "features: \"data:0\\\\.359\"\n",
            "features: \"data:0\\\\.36\"\n",
            "features: \"data:0\\\\.360\"\n",
            "features: \"data:0\\\\.361\"\n",
            "features: \"data:0\\\\.362\"\n",
            "features: \"data:0\\\\.363\"\n",
            "features: \"data:0\\\\.364\"\n",
            "features: \"data:0\\\\.365\"\n",
            "features: \"data:0\\\\.366\"\n",
            "features: \"data:0\\\\.367\"\n",
            "features: \"data:0\\\\.368\"\n",
            "features: \"data:0\\\\.369\"\n",
            "features: \"data:0\\\\.37\"\n",
            "features: \"data:0\\\\.370\"\n",
            "features: \"data:0\\\\.371\"\n",
            "features: \"data:0\\\\.372\"\n",
            "features: \"data:0\\\\.373\"\n",
            "features: \"data:0\\\\.374\"\n",
            "features: \"data:0\\\\.375\"\n",
            "features: \"data:0\\\\.376\"\n",
            "features: \"data:0\\\\.377\"\n",
            "features: \"data:0\\\\.378\"\n",
            "features: \"data:0\\\\.379\"\n",
            "features: \"data:0\\\\.38\"\n",
            "features: \"data:0\\\\.380\"\n",
            "features: \"data:0\\\\.381\"\n",
            "features: \"data:0\\\\.382\"\n",
            "features: \"data:0\\\\.383\"\n",
            "features: \"data:0\\\\.384\"\n",
            "features: \"data:0\\\\.385\"\n",
            "features: \"data:0\\\\.386\"\n",
            "features: \"data:0\\\\.387\"\n",
            "features: \"data:0\\\\.388\"\n",
            "features: \"data:0\\\\.389\"\n",
            "features: \"data:0\\\\.39\"\n",
            "features: \"data:0\\\\.390\"\n",
            "features: \"data:0\\\\.391\"\n",
            "features: \"data:0\\\\.392\"\n",
            "features: \"data:0\\\\.393\"\n",
            "features: \"data:0\\\\.394\"\n",
            "features: \"data:0\\\\.395\"\n",
            "features: \"data:0\\\\.396\"\n",
            "features: \"data:0\\\\.397\"\n",
            "features: \"data:0\\\\.398\"\n",
            "features: \"data:0\\\\.399\"\n",
            "features: \"data:0\\\\.4\"\n",
            "features: \"data:0\\\\.40\"\n",
            "features: \"data:0\\\\.400\"\n",
            "features: \"data:0\\\\.401\"\n",
            "features: \"data:0\\\\.402\"\n",
            "features: \"data:0\\\\.403\"\n",
            "features: \"data:0\\\\.404\"\n",
            "features: \"data:0\\\\.405\"\n",
            "features: \"data:0\\\\.406\"\n",
            "features: \"data:0\\\\.407\"\n",
            "features: \"data:0\\\\.408\"\n",
            "features: \"data:0\\\\.409\"\n",
            "features: \"data:0\\\\.41\"\n",
            "features: \"data:0\\\\.410\"\n",
            "features: \"data:0\\\\.411\"\n",
            "features: \"data:0\\\\.412\"\n",
            "features: \"data:0\\\\.413\"\n",
            "features: \"data:0\\\\.414\"\n",
            "features: \"data:0\\\\.415\"\n",
            "features: \"data:0\\\\.416\"\n",
            "features: \"data:0\\\\.417\"\n",
            "features: \"data:0\\\\.418\"\n",
            "features: \"data:0\\\\.419\"\n",
            "features: \"data:0\\\\.42\"\n",
            "features: \"data:0\\\\.420\"\n",
            "features: \"data:0\\\\.421\"\n",
            "features: \"data:0\\\\.422\"\n",
            "features: \"data:0\\\\.423\"\n",
            "features: \"data:0\\\\.424\"\n",
            "features: \"data:0\\\\.425\"\n",
            "features: \"data:0\\\\.426\"\n",
            "features: \"data:0\\\\.427\"\n",
            "features: \"data:0\\\\.428\"\n",
            "features: \"data:0\\\\.429\"\n",
            "features: \"data:0\\\\.43\"\n",
            "features: \"data:0\\\\.430\"\n",
            "features: \"data:0\\\\.431\"\n",
            "features: \"data:0\\\\.432\"\n",
            "features: \"data:0\\\\.433\"\n",
            "features: \"data:0\\\\.434\"\n",
            "features: \"data:0\\\\.435\"\n",
            "features: \"data:0\\\\.436\"\n",
            "features: \"data:0\\\\.437\"\n",
            "features: \"data:0\\\\.438\"\n",
            "features: \"data:0\\\\.439\"\n",
            "features: \"data:0\\\\.44\"\n",
            "features: \"data:0\\\\.440\"\n",
            "features: \"data:0\\\\.441\"\n",
            "features: \"data:0\\\\.442\"\n",
            "features: \"data:0\\\\.443\"\n",
            "features: \"data:0\\\\.444\"\n",
            "features: \"data:0\\\\.445\"\n",
            "features: \"data:0\\\\.446\"\n",
            "features: \"data:0\\\\.447\"\n",
            "features: \"data:0\\\\.448\"\n",
            "features: \"data:0\\\\.449\"\n",
            "features: \"data:0\\\\.45\"\n",
            "features: \"data:0\\\\.450\"\n",
            "features: \"data:0\\\\.451\"\n",
            "features: \"data:0\\\\.452\"\n",
            "features: \"data:0\\\\.453\"\n",
            "features: \"data:0\\\\.454\"\n",
            "features: \"data:0\\\\.455\"\n",
            "features: \"data:0\\\\.456\"\n",
            "features: \"data:0\\\\.457\"\n",
            "features: \"data:0\\\\.458\"\n",
            "features: \"data:0\\\\.459\"\n",
            "features: \"data:0\\\\.46\"\n",
            "features: \"data:0\\\\.460\"\n",
            "features: \"data:0\\\\.461\"\n",
            "features: \"data:0\\\\.462\"\n",
            "features: \"data:0\\\\.463\"\n",
            "features: \"data:0\\\\.464\"\n",
            "features: \"data:0\\\\.465\"\n",
            "features: \"data:0\\\\.466\"\n",
            "features: \"data:0\\\\.467\"\n",
            "features: \"data:0\\\\.468\"\n",
            "features: \"data:0\\\\.469\"\n",
            "features: \"data:0\\\\.47\"\n",
            "features: \"data:0\\\\.470\"\n",
            "features: \"data:0\\\\.471\"\n",
            "features: \"data:0\\\\.472\"\n",
            "features: \"data:0\\\\.473\"\n",
            "features: \"data:0\\\\.474\"\n",
            "features: \"data:0\\\\.475\"\n",
            "features: \"data:0\\\\.476\"\n",
            "features: \"data:0\\\\.477\"\n",
            "features: \"data:0\\\\.478\"\n",
            "features: \"data:0\\\\.479\"\n",
            "features: \"data:0\\\\.48\"\n",
            "features: \"data:0\\\\.480\"\n",
            "features: \"data:0\\\\.481\"\n",
            "features: \"data:0\\\\.482\"\n",
            "features: \"data:0\\\\.483\"\n",
            "features: \"data:0\\\\.484\"\n",
            "features: \"data:0\\\\.485\"\n",
            "features: \"data:0\\\\.486\"\n",
            "features: \"data:0\\\\.487\"\n",
            "features: \"data:0\\\\.488\"\n",
            "features: \"data:0\\\\.489\"\n",
            "features: \"data:0\\\\.49\"\n",
            "features: \"data:0\\\\.490\"\n",
            "features: \"data:0\\\\.491\"\n",
            "features: \"data:0\\\\.492\"\n",
            "features: \"data:0\\\\.493\"\n",
            "features: \"data:0\\\\.494\"\n",
            "features: \"data:0\\\\.495\"\n",
            "features: \"data:0\\\\.496\"\n",
            "features: \"data:0\\\\.497\"\n",
            "features: \"data:0\\\\.498\"\n",
            "features: \"data:0\\\\.499\"\n",
            "features: \"data:0\\\\.5\"\n",
            "features: \"data:0\\\\.50\"\n",
            "features: \"data:0\\\\.500\"\n",
            "features: \"data:0\\\\.501\"\n",
            "features: \"data:0\\\\.502\"\n",
            "features: \"data:0\\\\.503\"\n",
            "features: \"data:0\\\\.504\"\n",
            "features: \"data:0\\\\.505\"\n",
            "features: \"data:0\\\\.506\"\n",
            "features: \"data:0\\\\.507\"\n",
            "features: \"data:0\\\\.508\"\n",
            "features: \"data:0\\\\.509\"\n",
            "features: \"data:0\\\\.51\"\n",
            "features: \"data:0\\\\.510\"\n",
            "features: \"data:0\\\\.511\"\n",
            "features: \"data:0\\\\.512\"\n",
            "features: \"data:0\\\\.513\"\n",
            "features: \"data:0\\\\.514\"\n",
            "features: \"data:0\\\\.515\"\n",
            "features: \"data:0\\\\.516\"\n",
            "features: \"data:0\\\\.517\"\n",
            "features: \"data:0\\\\.518\"\n",
            "features: \"data:0\\\\.519\"\n",
            "features: \"data:0\\\\.52\"\n",
            "features: \"data:0\\\\.520\"\n",
            "features: \"data:0\\\\.521\"\n",
            "features: \"data:0\\\\.522\"\n",
            "features: \"data:0\\\\.523\"\n",
            "features: \"data:0\\\\.524\"\n",
            "features: \"data:0\\\\.525\"\n",
            "features: \"data:0\\\\.526\"\n",
            "features: \"data:0\\\\.527\"\n",
            "features: \"data:0\\\\.528\"\n",
            "features: \"data:0\\\\.529\"\n",
            "features: \"data:0\\\\.53\"\n",
            "features: \"data:0\\\\.530\"\n",
            "features: \"data:0\\\\.531\"\n",
            "features: \"data:0\\\\.532\"\n",
            "features: \"data:0\\\\.533\"\n",
            "features: \"data:0\\\\.534\"\n",
            "features: \"data:0\\\\.535\"\n",
            "features: \"data:0\\\\.536\"\n",
            "features: \"data:0\\\\.537\"\n",
            "features: \"data:0\\\\.538\"\n",
            "features: \"data:0\\\\.539\"\n",
            "features: \"data:0\\\\.54\"\n",
            "features: \"data:0\\\\.540\"\n",
            "features: \"data:0\\\\.541\"\n",
            "features: \"data:0\\\\.542\"\n",
            "features: \"data:0\\\\.543\"\n",
            "features: \"data:0\\\\.544\"\n",
            "features: \"data:0\\\\.545\"\n",
            "features: \"data:0\\\\.546\"\n",
            "features: \"data:0\\\\.547\"\n",
            "features: \"data:0\\\\.548\"\n",
            "features: \"data:0\\\\.549\"\n",
            "features: \"data:0\\\\.55\"\n",
            "features: \"data:0\\\\.550\"\n",
            "features: \"data:0\\\\.551\"\n",
            "features: \"data:0\\\\.552\"\n",
            "features: \"data:0\\\\.553\"\n",
            "features: \"data:0\\\\.554\"\n",
            "features: \"data:0\\\\.555\"\n",
            "features: \"data:0\\\\.556\"\n",
            "features: \"data:0\\\\.557\"\n",
            "features: \"data:0\\\\.558\"\n",
            "features: \"data:0\\\\.559\"\n",
            "features: \"data:0\\\\.56\"\n",
            "features: \"data:0\\\\.560\"\n",
            "features: \"data:0\\\\.561\"\n",
            "features: \"data:0\\\\.562\"\n",
            "features: \"data:0\\\\.563\"\n",
            "features: \"data:0\\\\.564\"\n",
            "features: \"data:0\\\\.565\"\n",
            "features: \"data:0\\\\.566\"\n",
            "features: \"data:0\\\\.567\"\n",
            "features: \"data:0\\\\.568\"\n",
            "features: \"data:0\\\\.569\"\n",
            "features: \"data:0\\\\.57\"\n",
            "features: \"data:0\\\\.570\"\n",
            "features: \"data:0\\\\.571\"\n",
            "features: \"data:0\\\\.572\"\n",
            "features: \"data:0\\\\.573\"\n",
            "features: \"data:0\\\\.574\"\n",
            "features: \"data:0\\\\.575\"\n",
            "features: \"data:0\\\\.576\"\n",
            "features: \"data:0\\\\.577\"\n",
            "features: \"data:0\\\\.578\"\n",
            "features: \"data:0\\\\.579\"\n",
            "features: \"data:0\\\\.58\"\n",
            "features: \"data:0\\\\.580\"\n",
            "features: \"data:0\\\\.581\"\n",
            "features: \"data:0\\\\.582\"\n",
            "features: \"data:0\\\\.583\"\n",
            "features: \"data:0\\\\.584\"\n",
            "features: \"data:0\\\\.585\"\n",
            "features: \"data:0\\\\.586\"\n",
            "features: \"data:0\\\\.587\"\n",
            "features: \"data:0\\\\.588\"\n",
            "features: \"data:0\\\\.589\"\n",
            "features: \"data:0\\\\.59\"\n",
            "features: \"data:0\\\\.590\"\n",
            "features: \"data:0\\\\.591\"\n",
            "features: \"data:0\\\\.592\"\n",
            "features: \"data:0\\\\.593\"\n",
            "features: \"data:0\\\\.594\"\n",
            "features: \"data:0\\\\.595\"\n",
            "features: \"data:0\\\\.596\"\n",
            "features: \"data:0\\\\.597\"\n",
            "features: \"data:0\\\\.598\"\n",
            "features: \"data:0\\\\.599\"\n",
            "features: \"data:0\\\\.6\"\n",
            "features: \"data:0\\\\.60\"\n",
            "features: \"data:0\\\\.600\"\n",
            "features: \"data:0\\\\.601\"\n",
            "features: \"data:0\\\\.602\"\n",
            "features: \"data:0\\\\.603\"\n",
            "features: \"data:0\\\\.604\"\n",
            "features: \"data:0\\\\.605\"\n",
            "features: \"data:0\\\\.606\"\n",
            "features: \"data:0\\\\.607\"\n",
            "features: \"data:0\\\\.608\"\n",
            "features: \"data:0\\\\.609\"\n",
            "features: \"data:0\\\\.61\"\n",
            "features: \"data:0\\\\.610\"\n",
            "features: \"data:0\\\\.611\"\n",
            "features: \"data:0\\\\.612\"\n",
            "features: \"data:0\\\\.613\"\n",
            "features: \"data:0\\\\.614\"\n",
            "features: \"data:0\\\\.615\"\n",
            "features: \"data:0\\\\.616\"\n",
            "features: \"data:0\\\\.617\"\n",
            "features: \"data:0\\\\.618\"\n",
            "features: \"data:0\\\\.619\"\n",
            "features: \"data:0\\\\.62\"\n",
            "features: \"data:0\\\\.620\"\n",
            "features: \"data:0\\\\.621\"\n",
            "features: \"data:0\\\\.622\"\n",
            "features: \"data:0\\\\.623\"\n",
            "features: \"data:0\\\\.624\"\n",
            "features: \"data:0\\\\.625\"\n",
            "features: \"data:0\\\\.626\"\n",
            "features: \"data:0\\\\.627\"\n",
            "features: \"data:0\\\\.628\"\n",
            "features: \"data:0\\\\.629\"\n",
            "features: \"data:0\\\\.63\"\n",
            "features: \"data:0\\\\.630\"\n",
            "features: \"data:0\\\\.631\"\n",
            "features: \"data:0\\\\.632\"\n",
            "features: \"data:0\\\\.633\"\n",
            "features: \"data:0\\\\.634\"\n",
            "features: \"data:0\\\\.635\"\n",
            "features: \"data:0\\\\.636\"\n",
            "features: \"data:0\\\\.637\"\n",
            "features: \"data:0\\\\.638\"\n",
            "features: \"data:0\\\\.639\"\n",
            "features: \"data:0\\\\.64\"\n",
            "features: \"data:0\\\\.640\"\n",
            "features: \"data:0\\\\.641\"\n",
            "features: \"data:0\\\\.642\"\n",
            "features: \"data:0\\\\.643\"\n",
            "features: \"data:0\\\\.644\"\n",
            "features: \"data:0\\\\.645\"\n",
            "features: \"data:0\\\\.646\"\n",
            "features: \"data:0\\\\.647\"\n",
            "features: \"data:0\\\\.648\"\n",
            "features: \"data:0\\\\.649\"\n",
            "features: \"data:0\\\\.65\"\n",
            "features: \"data:0\\\\.650\"\n",
            "features: \"data:0\\\\.651\"\n",
            "features: \"data:0\\\\.652\"\n",
            "features: \"data:0\\\\.653\"\n",
            "features: \"data:0\\\\.654\"\n",
            "features: \"data:0\\\\.655\"\n",
            "features: \"data:0\\\\.656\"\n",
            "features: \"data:0\\\\.657\"\n",
            "features: \"data:0\\\\.658\"\n",
            "features: \"data:0\\\\.659\"\n",
            "features: \"data:0\\\\.66\"\n",
            "features: \"data:0\\\\.660\"\n",
            "features: \"data:0\\\\.661\"\n",
            "features: \"data:0\\\\.662\"\n",
            "features: \"data:0\\\\.663\"\n",
            "features: \"data:0\\\\.664\"\n",
            "features: \"data:0\\\\.665\"\n",
            "features: \"data:0\\\\.666\"\n",
            "features: \"data:0\\\\.667\"\n",
            "features: \"data:0\\\\.668\"\n",
            "features: \"data:0\\\\.669\"\n",
            "features: \"data:0\\\\.67\"\n",
            "features: \"data:0\\\\.670\"\n",
            "features: \"data:0\\\\.671\"\n",
            "features: \"data:0\\\\.672\"\n",
            "features: \"data:0\\\\.673\"\n",
            "features: \"data:0\\\\.674\"\n",
            "features: \"data:0\\\\.675\"\n",
            "features: \"data:0\\\\.676\"\n",
            "features: \"data:0\\\\.677\"\n",
            "features: \"data:0\\\\.678\"\n",
            "features: \"data:0\\\\.679\"\n",
            "features: \"data:0\\\\.68\"\n",
            "features: \"data:0\\\\.680\"\n",
            "features: \"data:0\\\\.681\"\n",
            "features: \"data:0\\\\.682\"\n",
            "features: \"data:0\\\\.683\"\n",
            "features: \"data:0\\\\.684\"\n",
            "features: \"data:0\\\\.685\"\n",
            "features: \"data:0\\\\.686\"\n",
            "features: \"data:0\\\\.687\"\n",
            "features: \"data:0\\\\.688\"\n",
            "features: \"data:0\\\\.689\"\n",
            "features: \"data:0\\\\.69\"\n",
            "features: \"data:0\\\\.690\"\n",
            "features: \"data:0\\\\.691\"\n",
            "features: \"data:0\\\\.692\"\n",
            "features: \"data:0\\\\.693\"\n",
            "features: \"data:0\\\\.694\"\n",
            "features: \"data:0\\\\.695\"\n",
            "features: \"data:0\\\\.696\"\n",
            "features: \"data:0\\\\.697\"\n",
            "features: \"data:0\\\\.698\"\n",
            "features: \"data:0\\\\.699\"\n",
            "features: \"data:0\\\\.7\"\n",
            "features: \"data:0\\\\.70\"\n",
            "features: \"data:0\\\\.700\"\n",
            "features: \"data:0\\\\.701\"\n",
            "features: \"data:0\\\\.702\"\n",
            "features: \"data:0\\\\.703\"\n",
            "features: \"data:0\\\\.704\"\n",
            "features: \"data:0\\\\.705\"\n",
            "features: \"data:0\\\\.706\"\n",
            "features: \"data:0\\\\.707\"\n",
            "features: \"data:0\\\\.708\"\n",
            "features: \"data:0\\\\.709\"\n",
            "features: \"data:0\\\\.71\"\n",
            "features: \"data:0\\\\.710\"\n",
            "features: \"data:0\\\\.711\"\n",
            "features: \"data:0\\\\.712\"\n",
            "features: \"data:0\\\\.713\"\n",
            "features: \"data:0\\\\.714\"\n",
            "features: \"data:0\\\\.715\"\n",
            "features: \"data:0\\\\.716\"\n",
            "features: \"data:0\\\\.717\"\n",
            "features: \"data:0\\\\.718\"\n",
            "features: \"data:0\\\\.719\"\n",
            "features: \"data:0\\\\.72\"\n",
            "features: \"data:0\\\\.720\"\n",
            "features: \"data:0\\\\.721\"\n",
            "features: \"data:0\\\\.722\"\n",
            "features: \"data:0\\\\.723\"\n",
            "features: \"data:0\\\\.724\"\n",
            "features: \"data:0\\\\.725\"\n",
            "features: \"data:0\\\\.726\"\n",
            "features: \"data:0\\\\.727\"\n",
            "features: \"data:0\\\\.728\"\n",
            "features: \"data:0\\\\.729\"\n",
            "features: \"data:0\\\\.73\"\n",
            "features: \"data:0\\\\.730\"\n",
            "features: \"data:0\\\\.731\"\n",
            "features: \"data:0\\\\.732\"\n",
            "features: \"data:0\\\\.733\"\n",
            "features: \"data:0\\\\.734\"\n",
            "features: \"data:0\\\\.735\"\n",
            "features: \"data:0\\\\.736\"\n",
            "features: \"data:0\\\\.737\"\n",
            "features: \"data:0\\\\.738\"\n",
            "features: \"data:0\\\\.739\"\n",
            "features: \"data:0\\\\.74\"\n",
            "features: \"data:0\\\\.740\"\n",
            "features: \"data:0\\\\.741\"\n",
            "features: \"data:0\\\\.742\"\n",
            "features: \"data:0\\\\.743\"\n",
            "features: \"data:0\\\\.744\"\n",
            "features: \"data:0\\\\.745\"\n",
            "features: \"data:0\\\\.746\"\n",
            "features: \"data:0\\\\.747\"\n",
            "features: \"data:0\\\\.748\"\n",
            "features: \"data:0\\\\.749\"\n",
            "features: \"data:0\\\\.75\"\n",
            "features: \"data:0\\\\.750\"\n",
            "features: \"data:0\\\\.751\"\n",
            "features: \"data:0\\\\.752\"\n",
            "features: \"data:0\\\\.753\"\n",
            "features: \"data:0\\\\.754\"\n",
            "features: \"data:0\\\\.755\"\n",
            "features: \"data:0\\\\.756\"\n",
            "features: \"data:0\\\\.757\"\n",
            "features: \"data:0\\\\.758\"\n",
            "features: \"data:0\\\\.759\"\n",
            "features: \"data:0\\\\.76\"\n",
            "features: \"data:0\\\\.760\"\n",
            "features: \"data:0\\\\.761\"\n",
            "features: \"data:0\\\\.762\"\n",
            "features: \"data:0\\\\.763\"\n",
            "features: \"data:0\\\\.764\"\n",
            "features: \"data:0\\\\.765\"\n",
            "features: \"data:0\\\\.766\"\n",
            "features: \"data:0\\\\.767\"\n",
            "features: \"data:0\\\\.768\"\n",
            "features: \"data:0\\\\.769\"\n",
            "features: \"data:0\\\\.77\"\n",
            "features: \"data:0\\\\.770\"\n",
            "features: \"data:0\\\\.771\"\n",
            "features: \"data:0\\\\.772\"\n",
            "features: \"data:0\\\\.773\"\n",
            "features: \"data:0\\\\.774\"\n",
            "features: \"data:0\\\\.775\"\n",
            "features: \"data:0\\\\.776\"\n",
            "features: \"data:0\\\\.777\"\n",
            "features: \"data:0\\\\.778\"\n",
            "features: \"data:0\\\\.779\"\n",
            "features: \"data:0\\\\.78\"\n",
            "features: \"data:0\\\\.780\"\n",
            "features: \"data:0\\\\.781\"\n",
            "features: \"data:0\\\\.782\"\n",
            "features: \"data:0\\\\.783\"\n",
            "features: \"data:0\\\\.79\"\n",
            "features: \"data:0\\\\.8\"\n",
            "features: \"data:0\\\\.80\"\n",
            "features: \"data:0\\\\.81\"\n",
            "features: \"data:0\\\\.82\"\n",
            "features: \"data:0\\\\.83\"\n",
            "features: \"data:0\\\\.84\"\n",
            "features: \"data:0\\\\.85\"\n",
            "features: \"data:0\\\\.86\"\n",
            "features: \"data:0\\\\.87\"\n",
            "features: \"data:0\\\\.88\"\n",
            "features: \"data:0\\\\.89\"\n",
            "features: \"data:0\\\\.9\"\n",
            "features: \"data:0\\\\.90\"\n",
            "features: \"data:0\\\\.91\"\n",
            "features: \"data:0\\\\.92\"\n",
            "features: \"data:0\\\\.93\"\n",
            "features: \"data:0\\\\.94\"\n",
            "features: \"data:0\\\\.95\"\n",
            "features: \"data:0\\\\.96\"\n",
            "features: \"data:0\\\\.97\"\n",
            "features: \"data:0\\\\.98\"\n",
            "features: \"data:0\\\\.99\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "random_seed: 123456\n",
            "metadata {\n",
            "  framework: \"TF Keras\"\n",
            "}\n",
            "pure_serving_model: false\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 300\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    keep_non_leaf_label_distribution: true\n",
            "    num_candidate_attributes: 0\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "    uplift {\n",
            "      min_examples_in_treatment: 5\n",
            "      split_score: KULLBACK_LEIBLER\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  num_oob_variable_importances_permutations: 1\n",
            "  bootstrap_training_dataset: true\n",
            "  bootstrap_size_ratio: 1\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "  sampling_with_replacement: true\n",
            "}\n",
            "\n",
            "[INFO 2023-01-06T04:56:06.721544474+00:00 kernel.cc:916] Deployment config:\n",
            "cache_path: \"/tmp/tmp6on3prrr/working_cache\"\n",
            "num_threads: 2\n",
            "try_resume_training: true\n",
            "\n",
            "[INFO 2023-01-06T04:56:06.721569686+00:00 kernel.cc:945] Train model\n",
            "[INFO 2023-01-06T04:56:06.802782773+00:00 random_forest.cc:407] Training random forest on 33600 example(s) and 784 feature(s).\n",
            "[INFO 2023-01-06T04:56:09.640518539+00:00 random_forest.cc:796] Training of tree  1/300 (tree index:0) done accuracy:0.809814 logloss:6.85498\n",
            "[INFO 2023-01-06T04:56:17.517458666+00:00 random_forest.cc:796] Training of tree  11/300 (tree index:10) done accuracy:0.88503 logloss:1.6069\n",
            "[INFO 2023-01-06T04:56:25.426601217+00:00 random_forest.cc:796] Training of tree  21/300 (tree index:20) done accuracy:0.928718 logloss:0.689242\n",
            "[INFO 2023-01-06T04:56:33.18664955+00:00 random_forest.cc:796] Training of tree  31/300 (tree index:30) done accuracy:0.941131 logloss:0.491958\n",
            "[INFO 2023-01-06T04:56:40.951272035+00:00 random_forest.cc:796] Training of tree  41/300 (tree index:40) done accuracy:0.946845 logloss:0.399013\n",
            "[INFO 2023-01-06T04:56:48.861607084+00:00 random_forest.cc:796] Training of tree  51/300 (tree index:50) done accuracy:0.950119 logloss:0.352789\n",
            "[INFO 2023-01-06T04:56:56.67070564+00:00 random_forest.cc:796] Training of tree  61/300 (tree index:60) done accuracy:0.952708 logloss:0.32227\n",
            "[INFO 2023-01-06T04:57:04.462508994+00:00 random_forest.cc:796] Training of tree  71/300 (tree index:70) done accuracy:0.954256 logloss:0.306768\n",
            "[INFO 2023-01-06T04:57:12.234162239+00:00 random_forest.cc:796] Training of tree  81/300 (tree index:80) done accuracy:0.955238 logloss:0.294959\n",
            "[INFO 2023-01-06T04:57:20.301830383+00:00 random_forest.cc:796] Training of tree  91/300 (tree index:90) done accuracy:0.956071 logloss:0.288664\n",
            "[INFO 2023-01-06T04:57:28.118871091+00:00 random_forest.cc:796] Training of tree  101/300 (tree index:100) done accuracy:0.956875 logloss:0.281815\n",
            "[INFO 2023-01-06T04:57:37.807378724+00:00 random_forest.cc:796] Training of tree  111/300 (tree index:110) done accuracy:0.956786 logloss:0.280216\n",
            "[INFO 2023-01-06T04:57:45.624472668+00:00 random_forest.cc:796] Training of tree  121/300 (tree index:120) done accuracy:0.957649 logloss:0.27792\n",
            "[INFO 2023-01-06T04:57:53.350759131+00:00 random_forest.cc:796] Training of tree  131/300 (tree index:130) done accuracy:0.958601 logloss:0.275804\n",
            "[INFO 2023-01-06T04:58:01.208988823+00:00 random_forest.cc:796] Training of tree  141/300 (tree index:140) done accuracy:0.95869 logloss:0.27376\n",
            "[INFO 2023-01-06T04:58:09.012728198+00:00 random_forest.cc:796] Training of tree  151/300 (tree index:150) done accuracy:0.958899 logloss:0.273123\n",
            "[INFO 2023-01-06T04:58:16.848850714+00:00 random_forest.cc:796] Training of tree  161/300 (tree index:160) done accuracy:0.958869 logloss:0.272116\n",
            "[INFO 2023-01-06T04:58:24.545061432+00:00 random_forest.cc:796] Training of tree  171/300 (tree index:170) done accuracy:0.959732 logloss:0.272\n",
            "[INFO 2023-01-06T04:58:32.266615038+00:00 random_forest.cc:796] Training of tree  181/300 (tree index:180) done accuracy:0.95997 logloss:0.271058\n",
            "[INFO 2023-01-06T04:58:40.108650202+00:00 random_forest.cc:796] Training of tree  191/300 (tree index:190) done accuracy:0.960327 logloss:0.268613\n",
            "[INFO 2023-01-06T04:58:47.843592149+00:00 random_forest.cc:796] Training of tree  201/300 (tree index:200) done accuracy:0.960268 logloss:0.267406\n",
            "[INFO 2023-01-06T04:58:55.720012888+00:00 random_forest.cc:796] Training of tree  211/300 (tree index:210) done accuracy:0.960089 logloss:0.267407\n",
            "[INFO 2023-01-06T04:59:04.039568349+00:00 random_forest.cc:796] Training of tree  221/300 (tree index:221) done accuracy:0.960476 logloss:0.266389\n",
            "[INFO 2023-01-06T04:59:11.722601728+00:00 random_forest.cc:796] Training of tree  231/300 (tree index:230) done accuracy:0.960744 logloss:0.266477\n",
            "[INFO 2023-01-06T04:59:22.291255034+00:00 random_forest.cc:796] Training of tree  241/300 (tree index:240) done accuracy:0.960655 logloss:0.266266\n",
            "[INFO 2023-01-06T04:59:32.842369641+00:00 random_forest.cc:796] Training of tree  251/300 (tree index:250) done accuracy:0.960565 logloss:0.265176\n",
            "[INFO 2023-01-06T04:59:40.514387522+00:00 random_forest.cc:796] Training of tree  261/300 (tree index:260) done accuracy:0.960208 logloss:0.264966\n",
            "[INFO 2023-01-06T04:59:48.382762818+00:00 random_forest.cc:796] Training of tree  271/300 (tree index:270) done accuracy:0.960446 logloss:0.265098\n",
            "[INFO 2023-01-06T04:59:56.140793629+00:00 random_forest.cc:796] Training of tree  281/300 (tree index:280) done accuracy:0.960744 logloss:0.263966\n",
            "[INFO 2023-01-06T05:00:03.99397304+00:00 random_forest.cc:796] Training of tree  291/300 (tree index:290) done accuracy:0.960923 logloss:0.263841\n",
            "[INFO 2023-01-06T05:00:10.415090222+00:00 random_forest.cc:796] Training of tree  300/300 (tree index:299) done accuracy:0.960982 logloss:0.26379\n",
            "[INFO 2023-01-06T05:00:10.415628647+00:00 random_forest.cc:876] Final OOB metrics: accuracy:0.960982 logloss:0.26379\n",
            "[INFO 2023-01-06T05:00:13.829563607+00:00 kernel.cc:962] Export model in log directory: /tmp/tmp6on3prrr with prefix bd5c44df8e4d4cec\n",
            "[INFO 2023-01-06T05:00:14.720266327+00:00 kernel.cc:979] Save model in resources\n",
            "[INFO 2023-01-06T05:00:14.774830909+00:00 abstract_model.cc:844] Model self evaluation:\n",
            "Number of predictions (without weights): 33600\n",
            "Number of predictions (with weights): 33600\n",
            "Task: CLASSIFICATION\n",
            "Label: __LABEL\n",
            "\n",
            "Accuracy: 0.960982  CI95[W][0.9592 0.962705]\n",
            "LogLoss: : 0.26379\n",
            "ErrorRate: : 0.0390179\n",
            "\n",
            "Default Accuracy: : 0.112351\n",
            "Default LogLoss: : 2.30126\n",
            "Default ErrorRate: : 0.887649\n",
            "\n",
            "Confusion Table:\n",
            "truth\\prediction\n",
            "    0     1     2     3     4     5     6     7     8     9    10\n",
            " 0  0     0     0     0     0     0     0     0     0     0     0\n",
            " 1  0  3268     0     5     1     3     2    11     1    23     2\n",
            " 2  0     0  3714    12    18     7     4     4     8     6     2\n",
            " 3  0    15     6  3202    17    14     2    18    35    15     7\n",
            " 4  0     8     3    64  3201     1    58    11    21    33    14\n",
            " 5  0     6     6     6     0  3117     2    14     4    11    67\n",
            " 6  0    15     7     5    39     9  2966    17     2    20    13\n",
            " 7  0    20     5     4     0    11    26  3276     0    10     0\n",
            " 8  0     3    15    49     6    22     1     0  3372     6    34\n",
            " 9  0     9    16    20    26    16    28    19     2  3044    48\n",
            "10  0    21     7    10    41    60    13     3    38    28  3129\n",
            "Total: 33600\n",
            "\n",
            "One vs other classes:\n",
            "\n",
            "[INFO 2023-01-06T05:00:15.152882717+00:00 kernel.cc:1175] Loading model from path /tmp/tmp6on3prrr/model/ with prefix bd5c44df8e4d4cec\n",
            "[INFO 2023-01-06T05:00:18.676864104+00:00 decision_forest.cc:640] Model loaded with 300 root(s), 904664 node(s), and 551 input feature(s).\n",
            "[INFO 2023-01-06T05:00:18.676931366+00:00 abstract_model.cc:1306] Engine \"RandomForestGeneric\" built\n",
            "[INFO 2023-01-06T05:00:18.677464757+00:00 kernel.cc:1021] Use fast generic engine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained in 0:04:12.560275\n",
            "Compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f08d72b0af0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f08d72b0af0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f08d715dc10>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I don't know how to fix the evaluation errors in this function. I'll take the output accuracy above at its word, ~96%"
      ],
      "metadata": {
        "id": "YcJOSrJSUpC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results = [0.26379, 0.960982]"
      ],
      "metadata": {
        "id": "QUF1vry3VDX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluate model results\n",
        "results = {\"model_1_baseline\": model_0_results,\n",
        "           \"model_2_dense_lite\": model_1_results,\n",
        "           \"model_3_dense_large\": model_2_results,\n",
        "           \"model_4_cnn_lite\": model_3_results,\n",
        "           \"model_5_cnn_large\": model_4_results,\n",
        "           \"model_6_lstm\": model_5_results,\n",
        "           \"model_7_random_forest\": model_6_results}\n",
        "\n",
        "results_df = pd.DataFrame(results).transpose()\n",
        "acc_df = results_df[1]\n",
        "acc_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXK4eGP9f0cu",
        "outputId": "9c9723cb-cbaf-480c-9dfd-ed5f541f2622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_1_baseline         0.973452\n",
              "model_2_dense_lite       0.930821\n",
              "model_3_dense_large      0.941794\n",
              "model_4_cnn_lite         0.951813\n",
              "model_5_cnn_large        0.981990\n",
              "model_6_lstm             0.354246\n",
              "model_7_random_forest    0.960982\n",
              "Name: 1, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_df.sort_values(ascending=False).plot(kind=\"bar\", title=\"Model Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "_YVHIwZ1gX1L",
        "outputId": "eadbc3f7-7748-48f4-9032-49a6a800ef7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f08d7b33a30>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So model 5 is our most accurate model, the only one to beat the baseline. Lets try and fine tune it."
      ],
      "metadata": {
        "id": "hRetTPV6hyUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tuning\n"
      ],
      "metadata": {
        "id": "Kmt7YED6ii8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 8 - Reduce Dropout"
      ],
      "metadata": {
        "id": "3A6hfuv_jJBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce dropout percentages\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_7 = tf.keras.Sequential([\n",
        "  layers.Rescaling(scale=1/255.),\n",
        "  layers.Conv1D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool1D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Conv1D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool1D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(256, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_7.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\n",
        "                        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6bSzSS2ir8D",
        "outputId": "abe28d66-e28c-424c-98c3-e3957b7e2250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 7s 5ms/step - loss: 0.3158 - accuracy: 0.9045 - val_loss: 0.1357 - val_accuracy: 0.9579 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.1346 - accuracy: 0.9577 - val_loss: 0.1057 - val_accuracy: 0.9674 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.1019 - accuracy: 0.9681 - val_loss: 0.0943 - val_accuracy: 0.9690 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0778 - accuracy: 0.9754 - val_loss: 0.0970 - val_accuracy: 0.9689 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0649 - accuracy: 0.9786 - val_loss: 0.0994 - val_accuracy: 0.9674 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0528 - accuracy: 0.9831 - val_loss: 0.0896 - val_accuracy: 0.9708 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0453 - accuracy: 0.9854 - val_loss: 0.0716 - val_accuracy: 0.9782 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0403 - accuracy: 0.9866 - val_loss: 0.0694 - val_accuracy: 0.9785 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0363 - accuracy: 0.9882 - val_loss: 0.0725 - val_accuracy: 0.9779 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0314 - accuracy: 0.9891 - val_loss: 0.0908 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0290 - accuracy: 0.9901 - val_loss: 0.0697 - val_accuracy: 0.9806 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0251 - accuracy: 0.9909 - val_loss: 0.0720 - val_accuracy: 0.9784 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0689 - val_accuracy: 0.9802 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 0.0743 - val_accuracy: 0.9792 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.0750 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0192 - accuracy: 0.9930 - val_loss: 0.0776 - val_accuracy: 0.9813 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 0.0866 - val_accuracy: 0.9781 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "1046/1050 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9941\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0165 - accuracy: 0.9941 - val_loss: 0.0753 - val_accuracy: 0.9804 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0643 - val_accuracy: 0.9832 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.0641 - val_accuracy: 0.9835 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0628 - val_accuracy: 0.9835 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0619 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.0634 - val_accuracy: 0.9843 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0636 - val_accuracy: 0.9854 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0647 - val_accuracy: 0.9852 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0653 - val_accuracy: 0.9840 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "1046/1050 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9980\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0651 - val_accuracy: 0.9845 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0649 - val_accuracy: 0.9843 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0646 - val_accuracy: 0.9844 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0649 - val_accuracy: 0.9846 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0652 - val_accuracy: 0.9846 - lr: 1.0000e-05\n",
            "Epoch 32/100\n",
            "1040/1050 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0656 - val_accuracy: 0.9845 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f08d91ab1c0>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7_results = model_7.evaluate(val_ds)\n",
        "model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV_Ekz4Bi1Gg",
        "outputId": "1322a8a7-e744-4f70-cd0b-1a760a4ee7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 3ms/step - loss: 0.0619 - accuracy: 0.9844\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.061893973499536514, 0.984375]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 9 - Increase Convolution Units"
      ],
      "metadata": {
        "id": "ogzjkB0gjH-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce dropout percentages\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_8 = tf.keras.Sequential([\n",
        "  layers.Rescaling(scale=1/255.),\n",
        "  layers.Conv1D(32, 3, activation=\"relu\"),\n",
        "  layers.MaxPool1D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Conv1D(16, 3, activation=\"relu\"),\n",
        "  layers.MaxPool1D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(256, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_8.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_8.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\n",
        "                        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7gFfvoijSji",
        "outputId": "97e8287c-87a9-4773-f8d4-6551b24ac71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 8s 6ms/step - loss: 0.2795 - accuracy: 0.9133 - val_loss: 0.1384 - val_accuracy: 0.9583 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.1191 - accuracy: 0.9633 - val_loss: 0.1054 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0872 - accuracy: 0.9721 - val_loss: 0.0908 - val_accuracy: 0.9709 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0703 - accuracy: 0.9770 - val_loss: 0.0851 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 12s 11ms/step - loss: 0.0549 - accuracy: 0.9820 - val_loss: 0.0716 - val_accuracy: 0.9770 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 9s 9ms/step - loss: 0.0472 - accuracy: 0.9847 - val_loss: 0.0825 - val_accuracy: 0.9747 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0379 - accuracy: 0.9867 - val_loss: 0.0709 - val_accuracy: 0.9783 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.0884 - val_accuracy: 0.9757 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0323 - accuracy: 0.9888 - val_loss: 0.0701 - val_accuracy: 0.9782 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0279 - accuracy: 0.9904 - val_loss: 0.0663 - val_accuracy: 0.9800 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 0.0676 - val_accuracy: 0.9807 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.0724 - val_accuracy: 0.9792 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.0746 - val_accuracy: 0.9792 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0194 - accuracy: 0.9934 - val_loss: 0.0765 - val_accuracy: 0.9807 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1049/1050 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9939\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.0856 - val_accuracy: 0.9809 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.0652 - val_accuracy: 0.9837 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0639 - val_accuracy: 0.9841 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0643 - val_accuracy: 0.9841 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0648 - val_accuracy: 0.9840 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0653 - val_accuracy: 0.9840 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0677 - val_accuracy: 0.9841 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "1043/1050 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9986\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1050/1050 [==============================] - 7s 6ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.0704 - val_accuracy: 0.9843 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0699 - val_accuracy: 0.9840 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0700 - val_accuracy: 0.9841 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0699 - val_accuracy: 0.9841 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0693 - val_accuracy: 0.9840 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "1050/1050 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "1050/1050 [==============================] - 7s 6ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0689 - val_accuracy: 0.9843 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f08d74281f0>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_8_results = model_8.evaluate(val_ds)\n",
        "model_8_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTBheLHqjXlb",
        "outputId": "2b40f6fc-8cec-4b8d-b4b2-a105b3ca8b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 2s 6ms/step - loss: 0.0639 - accuracy: 0.9841\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06385187804698944, 0.9841364622116089]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 10 - Change Dense Layers Before Output\n",
        "\n"
      ],
      "metadata": {
        "id": "VpQ9nqiZjlY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce dropout percentages\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_9 = tf.keras.Sequential([\n",
        "  layers.Rescaling(scale=1/255.),\n",
        "  layers.Conv1D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool1D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Conv1D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool1D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_9.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_9.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\n",
        "                        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1)])"
      ],
      "metadata": {
        "id": "Zvurj6gwmygF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_9_results = model_9.evaluate(val_ds)\n",
        "model_9_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG9UxuY4kCP3",
        "outputId": "c060d194-4906-40cd-863a-9c96f3800d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.9816\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05950496718287468, 0.9816316962242126]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 11 - Add another Conv layer block\n"
      ],
      "metadata": {
        "id": "LGgzWo6HkFbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_10 = tf.keras.Sequential([\n",
        "  layers.Rescaling(scale=1/255.),\n",
        "  layers.Conv1D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool1D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Conv1D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool1D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Conv1D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool1D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(256, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_10.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_10.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZQ1EjwHkmoG",
        "outputId": "c0fd69d7-a2b9-4e70-f982-e07ac62aed50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 8s 6ms/step - loss: 0.4495 - accuracy: 0.8567 - val_loss: 0.1805 - val_accuracy: 0.9445 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.2168 - accuracy: 0.9292 - val_loss: 0.1279 - val_accuracy: 0.9608 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 7s 6ms/step - loss: 0.1624 - accuracy: 0.9487 - val_loss: 0.1220 - val_accuracy: 0.9583 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.1442 - accuracy: 0.9536 - val_loss: 0.1008 - val_accuracy: 0.9665 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1252 - accuracy: 0.9598 - val_loss: 0.0870 - val_accuracy: 0.9703 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.1121 - accuracy: 0.9633 - val_loss: 0.0849 - val_accuracy: 0.9707 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 8s 8ms/step - loss: 0.1043 - accuracy: 0.9662 - val_loss: 0.0811 - val_accuracy: 0.9730 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0964 - accuracy: 0.9680 - val_loss: 0.0714 - val_accuracy: 0.9770 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0867 - accuracy: 0.9715 - val_loss: 0.0860 - val_accuracy: 0.9732 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0857 - accuracy: 0.9721 - val_loss: 0.0706 - val_accuracy: 0.9772 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0807 - accuracy: 0.9737 - val_loss: 0.0636 - val_accuracy: 0.9790 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0770 - accuracy: 0.9749 - val_loss: 0.0630 - val_accuracy: 0.9803 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0710 - accuracy: 0.9772 - val_loss: 0.0619 - val_accuracy: 0.9798 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0687 - accuracy: 0.9772 - val_loss: 0.0604 - val_accuracy: 0.9813 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0659 - accuracy: 0.9781 - val_loss: 0.0565 - val_accuracy: 0.9825 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0657 - accuracy: 0.9781 - val_loss: 0.0561 - val_accuracy: 0.9832 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.0614 - accuracy: 0.9801 - val_loss: 0.0579 - val_accuracy: 0.9813 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0559 - accuracy: 0.9801 - val_loss: 0.0687 - val_accuracy: 0.9784 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0544 - accuracy: 0.9815 - val_loss: 0.0569 - val_accuracy: 0.9822 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0565 - accuracy: 0.9802 - val_loss: 0.0586 - val_accuracy: 0.9815 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "1044/1050 [============================>.] - ETA: 0s - loss: 0.0546 - accuracy: 0.9817\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0546 - accuracy: 0.9817 - val_loss: 0.0583 - val_accuracy: 0.9818 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0416 - accuracy: 0.9859 - val_loss: 0.0511 - val_accuracy: 0.9849 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0364 - accuracy: 0.9874 - val_loss: 0.0493 - val_accuracy: 0.9852 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0358 - accuracy: 0.9876 - val_loss: 0.0486 - val_accuracy: 0.9847 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "1050/1050 [==============================] - 7s 6ms/step - loss: 0.0345 - accuracy: 0.9886 - val_loss: 0.0476 - val_accuracy: 0.9856 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "1050/1050 [==============================] - 7s 6ms/step - loss: 0.0347 - accuracy: 0.9880 - val_loss: 0.0453 - val_accuracy: 0.9858 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "1050/1050 [==============================] - 8s 7ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.0458 - val_accuracy: 0.9859 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0310 - accuracy: 0.9892 - val_loss: 0.0484 - val_accuracy: 0.9854 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0324 - accuracy: 0.9892 - val_loss: 0.0467 - val_accuracy: 0.9856 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0320 - accuracy: 0.9897 - val_loss: 0.0470 - val_accuracy: 0.9854 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "1045/1050 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9891\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0324 - accuracy: 0.9891 - val_loss: 0.0461 - val_accuracy: 0.9860 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0282 - accuracy: 0.9901 - val_loss: 0.0457 - val_accuracy: 0.9860 - lr: 1.0000e-05\n",
            "Epoch 33/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0290 - accuracy: 0.9901 - val_loss: 0.0456 - val_accuracy: 0.9856 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f08d95dcfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_10_results = model_10.evaluate(val_ds)\n",
        "model_10_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPzDD2KykfQu",
        "outputId": "1c3d47cf-52af-48eb-dec6-f3a942c83542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 3ms/step - loss: 0.0453 - accuracy: 0.9858\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.045344505459070206, 0.9858062863349915]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 12 - Model 5 with LR callback\n"
      ],
      "metadata": {
        "id": "LT86M5Apk3h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_11 = tf.keras.Sequential([\n",
        "  layers.Rescaling(scale=1/255.),\n",
        "  layers.Conv1D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool1D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Conv1D(10, 3, activation=\"relu\"),\n",
        "  layers.MaxPool1D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(256, activation=\"relu\"),\n",
        "  layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_11.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_11.fit(train_ds,\n",
        "            # batch_size=32,\n",
        "            # steps_per_epoch = int(len(train_ds)//32),\n",
        "            epochs=100,\n",
        "            validation_data=val_ds,\n",
        "            # validation_steps = int(len(val_ds)//32),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True),\n",
        "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5, verbose=1)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9mAzIzamA3q",
        "outputId": "4dd29db9-033b-485a-950c-8d99c27939aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1050/1050 [==============================] - 7s 5ms/step - loss: 0.3376 - accuracy: 0.8936 - val_loss: 0.1480 - val_accuracy: 0.9529 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.1578 - accuracy: 0.9499 - val_loss: 0.1111 - val_accuracy: 0.9642 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.1196 - accuracy: 0.9624 - val_loss: 0.1050 - val_accuracy: 0.9655 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0973 - accuracy: 0.9701 - val_loss: 0.0888 - val_accuracy: 0.9703 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0821 - accuracy: 0.9740 - val_loss: 0.0826 - val_accuracy: 0.9727 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0696 - accuracy: 0.9775 - val_loss: 0.0828 - val_accuracy: 0.9727 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0645 - accuracy: 0.9775 - val_loss: 0.0738 - val_accuracy: 0.9769 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0554 - accuracy: 0.9815 - val_loss: 0.0676 - val_accuracy: 0.9783 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0544 - accuracy: 0.9815 - val_loss: 0.0638 - val_accuracy: 0.9772 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0439 - accuracy: 0.9852 - val_loss: 0.0697 - val_accuracy: 0.9773 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0431 - accuracy: 0.9847 - val_loss: 0.0671 - val_accuracy: 0.9786 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0406 - accuracy: 0.9868 - val_loss: 0.0612 - val_accuracy: 0.9800 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0374 - accuracy: 0.9873 - val_loss: 0.0647 - val_accuracy: 0.9794 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 0.0639 - val_accuracy: 0.9819 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0307 - accuracy: 0.9893 - val_loss: 0.0692 - val_accuracy: 0.9795 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0312 - accuracy: 0.9891 - val_loss: 0.0704 - val_accuracy: 0.9792 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "1046/1050 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9905\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.0649 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0194 - accuracy: 0.9928 - val_loss: 0.0533 - val_accuracy: 0.9838 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 0.0535 - val_accuracy: 0.9839 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.0529 - val_accuracy: 0.9837 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.0521 - val_accuracy: 0.9849 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0543 - val_accuracy: 0.9838 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.0530 - val_accuracy: 0.9839 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0557 - val_accuracy: 0.9837 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "1050/1050 [==============================] - 6s 5ms/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.0552 - val_accuracy: 0.9839 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "1049/1050 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9958\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.0555 - val_accuracy: 0.9835 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0547 - val_accuracy: 0.9835 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "1050/1050 [==============================] - 5s 5ms/step - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.0540 - val_accuracy: 0.9841 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f08d6455b50>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_11_results = model_11.evaluate(val_ds)\n",
        "model_11_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNmvpaTPmDnc",
        "outputId": "7d0b60d4-a778-4f12-9137-93afef64930c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 2s 6ms/step - loss: 0.0521 - accuracy: 0.9849\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05213718116283417, 0.9848520755767822]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot fine tuning results"
      ],
      "metadata": {
        "id": "zXG_J2qTmHVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuning_results = {\"model_8_lower_dropout\": model_7_results,\n",
        "                       \"model_9_increase_filters\": model_8_results,\n",
        "                       \"model_10_lower_dense_output\": model_9_results,\n",
        "                       \"model_11_extra_conv_block\": model_10_results,\n",
        "                       \"model_5_baseline\": model_11_results}\n",
        "fine_tuning_df = pd.DataFrame(fine_tuning_results).transpose()\n",
        "fine_tuning_acc = fine_tuning_df[1]\n",
        "fine_tuning_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKChJRopmiED",
        "outputId": "4e8bb221-cba9-4046-d01e-1abca1adb703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_8_lower_dropout          0.984375\n",
              "model_9_increase_filters       0.984136\n",
              "model_10_lower_dense_output    0.981632\n",
              "model_11_extra_conv_block      0.985806\n",
              "model_5_baseline               0.984852\n",
              "Name: 1, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuning_acc.sort_values(ascending=False).plot(kind=\"bar\", title=\"Fine Tuning Comparison\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "TQkFO0nmpFWm",
        "outputId": "463dcb95-bc5d-416b-b5c6-4870e0274f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f08d93b3c70>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the hyperparameters were fine for the most part, just adding another convolutional block increased accuracy just a bit. So we'll go with that model, model 11."
      ],
      "metadata": {
        "id": "jQFcvEMTpiCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct the final model with tuned hyperparameters"
      ],
      "metadata": {
        "id": "P8h1_nIPn1uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = model_10\n",
        "final_model.evaluate(val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxchP2x8o265",
        "outputId": "072f5629-b1b8-4495-eaf6-12ad197c6de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "262/262 [==============================] - 1s 5ms/step - loss: 0.0453 - accuracy: 0.9858\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.045344505459070206, 0.9858062863349915]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we'd expect around a 98.6% accuracy rate on the csv uploaded to Kaggle."
      ],
      "metadata": {
        "id": "9r453GcJp2gg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Test Dataset"
      ],
      "metadata": {
        "id": "xOdhPhUHqFOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds = tf.round(final_model.predict(test_df))\n",
        "test_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG8eR2K-qMdq",
        "outputId": "15ad1363-ff74-4a44-f4bd-8d5d02c0c35a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "875/875 [==============================] - 2s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(28000, 10), dtype=float32, numpy=\n",
              "array([[0., 0., 1., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds_labels = tf.argmax(test_preds, axis=1)\n",
        "test_preds_labels_df = pd.DataFrame(test_preds_labels)\n",
        "test_preds_labels_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zjpFGuxIqRcy",
        "outputId": "94f3bfd4-4503-4235-9a4a-53b36363a522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0\n",
              "0      2\n",
              "1      0\n",
              "2      9\n",
              "3      9\n",
              "4      3\n",
              "...   ..\n",
              "27995  9\n",
              "27996  7\n",
              "27997  3\n",
              "27998  9\n",
              "27999  2\n",
              "\n",
              "[28000 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4cdd0357-27ac-479f-82e6-8139a282c0c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27995</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27996</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27997</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27998</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27999</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28000 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cdd0357-27ac-479f-82e6-8139a282c0c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4cdd0357-27ac-479f-82e6-8139a282c0c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4cdd0357-27ac-479f-82e6-8139a282c0c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "DGHpl3sasrzc",
        "outputId": "1a19d139-9fd5-4f37-d79f-8bfb3e8e656f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0           0       0       0       0       0       0       0       0       0   \n",
              "1           0       0       0       0       0       0       0       0       0   \n",
              "2           0       0       0       0       0       0       0       0       0   \n",
              "3           0       0       0       0       0       0       0       0       0   \n",
              "4           0       0       0       0       0       0       0       0       0   \n",
              "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "27995       0       0       0       0       0       0       0       0       0   \n",
              "27996       0       0       0       0       0       0       0       0       0   \n",
              "27997       0       0       0       0       0       0       0       0       0   \n",
              "27998       0       0       0       0       0       0       0       0       0   \n",
              "27999       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "       pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
              "0           0  ...         0         0         0         0         0   \n",
              "1           0  ...         0         0         0         0         0   \n",
              "2           0  ...         0         0         0         0         0   \n",
              "3           0  ...         0         0         0         0         0   \n",
              "4           0  ...         0         0         0         0         0   \n",
              "...       ...  ...       ...       ...       ...       ...       ...   \n",
              "27995       0  ...         0         0         0         0         0   \n",
              "27996       0  ...         0         0         0         0         0   \n",
              "27997       0  ...         0         0         0         0         0   \n",
              "27998       0  ...         0         0         0         0         0   \n",
              "27999       0  ...         0         0         0         0         0   \n",
              "\n",
              "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
              "0             0         0         0         0         0  \n",
              "1             0         0         0         0         0  \n",
              "2             0         0         0         0         0  \n",
              "3             0         0         0         0         0  \n",
              "4             0         0         0         0         0  \n",
              "...         ...       ...       ...       ...       ...  \n",
              "27995         0         0         0         0         0  \n",
              "27996         0         0         0         0         0  \n",
              "27997         0         0         0         0         0  \n",
              "27998         0         0         0         0         0  \n",
              "27999         0         0         0         0         0  \n",
              "\n",
              "[28000 rows x 784 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-264b0332-1bd9-49b9-9ba3-82ef43434d54\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27998</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28000 rows × 784 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-264b0332-1bd9-49b9-9ba3-82ef43434d54')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-264b0332-1bd9-49b9-9ba3-82ef43434d54 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-264b0332-1bd9-49b9-9ba3-82ef43434d54');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(np.arange(1, 28001)), len(test_preds_labels))\n",
        "numpy_predicts = {\"ImageId\": np.arange(1, 28001), \"Label\":test_preds_labels}\n",
        "predict_df = pd.DataFrame(numpy_predicts)\n",
        "predict_df.to_csv(\"prediction_1.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKNQzQ4EreVP",
        "outputId": "edb6b34b-772f-4376-a79c-c6a711f23397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28000 28000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQN9Zv31soYo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}